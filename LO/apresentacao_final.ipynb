{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 18:19:19.873469: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-22 18:19:19.922500: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-22 18:19:19.922518: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import stft\n",
    "from math import prod\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from math import e\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from itertools import combinations\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(data, lowcut, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_lowpass(data, lowcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    b, a = signal.butter(order, low, btype='lowpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_highpass(data, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, high, btype='highpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_notch(data, cutoff, var=1, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = (cutoff - var) / nyq\n",
    "    high = (cutoff + var) / nyq\n",
    "    b, a = signal.iirfilter(order, [low, high], btype='bandstop', ftype=\"butter\")\n",
    "    return signal.filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtros(data):\n",
    "    data_filtered = butter_notch(data, 60)\n",
    "    data_filtered = butter_highpass(data_filtered, 5)\n",
    "    data_filtered = butter_lowpass(data_filtered, 50)\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4, 1600)\n"
     ]
    }
   ],
   "source": [
    "dir = './datasets/topicos_cc'\n",
    "arquivos = os.listdir(dir)\n",
    "arq_numpy = [f for f in arquivos if f.endswith(\".npy\") and f.startswith('p2')]\n",
    "participantes = {}\n",
    "vetor = []\n",
    "for i in arq_numpy:\n",
    "    nome = i.split('_')\n",
    "    trial = np.load(dir+'/'+i)\n",
    "    for m in range(0,8):\n",
    "        if participantes.get(f'trial_{nome[1]}',0) == 0:\n",
    "            participantes[f'trial_{nome[1]}'] = []\n",
    "        dados = trial[m, :, :].swapaxes(0,1)\n",
    "        participantes[f'trial_{nome[1]}'].append(filtros(dados))\n",
    "        \n",
    "\n",
    "arr = np.vstack((np.array(participantes['trial_1']), np.array(participantes['trial_2']), np.array(participantes['trial_3'])))\n",
    "\n",
    "\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (24, 4, 1600)\n",
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (24, 4, 125, 128) - (classes, ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (24, 4, 125, 65) - (classes, ensaios, canais, janelas, linhas)\n"
     ]
    }
   ],
   "source": [
    "step = 11.8\n",
    "segment = 128\n",
    "data = arr\n",
    "# .get_data()\n",
    "print('', data.shape)\n",
    "\n",
    "n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "ids = np.arange(n_win) * int(step)\n",
    "\n",
    "# Janelas do dado no dominio do tempo\n",
    "chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "# Janelas do dado no domínio da frequência\n",
    "_, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=115)\n",
    "chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "print(f'Dominio do tempo: {chunks_time.shape} - (classes, ensaios, canais, janelas, linhas)')\n",
    "print(f'Dominio da frequência:  {chunks_freq.shape} - (classes, ensaios, canais, janelas, linhas)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "\n",
    "# funções de extração de características\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape[:-1]) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape[:-1])))\n",
    "\n",
    "def wamp(x):\n",
    "    limiar = np.abs(np.diff(x))\n",
    "    return np.sum(limiar > 0.0001, axis=-1)\n",
    "\n",
    "def wl(x):\n",
    "    return np.sum(np.abs(np.diff(x)), axis=-1)\n",
    "\n",
    "\n",
    "def getzc(data, th):\n",
    "    t = len(data)\n",
    "    soma = 0\n",
    "    for i in range(t-1):\n",
    "        res = (data[i]*data[i+1])\n",
    "        res2 = np.abs(data[i]-data[i+1])\n",
    "        if (res<0 and res2 > th):\n",
    "            soma +=1\n",
    "    return soma\n",
    "\n",
    "def zc(data):\n",
    "    f=[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for i in range(x):\n",
    "        l = []\n",
    "        for j in range(y):\n",
    "            li = []\n",
    "            for k in range(z):\n",
    "                li.append(getzc(data[i][j][k], 0.0001))\n",
    "            l.append(li.copy())\n",
    "        f.append(l.copy())\n",
    "\n",
    "    return np.array(f)\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "\n",
    "def fmn(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*PSD(w)), axis=-1)/np.sum(PSD(w), axis=-1)\n",
    "\n",
    "def mmnf(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*np.abs(w)), axis=-1)/np.sum(np.abs(w), axis=-1)\n",
    "\n",
    "\n",
    "def logDec(data):\n",
    "    N = np.prod(data.shape)\n",
    "    return e ** (np.sum(np.log10(np.abs(data)), axis=-1))/N\n",
    "\n",
    "\n",
    "def iemg(x):\n",
    "    return np.sum(np.abs(x), axis=-1)\n",
    "\n",
    "def dasdv(x):\n",
    "    return np.sqrt(np.sum(np.diff(x)**2, axis=-1)/(np.prod(x.shape[:-1]) - 1))\n",
    "\n",
    "def tm(x,n):\n",
    "    return np.abs(np.sum(x**n , axis=-1)/np.prod(x.shape[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 24, 4, 125)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = list()\n",
    "final_data.append(var(chunks_time))\n",
    "final_data.append(rms(chunks_time))\n",
    "final_data.append(fmd(chunks_freq))\n",
    "final_data.append(mmdf(chunks_freq))\n",
    "final_data.append(logDec(chunks_time))\n",
    "final_data.append(wamp(chunks_time))\n",
    "final_data.append(wl(chunks_time))\n",
    "final_data.append(zc(chunks_time))\n",
    "final_data.append(fmn(chunks_freq))\n",
    "final_data.append(mmnf(chunks_freq))\n",
    "final_data.append(iemg(chunks_time))\n",
    "final_data.append(dasdv(chunks_time))\n",
    "\n",
    "for n in range(3,6):\n",
    "    final_data.append(tm(chunks_time, n))\n",
    "\n",
    "f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "final_data.append(Pxx_den)\n",
    "\n",
    "final = np.array(final_data)\n",
    "final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final.transpose(1,3,2,0)\n",
    "X = X.reshape(X.shape[0]*X.shape[1], X.shape[2]*X.shape[3])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [[i] * int(X.shape[0] / 8) for i in range(8)]\n",
    "y = np.array(y).flatten()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = []\n",
    "trial.append((X[:1000], y[:1000]))\n",
    "trial.append((X[1000:2000], y[1000:2000]))\n",
    "trial.append((X[2000:3000], y[2000:3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h):\n",
    "    loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' in s]\n",
    "    if len(loss_list) == 0:\n",
    "        print('Custo não está presente no histórico')\n",
    "        return\n",
    "    epochs = range(1, len(history.history[loss_list[0]]) + 1)\n",
    "    # Custo\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Custo [treinamento] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Custo [validação] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    plt.title('Custo')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Custo')\n",
    "    plt.legend()\n",
    "    # Acurácia\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Acurácia [treinamento] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Acurácia [validação] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    plt.title('Acurácia')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model):\n",
    "    j=0\n",
    "    scores = []\n",
    "    validations=[]\n",
    "    for i in combinations(trial, 2):\n",
    "        X_treino = np.vstack((i[0][0],i[1][0]))\n",
    "        X_teste = trial[j][0]\n",
    "\n",
    "        y_treino = np.vstack((i[0][1],i[1][1]))\n",
    "        y_treino= y_treino.reshape(y_treino.shape[0]*y_treino.shape[1])\n",
    "        y_teste = trial[j][1]\n",
    "\n",
    "\n",
    "        j+=1\n",
    "\n",
    "        # X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, test_size=0.3, shuffle=True, stratify=y_treino)\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, test_size=0.3, stratify=y_treino)\n",
    "\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_treino)\n",
    "\n",
    "        X_treino = scaler.transform(X_treino)\n",
    "        X_teste = scaler.transform(X_teste)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        history = model.fit(X_treino, y_treino, epochs=100, batch_size=15, validation_data=(X_val, y_val))\n",
    "        # plot_history(history)\n",
    "        predict_x=model.predict(X_val) \n",
    "        score=np.argmax(predict_x,axis=1)\n",
    "\n",
    "        print('--',score)\n",
    "\n",
    "        scores.append(score)\n",
    "        validations.append(y_val)\n",
    "\n",
    "\n",
    "    # y_true =  np.vstack((trial[0][1],trial[1][1], trial[2][1]))\n",
    "    y_true =  np.vstack((validations[0],validations[1], validations[2]))\n",
    "    y_true= y_true.reshape(y_true.shape[0]*y_true.shape[1])\n",
    "    sc = np.vstack((scores[0], scores[1], scores[2]))\n",
    "    sc= sc.reshape(sc.shape[0]*sc.shape[1])\n",
    "\n",
    "    print('\\n\\nAcurácia: %0.2f%%' % (accuracy_score(y_true, sc) * 100))\n",
    "    print('Matriz de confusão:')\n",
    "    print(confusion_matrix(y_true, sc))\n",
    "    print()\n",
    "    print(classification_report(y_true, sc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 14:49:18.306028: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-21 14:49:18.306046: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-21 14:49:18.306061: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (luisotavio-Aspire5): /proc/driver/nvidia/version does not exist\n",
      "2022-06-21 14:49:18.306422: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 2ms/step - loss: 2.0013 - accuracy: 0.3357 - val_loss: 1.6633 - val_accuracy: 0.4200\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5039 - accuracy: 0.4893 - val_loss: 1.3886 - val_accuracy: 0.5483\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3331 - accuracy: 0.5521 - val_loss: 1.2707 - val_accuracy: 0.5867\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2169 - accuracy: 0.5964 - val_loss: 1.2060 - val_accuracy: 0.6200\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1542 - accuracy: 0.6357 - val_loss: 1.2101 - val_accuracy: 0.6183\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1059 - accuracy: 0.6643 - val_loss: 1.1457 - val_accuracy: 0.6950\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0770 - accuracy: 0.6771 - val_loss: 1.1697 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0626 - accuracy: 0.6736 - val_loss: 1.0404 - val_accuracy: 0.7183\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9996 - accuracy: 0.7257 - val_loss: 1.0515 - val_accuracy: 0.6833\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9958 - accuracy: 0.7207 - val_loss: 1.0283 - val_accuracy: 0.7100\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.9699 - accuracy: 0.7243 - val_loss: 1.0336 - val_accuracy: 0.7350\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9521 - accuracy: 0.7400 - val_loss: 1.1009 - val_accuracy: 0.6400\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9191 - accuracy: 0.7550 - val_loss: 1.0110 - val_accuracy: 0.7283\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 0.7521 - val_loss: 0.9928 - val_accuracy: 0.7167\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8936 - accuracy: 0.7707 - val_loss: 0.9755 - val_accuracy: 0.7483\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8846 - accuracy: 0.7786 - val_loss: 0.9837 - val_accuracy: 0.7100\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.7593 - val_loss: 0.9998 - val_accuracy: 0.7233\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8866 - accuracy: 0.7650 - val_loss: 0.9560 - val_accuracy: 0.7383\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8880 - accuracy: 0.7686 - val_loss: 0.9263 - val_accuracy: 0.7450\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8623 - accuracy: 0.7736 - val_loss: 0.9543 - val_accuracy: 0.7383\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8423 - accuracy: 0.7814 - val_loss: 0.9203 - val_accuracy: 0.7550\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8307 - accuracy: 0.7879 - val_loss: 0.9650 - val_accuracy: 0.7283\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8056 - accuracy: 0.8043 - val_loss: 0.8948 - val_accuracy: 0.7767\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8073 - accuracy: 0.8000 - val_loss: 0.9570 - val_accuracy: 0.7183\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7989 - accuracy: 0.8043 - val_loss: 0.8687 - val_accuracy: 0.7783\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8161 - accuracy: 0.8036 - val_loss: 0.8447 - val_accuracy: 0.7850\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7888 - accuracy: 0.8164 - val_loss: 0.8877 - val_accuracy: 0.7617\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8181 - accuracy: 0.8029 - val_loss: 0.9127 - val_accuracy: 0.7483\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8025 - accuracy: 0.8007 - val_loss: 0.8672 - val_accuracy: 0.7850\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7868 - accuracy: 0.8186 - val_loss: 0.8642 - val_accuracy: 0.7783\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7560 - accuracy: 0.8250 - val_loss: 0.8665 - val_accuracy: 0.7517\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.8379 - val_loss: 0.8986 - val_accuracy: 0.7700\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7652 - accuracy: 0.8200 - val_loss: 0.8692 - val_accuracy: 0.7883\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7560 - accuracy: 0.8136 - val_loss: 0.8219 - val_accuracy: 0.8117\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7607 - accuracy: 0.8157 - val_loss: 0.9418 - val_accuracy: 0.7650\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7578 - accuracy: 0.8157 - val_loss: 0.8538 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7376 - accuracy: 0.8321 - val_loss: 0.8139 - val_accuracy: 0.8067\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.8229 - val_loss: 0.8764 - val_accuracy: 0.7583\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7924 - accuracy: 0.8136 - val_loss: 0.8313 - val_accuracy: 0.8017\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7153 - accuracy: 0.8371 - val_loss: 0.8136 - val_accuracy: 0.8233\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.8250 - val_loss: 0.7492 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.8379 - val_loss: 0.7730 - val_accuracy: 0.7983\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.8593 - val_loss: 0.7930 - val_accuracy: 0.7917\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.8564 - val_loss: 0.8152 - val_accuracy: 0.7983\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.8579 - val_loss: 0.7619 - val_accuracy: 0.8117\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.8586 - val_loss: 0.8108 - val_accuracy: 0.7750\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6723 - accuracy: 0.8514 - val_loss: 0.8267 - val_accuracy: 0.7700\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.8393 - val_loss: 0.8303 - val_accuracy: 0.7783\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7318 - accuracy: 0.8350 - val_loss: 0.7788 - val_accuracy: 0.8017\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7930 - accuracy: 0.8264 - val_loss: 0.7648 - val_accuracy: 0.8183\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.8550 - val_loss: 0.7273 - val_accuracy: 0.8400\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.8586 - val_loss: 0.7955 - val_accuracy: 0.8067\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.8329 - val_loss: 0.7528 - val_accuracy: 0.8233\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.8557 - val_loss: 0.8065 - val_accuracy: 0.8133\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.8557 - val_loss: 0.7768 - val_accuracy: 0.8150\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.8721 - val_loss: 0.7686 - val_accuracy: 0.8200\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.8707 - val_loss: 0.7569 - val_accuracy: 0.8300\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.8593 - val_loss: 0.7204 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.8543 - val_loss: 0.7976 - val_accuracy: 0.7900\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6788 - accuracy: 0.8493 - val_loss: 0.7172 - val_accuracy: 0.8417\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.8571 - val_loss: 0.7342 - val_accuracy: 0.8517\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.8686 - val_loss: 0.7819 - val_accuracy: 0.7983\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6203 - accuracy: 0.8643 - val_loss: 0.6952 - val_accuracy: 0.8467\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.8593 - val_loss: 0.7350 - val_accuracy: 0.8217\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.8600 - val_loss: 0.7585 - val_accuracy: 0.8133\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.8450 - val_loss: 0.7355 - val_accuracy: 0.8133\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6131 - accuracy: 0.8629 - val_loss: 0.6715 - val_accuracy: 0.8633\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.8829 - val_loss: 0.8383 - val_accuracy: 0.7750\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.8414 - val_loss: 0.6856 - val_accuracy: 0.8450\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6106 - accuracy: 0.8771 - val_loss: 0.7097 - val_accuracy: 0.8367\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.8629 - val_loss: 0.6871 - val_accuracy: 0.8467\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.8786 - val_loss: 0.7461 - val_accuracy: 0.8050\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.8707 - val_loss: 0.7637 - val_accuracy: 0.8183\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.8614 - val_loss: 0.7017 - val_accuracy: 0.8433\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6140 - accuracy: 0.8664 - val_loss: 0.6938 - val_accuracy: 0.8317\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.8779 - val_loss: 0.7242 - val_accuracy: 0.8517\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.8764 - val_loss: 0.6702 - val_accuracy: 0.8467\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.8629 - val_loss: 0.6842 - val_accuracy: 0.8450\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.8714 - val_loss: 0.7188 - val_accuracy: 0.8283\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.8664 - val_loss: 0.8051 - val_accuracy: 0.8233\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.8329 - val_loss: 0.8559 - val_accuracy: 0.7767\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.8636 - val_loss: 0.7949 - val_accuracy: 0.7900\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6386 - accuracy: 0.8493 - val_loss: 0.7655 - val_accuracy: 0.8200\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.8779 - val_loss: 0.7180 - val_accuracy: 0.8283\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6090 - accuracy: 0.8671 - val_loss: 0.7002 - val_accuracy: 0.8367\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.8643 - val_loss: 0.7138 - val_accuracy: 0.8267\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.8800 - val_loss: 0.7241 - val_accuracy: 0.8283\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.8879 - val_loss: 0.7301 - val_accuracy: 0.8233\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.8657 - val_loss: 0.6865 - val_accuracy: 0.8500\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.8807 - val_loss: 0.6765 - val_accuracy: 0.8517\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.8786 - val_loss: 0.7221 - val_accuracy: 0.8250\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 0.8764 - val_loss: 0.6646 - val_accuracy: 0.8500\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.8779 - val_loss: 0.7144 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.8864 - val_loss: 0.7326 - val_accuracy: 0.8233\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.8686 - val_loss: 0.6779 - val_accuracy: 0.8467\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.8671 - val_loss: 0.7399 - val_accuracy: 0.8167\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5721 - accuracy: 0.8814 - val_loss: 0.7074 - val_accuracy: 0.8267\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.8979 - val_loss: 0.7396 - val_accuracy: 0.8367\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.8529 - val_loss: 0.7976 - val_accuracy: 0.7817\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6009 - accuracy: 0.8764 - val_loss: 0.6719 - val_accuracy: 0.8550\n",
      "19/19 [==============================] - 0s 688us/step\n",
      "-- [2 5 1 3 0 4 4 1 2 4 3 4 3 1 3 0 3 0 3 0 2 2 2 2 3 2 0 2 3 1 2 1 2 0 1 4 0\n",
      " 3 2 3 2 4 4 4 4 3 4 2 2 1 2 4 5 2 3 0 4 2 2 0 1 0 2 3 5 3 2 4 3 4 4 0 5 0\n",
      " 1 2 2 0 3 4 2 1 3 2 3 3 0 5 4 4 1 0 3 1 2 1 0 3 4 4 1 1 2 1 1 3 5 5 0 1 2\n",
      " 1 2 2 4 3 4 4 0 3 2 2 4 3 4 2 1 0 3 1 4 2 1 3 2 1 3 2 5 2 3 0 0 4 1 0 4 0\n",
      " 4 1 3 4 4 3 0 2 0 4 0 2 0 2 3 0 0 4 3 2 2 0 0 3 2 4 2 0 0 2 2 3 4 5 4 4 1\n",
      " 1 5 0 2 1 4 1 0 0 0 2 2 0 4 3 5 2 3 4 0 4 0 1 1 0 0 0 2 1 0 1 3 4 2 0 3 3\n",
      " 3 4 1 4 0 5 5 0 1 2 4 4 5 3 4 0 4 1 1 0 1 4 2 4 0 2 1 4 1 2 4 2 0 2 3 1 2\n",
      " 3 4 1 3 4 2 4 2 3 3 2 3 2 0 5 2 3 4 4 3 1 4 1 3 0 4 3 1 4 4 0 2 3 4 5 4 4\n",
      " 1 2 0 1 0 2 0 1 2 4 3 2 3 0 1 2 3 4 5 1 0 4 1 0 0 0 4 1 3 1 4 1 0 3 5 3 1\n",
      " 1 4 4 2 1 3 3 2 3 0 4 3 3 1 1 2 2 3 3 4 3 4 3 2 1 0 2 3 5 3 4 1 2 2 2 3 1\n",
      " 3 1 0 1 2 2 0 1 1 3 2 1 4 2 2 5 2 5 4 1 4 3 3 4 3 4 2 4 3 4 3 1 1 0 3 0 4\n",
      " 0 2 4 5 2 1 4 1 5 3 0 0 4 4 2 0 2 0 0 1 3 4 0 1 0 2 2 0 1 3 1 3 4 1 1 0 0\n",
      " 0 0 5 4 5 1 4 0 4 0 1 4 2 3 2 1 4 2 2 0 1 2 4 3 3 2 4 2 4 0 2 3 3 2 2 3 1\n",
      " 0 2 1 4 4 3 2 2 4 1 0 3 0 1 3 4 2 1 1 3 1 0 1 2 2 3 0 4 4 3 1 1 3 0 1 0 1\n",
      " 4 4 4 1 3 1 5 1 4 2 0 2 0 0 5 1 3 0 4 0 1 1 2 1 5 4 5 4 0 0 4 3 5 1 0 1 0\n",
      " 1 3 5 1 4 2 4 1 3 1 0 3 3 4 2 3 2 0 4 2 1 1 4 4 4 4 2 4 4 1 0 1 4 3 1 5 0\n",
      " 0 5 4 2 2 1 0 1]\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.4461 - accuracy: 0.3957 - val_loss: 3.6256 - val_accuracy: 0.5033\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3557 - accuracy: 0.5729 - val_loss: 2.3888 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1743 - accuracy: 0.6500 - val_loss: 1.0975 - val_accuracy: 0.6783\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0164 - accuracy: 0.7350 - val_loss: 1.0493 - val_accuracy: 0.7167\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9582 - accuracy: 0.7479 - val_loss: 0.9666 - val_accuracy: 0.7517\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8853 - accuracy: 0.7857 - val_loss: 0.9701 - val_accuracy: 0.7183\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8479 - accuracy: 0.7957 - val_loss: 0.9157 - val_accuracy: 0.7667\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8048 - accuracy: 0.8229 - val_loss: 0.8521 - val_accuracy: 0.7617\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8073 - accuracy: 0.8086 - val_loss: 0.8212 - val_accuracy: 0.7867\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7739 - accuracy: 0.8186 - val_loss: 0.7701 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.8329 - val_loss: 0.8316 - val_accuracy: 0.7900\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.8379 - val_loss: 0.7415 - val_accuracy: 0.8283\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.8414 - val_loss: 0.8045 - val_accuracy: 0.7933\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7144 - accuracy: 0.8457 - val_loss: 0.7492 - val_accuracy: 0.8217\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.8636 - val_loss: 3.9116 - val_accuracy: 0.7900\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.8514 - val_loss: 0.7243 - val_accuracy: 0.8217\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.8571 - val_loss: 0.8029 - val_accuracy: 0.7900\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.8600 - val_loss: 0.7011 - val_accuracy: 0.8350\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.8664 - val_loss: 4.1895 - val_accuracy: 0.8117\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6723 - accuracy: 0.8536 - val_loss: 0.7372 - val_accuracy: 0.8400\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6302 - accuracy: 0.8843 - val_loss: 3.5435 - val_accuracy: 0.8300\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.8707 - val_loss: 3.6597 - val_accuracy: 0.8167\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.8514 - val_loss: 0.7936 - val_accuracy: 0.8067\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.8521 - val_loss: 0.8381 - val_accuracy: 0.7933\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.8479 - val_loss: 0.7488 - val_accuracy: 0.8300\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.8743 - val_loss: 0.6972 - val_accuracy: 0.8633\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.8886 - val_loss: 0.6932 - val_accuracy: 0.8433\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.8607 - val_loss: 0.6723 - val_accuracy: 0.8583\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.8907 - val_loss: 0.6709 - val_accuracy: 0.8517\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.8807 - val_loss: 0.7501 - val_accuracy: 0.8250\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.8914 - val_loss: 0.6775 - val_accuracy: 0.8567\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5964 - accuracy: 0.8971 - val_loss: 0.7784 - val_accuracy: 0.8083\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.8743 - val_loss: 1.1899 - val_accuracy: 0.8233\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.8779 - val_loss: 0.6672 - val_accuracy: 0.8583\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.8964 - val_loss: 4.4917 - val_accuracy: 0.8617\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.8900 - val_loss: 3.2130 - val_accuracy: 0.8633\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.8871 - val_loss: 0.8185 - val_accuracy: 0.8567\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.9043 - val_loss: 0.7926 - val_accuracy: 0.8383\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.8857 - val_loss: 0.6646 - val_accuracy: 0.8550\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.8836 - val_loss: 0.6647 - val_accuracy: 0.8533\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6133 - accuracy: 0.8829 - val_loss: 0.6923 - val_accuracy: 0.8250\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.8657 - val_loss: 0.7301 - val_accuracy: 0.8233\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.8686 - val_loss: 0.6800 - val_accuracy: 0.8467\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.8900 - val_loss: 0.6248 - val_accuracy: 0.8650\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.8979 - val_loss: 0.6192 - val_accuracy: 0.8717\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.9136 - val_loss: 0.5942 - val_accuracy: 0.8867\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5858 - accuracy: 0.8986 - val_loss: 0.6109 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.8971 - val_loss: 0.6324 - val_accuracy: 0.8767\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.9014 - val_loss: 0.6434 - val_accuracy: 0.8367\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.8964 - val_loss: 0.6194 - val_accuracy: 0.8600\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.8921 - val_loss: 0.6163 - val_accuracy: 0.8583\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5594 - accuracy: 0.9000 - val_loss: 0.6848 - val_accuracy: 0.8267\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.9043 - val_loss: 0.5840 - val_accuracy: 0.9050\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5378 - accuracy: 0.9150 - val_loss: 0.6414 - val_accuracy: 0.8500\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.8743 - val_loss: 0.6379 - val_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.9107 - val_loss: 0.5922 - val_accuracy: 0.8867\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5377 - accuracy: 0.9093 - val_loss: 0.5956 - val_accuracy: 0.8750\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.9114 - val_loss: 0.6070 - val_accuracy: 0.8717\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.9057 - val_loss: 0.6234 - val_accuracy: 0.8617\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.8936 - val_loss: 0.6656 - val_accuracy: 0.8367\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.8836 - val_loss: 0.6299 - val_accuracy: 0.8550\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6196 - accuracy: 0.8771 - val_loss: 1.2233 - val_accuracy: 0.8283\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.8729 - val_loss: 0.7003 - val_accuracy: 0.8367\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.8950 - val_loss: 0.6363 - val_accuracy: 0.8683\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.9021 - val_loss: 1.0000 - val_accuracy: 0.8517\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.9050 - val_loss: 0.6527 - val_accuracy: 0.8517\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.9121 - val_loss: 2.4694 - val_accuracy: 0.8417\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.9100 - val_loss: 2.5795 - val_accuracy: 0.8600\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5670 - accuracy: 0.9086 - val_loss: 4.7444 - val_accuracy: 0.8417\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.9000 - val_loss: 5.4110 - val_accuracy: 0.8717\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.9107 - val_loss: 2.7567 - val_accuracy: 0.8983\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.9221 - val_loss: 1.6493 - val_accuracy: 0.8867\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.9100 - val_loss: 3.1302 - val_accuracy: 0.8367\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.8707 - val_loss: 0.6732 - val_accuracy: 0.8400\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5361 - accuracy: 0.9071 - val_loss: 6.2550 - val_accuracy: 0.7900\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5366 - accuracy: 0.9093 - val_loss: 0.6074 - val_accuracy: 0.8750\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.9207 - val_loss: 2.8966 - val_accuracy: 0.8650\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.9050 - val_loss: 3.7391 - val_accuracy: 0.8600\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5082 - accuracy: 0.9150 - val_loss: 1.8280 - val_accuracy: 0.8733\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.9143 - val_loss: 3.2746 - val_accuracy: 0.8583\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.9086 - val_loss: 2.8556 - val_accuracy: 0.8367\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.9307 - val_loss: 2.6203 - val_accuracy: 0.8733\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5505 - accuracy: 0.8993 - val_loss: 2.6300 - val_accuracy: 0.8933\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.9207 - val_loss: 2.1100 - val_accuracy: 0.8583\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.9136 - val_loss: 6.0961 - val_accuracy: 0.8533\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.8886 - val_loss: 1.8946 - val_accuracy: 0.8617\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.8943 - val_loss: 0.7819 - val_accuracy: 0.8617\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.9100 - val_loss: 0.6134 - val_accuracy: 0.8483\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.9086 - val_loss: 2.8218 - val_accuracy: 0.8967\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.9186 - val_loss: 2.4420 - val_accuracy: 0.8767\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.9157 - val_loss: 0.5824 - val_accuracy: 0.8800\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.9171 - val_loss: 0.5481 - val_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.9157 - val_loss: 0.5494 - val_accuracy: 0.8783\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.9143 - val_loss: 1.4107 - val_accuracy: 0.8217\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.8957 - val_loss: 1.4934 - val_accuracy: 0.8567\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.9264 - val_loss: 0.6374 - val_accuracy: 0.8667\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.9243 - val_loss: 7.0736 - val_accuracy: 0.8650\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.9143 - val_loss: 1.8111 - val_accuracy: 0.8950\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.9179 - val_loss: 5.5057 - val_accuracy: 0.8800\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.9071 - val_loss: 0.8526 - val_accuracy: 0.8767\n",
      "19/19 [==============================] - 0s 976us/step\n",
      "-- [1 5 2 6 1 6 2 7 0 5 6 6 0 1 0 6 6 7 6 7 0 1 7 1 7 0 7 0 6 7 0 0 7 1 5 7 2\n",
      " 5 5 6 1 0 0 7 5 1 2 6 6 2 6 2 7 0 6 7 0 7 0 5 7 7 5 1 7 7 1 7 7 5 0 1 7 6\n",
      " 6 2 5 7 0 6 7 7 0 0 7 1 1 0 0 0 1 1 0 0 5 0 7 6 6 6 5 7 2 2 5 7 1 5 7 6 7\n",
      " 7 1 5 1 6 5 6 1 5 2 6 0 1 0 2 6 6 5 0 0 6 6 7 5 6 1 6 2 6 7 7 6 0 6 7 6 5\n",
      " 6 7 6 5 0 0 6 1 6 6 0 5 7 0 7 6 5 6 1 2 5 7 5 6 0 6 6 1 6 6 0 0 7 2 6 1 5\n",
      " 5 1 7 0 6 2 0 5 1 6 1 5 0 1 7 1 0 0 5 5 7 7 2 5 5 1 7 0 2 7 1 1 6 2 5 0 1\n",
      " 5 2 2 0 0 5 7 2 0 5 6 6 0 6 6 6 6 5 1 7 7 7 2 5 0 0 5 1 5 0 6 0 1 0 6 2 7\n",
      " 7 6 0 2 2 2 6 1 7 6 7 6 2 0 2 7 5 5 5 5 1 0 2 1 0 7 2 0 1 0 6 7 6 5 5 7 6\n",
      " 2 0 7 2 7 7 6 1 1 2 0 0 0 5 1 5 1 0 7 6 6 0 1 1 0 0 0 7 6 5 7 6 7 0 0 6 1\n",
      " 2 1 6 1 0 7 1 0 0 1 2 6 6 2 1 6 0 0 7 7 0 0 5 6 7 0 1 2 7 1 0 0 1 5 7 6 6\n",
      " 2 5 7 5 0 1 7 5 6 7 0 0 5 7 7 6 6 0 7 6 5 1 7 7 0 2 5 0 1 6 2 0 2 0 7 0 2\n",
      " 7 6 7 5 7 0 2 1 1 7 7 7 7 7 0 0 6 6 2 1 7 2 7 1 1 7 2 6 1 6 6 1 7 0 6 0 7\n",
      " 1 0 7 1 6 6 6 7 0 1 7 0 0 0 7 7 7 7 5 6 7 7 7 5 0 7 7 7 0 2 0 6 6 6 7 1 2\n",
      " 2 2 6 2 7 1 1 1 5 7 7 1 6 6 6 1 0 1 6 1 6 7 7 0 1 2 5 7 0 0 7 0 1 0 2 5 1\n",
      " 7 7 7 0 1 2 7 0 7 1 1 1 1 6 1 0 2 7 7 1 0 2 2 6 1 2 5 0 2 6 7 0 6 1 6 7 2\n",
      " 0 1 6 7 7 1 1 1 7 7 1 5 5 2 0 6 7 1 7 7 5 7 6 7 6 2 2 6 6 7 7 2 7 5 2 0 6\n",
      " 7 0 0 5 5 0 0 7]\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.1459 - accuracy: 0.4536 - val_loss: 1.3983 - val_accuracy: 0.6350\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1992 - accuracy: 0.6350 - val_loss: 1.3959 - val_accuracy: 0.6400\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0985 - accuracy: 0.6650 - val_loss: 1.1460 - val_accuracy: 0.6867\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0292 - accuracy: 0.6914 - val_loss: 1.1177 - val_accuracy: 0.6583\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9798 - accuracy: 0.7100 - val_loss: 1.0350 - val_accuracy: 0.6750\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9481 - accuracy: 0.6921 - val_loss: 1.0142 - val_accuracy: 0.7117\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8903 - accuracy: 0.7364 - val_loss: 0.9389 - val_accuracy: 0.7183\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8927 - accuracy: 0.7407 - val_loss: 0.9102 - val_accuracy: 0.7417\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8843 - accuracy: 0.7364 - val_loss: 0.9764 - val_accuracy: 0.7433\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8736 - accuracy: 0.7593 - val_loss: 0.9447 - val_accuracy: 0.7317\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8090 - accuracy: 0.7850 - val_loss: 0.9145 - val_accuracy: 0.7583\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8260 - accuracy: 0.7521 - val_loss: 0.9186 - val_accuracy: 0.7383\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7895 - accuracy: 0.7743 - val_loss: 0.8406 - val_accuracy: 0.7633\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8126 - accuracy: 0.7707 - val_loss: 0.8326 - val_accuracy: 0.7617\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7757 - accuracy: 0.7986 - val_loss: 0.8327 - val_accuracy: 0.7700\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7835 - accuracy: 0.7964 - val_loss: 0.8698 - val_accuracy: 0.8033\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7371 - accuracy: 0.8193 - val_loss: 0.9043 - val_accuracy: 0.7850\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7343 - accuracy: 0.8093 - val_loss: 0.8444 - val_accuracy: 0.7817\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.8236 - val_loss: 0.7646 - val_accuracy: 0.8267\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.8243 - val_loss: 0.7942 - val_accuracy: 0.7950\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.8100 - val_loss: 0.8608 - val_accuracy: 0.7600\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.8157 - val_loss: 0.7729 - val_accuracy: 0.8300\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.8279 - val_loss: 0.9748 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7599 - accuracy: 0.8079 - val_loss: 0.8013 - val_accuracy: 0.8350\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7196 - accuracy: 0.8264 - val_loss: 0.7906 - val_accuracy: 0.8050\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.8529 - val_loss: 0.8595 - val_accuracy: 0.7700\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.8371 - val_loss: 0.8082 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.8200 - val_loss: 0.9331 - val_accuracy: 0.7317\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7655 - accuracy: 0.8129 - val_loss: 0.8310 - val_accuracy: 0.7800\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7463 - accuracy: 0.8136 - val_loss: 0.9899 - val_accuracy: 0.7533\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7026 - accuracy: 0.8336 - val_loss: 0.7589 - val_accuracy: 0.8167\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.8500 - val_loss: 0.7820 - val_accuracy: 0.8133\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.8707 - val_loss: 0.7797 - val_accuracy: 0.8250\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.8636 - val_loss: 0.7186 - val_accuracy: 0.8533\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.8600 - val_loss: 0.7835 - val_accuracy: 0.8267\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.8464 - val_loss: 0.8400 - val_accuracy: 0.8483\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.8657 - val_loss: 0.7786 - val_accuracy: 0.8233\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.8793 - val_loss: 0.7096 - val_accuracy: 0.8583\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.8707 - val_loss: 0.7838 - val_accuracy: 0.8117\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.8593 - val_loss: 0.7445 - val_accuracy: 0.8100\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.8307 - val_loss: 0.7117 - val_accuracy: 0.8550\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.8843 - val_loss: 0.7195 - val_accuracy: 0.8583\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.8479 - val_loss: 0.8032 - val_accuracy: 0.8400\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6192 - accuracy: 0.8721 - val_loss: 1.3494 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6192 - accuracy: 0.8671 - val_loss: 1.3707 - val_accuracy: 0.8217\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.8429 - val_loss: 1.2275 - val_accuracy: 0.8383\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.8507 - val_loss: 1.0720 - val_accuracy: 0.8267\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.8693 - val_loss: 1.0499 - val_accuracy: 0.8483\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.8714 - val_loss: 1.0996 - val_accuracy: 0.8300\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5964 - accuracy: 0.8821 - val_loss: 1.0778 - val_accuracy: 0.8517\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.8514 - val_loss: 0.9099 - val_accuracy: 0.8117\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.8836 - val_loss: 1.0418 - val_accuracy: 0.8650\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.8421 - val_loss: 1.0314 - val_accuracy: 0.8133\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.8650 - val_loss: 0.7382 - val_accuracy: 0.8483\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.8886 - val_loss: 0.6932 - val_accuracy: 0.8800\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.8886 - val_loss: 0.7741 - val_accuracy: 0.8350\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.9000 - val_loss: 0.7968 - val_accuracy: 0.8533\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.8943 - val_loss: 0.8611 - val_accuracy: 0.8717\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.8800 - val_loss: 1.1661 - val_accuracy: 0.8717\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.8714 - val_loss: 1.0372 - val_accuracy: 0.8700\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.8857 - val_loss: 1.1606 - val_accuracy: 0.7950\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.8614 - val_loss: 0.9632 - val_accuracy: 0.8650\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.8936 - val_loss: 0.9468 - val_accuracy: 0.8700\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.8707 - val_loss: 0.9349 - val_accuracy: 0.8650\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.8957 - val_loss: 0.8262 - val_accuracy: 0.8633\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.8886 - val_loss: 0.9699 - val_accuracy: 0.7767\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.8829 - val_loss: 0.7314 - val_accuracy: 0.8867\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.9043 - val_loss: 0.7330 - val_accuracy: 0.8767\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.8750 - val_loss: 0.7023 - val_accuracy: 0.8617\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.8907 - val_loss: 0.7110 - val_accuracy: 0.8450\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.8936 - val_loss: 0.7684 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.9086 - val_loss: 0.6980 - val_accuracy: 0.8650\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.8986 - val_loss: 0.7061 - val_accuracy: 0.8383\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.8900 - val_loss: 0.8023 - val_accuracy: 0.8150\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.8907 - val_loss: 0.6345 - val_accuracy: 0.8867\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.8943 - val_loss: 0.8028 - val_accuracy: 0.8633\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.9007 - val_loss: 0.8897 - val_accuracy: 0.8550\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.8893 - val_loss: 0.8238 - val_accuracy: 0.8183\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.8529 - val_loss: 0.8014 - val_accuracy: 0.8367\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.8750 - val_loss: 0.7045 - val_accuracy: 0.8633\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.9071 - val_loss: 0.6484 - val_accuracy: 0.8900\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.9021 - val_loss: 0.8429 - val_accuracy: 0.8300\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5376 - accuracy: 0.9114 - val_loss: 0.6588 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.8879 - val_loss: 0.7937 - val_accuracy: 0.8483\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5338 - accuracy: 0.9064 - val_loss: 0.6670 - val_accuracy: 0.8767\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.9100 - val_loss: 0.7377 - val_accuracy: 0.8800\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.8971 - val_loss: 0.7857 - val_accuracy: 0.8617\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.9071 - val_loss: 0.7051 - val_accuracy: 0.8717\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.9193 - val_loss: 0.6880 - val_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.8993 - val_loss: 0.6809 - val_accuracy: 0.8700\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.8729 - val_loss: 0.7738 - val_accuracy: 0.8283\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.8579 - val_loss: 0.8949 - val_accuracy: 0.8083\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.8879 - val_loss: 0.6652 - val_accuracy: 0.8667\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.9000 - val_loss: 0.6981 - val_accuracy: 0.8683\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.9243 - val_loss: 0.5948 - val_accuracy: 0.8900\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.9171 - val_loss: 0.6522 - val_accuracy: 0.8967\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.9107 - val_loss: 0.6727 - val_accuracy: 0.8583\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.9057 - val_loss: 0.6868 - val_accuracy: 0.8683\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.9150 - val_loss: 0.6651 - val_accuracy: 0.8833\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.9136 - val_loss: 0.5835 - val_accuracy: 0.8900\n",
      "19/19 [==============================] - 0s 682us/step\n",
      "-- [6 3 4 3 5 2 5 5 5 7 7 2 4 6 4 5 7 3 5 7 3 7 2 4 2 6 7 6 7 5 5 3 4 6 3 6 4\n",
      " 5 4 7 3 4 6 6 6 3 7 4 6 5 5 3 5 7 5 6 6 4 6 5 5 4 6 2 6 6 3 4 5 7 4 4 5 7\n",
      " 3 4 5 6 6 7 6 3 3 4 6 5 7 3 2 4 7 7 3 2 4 5 6 5 7 3 7 3 6 5 2 6 5 4 3 4 3\n",
      " 7 5 5 6 3 2 6 4 3 5 3 7 7 5 6 3 5 5 5 3 3 7 6 3 5 6 7 4 4 3 5 6 5 5 6 4 4\n",
      " 4 3 3 7 4 6 6 6 6 4 4 7 5 7 5 5 7 3 4 3 7 4 7 4 6 6 7 3 3 4 6 6 4 6 4 5 4\n",
      " 5 4 6 3 5 7 4 5 5 4 5 3 4 3 7 2 7 4 3 7 5 5 4 4 5 4 6 6 6 6 6 6 7 7 6 6 5\n",
      " 4 6 6 7 5 3 6 7 6 7 6 3 3 7 7 7 3 2 6 7 4 4 3 7 4 3 4 5 7 7 7 3 7 3 5 7 4\n",
      " 5 6 4 4 6 2 4 4 4 4 4 7 3 6 3 6 7 3 7 5 2 4 5 6 2 6 4 3 5 5 4 5 2 3 6 6 5\n",
      " 5 6 7 5 7 5 7 5 3 5 4 7 3 7 5 6 7 7 4 7 7 6 3 3 3 6 6 4 3 4 6 6 3 5 7 6 4\n",
      " 7 6 5 2 5 6 5 4 6 5 4 3 7 3 6 3 7 4 3 6 2 5 5 3 3 4 6 5 4 3 6 7 5 2 6 7 7\n",
      " 5 2 3 3 4 3 6 3 5 6 5 3 5 5 4 3 7 3 5 2 6 5 4 4 6 5 4 5 5 3 7 5 6 7 7 2 7\n",
      " 6 3 2 3 6 3 3 2 4 4 6 2 5 6 4 2 4 7 3 5 6 3 2 6 5 6 5 3 3 7 6 7 6 4 7 7 5\n",
      " 3 2 3 7 5 4 3 4 4 4 6 4 6 5 6 6 4 3 2 6 6 5 7 4 6 3 6 2 7 6 3 3 3 5 3 3 7\n",
      " 5 6 5 7 3 2 7 5 6 4 7 3 5 3 7 5 7 5 7 7 3 3 4 7 3 4 5 3 2 6 3 5 3 3 6 4 6\n",
      " 2 6 5 6 2 6 7 7 7 7 6 5 5 3 5 4 7 7 5 5 4 4 3 3 4 3 6 4 7 6 3 6 7 7 4 3 7\n",
      " 7 4 4 5 4 6 3 3 6 6 4 4 3 6 7 2 3 3 4 3 6 5 3 6 4 3 7 6 3 6 5 3 7 3 5 4 4\n",
      " 3 2 4 3 6 6 7 7]\n",
      "\n",
      "\n",
      "Acurácia: 87.39%\n",
      "Matriz de confusão:\n",
      "[[200   0   7  12   1   1   0   4]\n",
      " [  1 191   5   0   8   2   4  14]\n",
      " [ 10   6 191   0   4   9   0   5]\n",
      " [  9   2   0 191  15   0   7   0]\n",
      " [  1   5   6  11 194   0   3   4]\n",
      " [  3   0   4   1   4 195   9  10]\n",
      " [  0   2   0   9   1   0 210   4]\n",
      " [  3   3   4   0   3   7   4 201]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88106   0.88889   0.88496       225\n",
      "           1    0.91388   0.84889   0.88018       225\n",
      "           2    0.88018   0.84889   0.86425       225\n",
      "           3    0.85268   0.85268   0.85268       224\n",
      "           4    0.84348   0.86607   0.85463       224\n",
      "           5    0.91121   0.86283   0.88636       226\n",
      "           6    0.88608   0.92920   0.90713       226\n",
      "           7    0.83058   0.89333   0.86081       225\n",
      "\n",
      "    accuracy                        0.87389      1800\n",
      "   macro avg    0.87489   0.87385   0.87388      1800\n",
      "weighted avg    0.87495   0.87389   0.87392      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definição de uma fração do regularizador\n",
    "l = 0.01\n",
    "\n",
    "# desenvolvimento do modelo Keras para uma MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=64,\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Aplicação de um modelo de descida de gradiente utilizando o Stocastic Gradient Descendent (SGD)\n",
    "sgd = SGD(learning_rate=0.05, momentum=0.0)\n",
    "# Função de otimização da rede: ADAM\n",
    "adam = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999)\n",
    "# Função de custo baseada em dados originalmente categóricos\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  \n",
    "cross_val(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val2(model):\n",
    "    j=0\n",
    "    scores = []\n",
    "    validations = []\n",
    "    for i in combinations(trial, 2):\n",
    "        X_treino = np.vstack((i[0][0],i[1][0]))\n",
    "        X_teste = trial[j][0]\n",
    "\n",
    "        y_treino = np.vstack((i[0][1],i[1][1]))\n",
    "        y_treino= y_treino.reshape(y_treino.shape[0]*y_treino.shape[1])\n",
    "        y_teste = trial[j][1]\n",
    "\n",
    "\n",
    "        j+=1\n",
    "\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(X_treino, y_treino, test_size=0.3, stratify=y_treino)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_treino)\n",
    "\n",
    "        X_treino = scaler.transform(X_treino)\n",
    "        X_teste = scaler.transform(X_teste)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        history = model.fit(X_treino, y_treino)\n",
    "        # plot_history(history)\n",
    "        predict_x=model.predict(X_val) \n",
    "        # print(predict_x)\n",
    "        # print(predict_x.shape)\n",
    "        # score=np.argmax(predict_x)\n",
    "        # score=np.argmax(predict_x,axis=1)\n",
    "        # scores.append(score)\n",
    "        scores.append(predict_x)\n",
    "        validations.append(y_val)\n",
    "\n",
    "    y_true =  np.vstack((validations[0],validations[1], validations[2]))\n",
    "    y_true= y_true.reshape(y_true.shape[0]*y_true.shape[1])\n",
    "    sc = np.vstack((scores[0], scores[1], scores[2]))\n",
    "    sc= sc.reshape(sc.shape[0]*sc.shape[1])\n",
    "\n",
    "    print('\\n\\nAcurácia: %0.2f%%' % (accuracy_score(y_true, sc) * 100))\n",
    "    print('Matriz de confusão:')\n",
    "    print(confusion_matrix(y_true, sc))\n",
    "    print()\n",
    "    print(classification_report(y_true, sc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Acurácia: 65.17%\n",
      "Matriz de confusão:\n",
      "[[153   8  24  19   2   6  11   2]\n",
      " [  4 119   4  16  28   0  38  16]\n",
      " [ 13  21 144   4  20   8   0  15]\n",
      " [  8  11  12 134   7  10  43   0]\n",
      " [  8  21   8  21 136   4  13  15]\n",
      " [ 11   3  13  21   6 128  29  13]\n",
      " [  0   1   0   9   2   5 207   1]\n",
      " [ 10   8   6  10  20  14   5 152]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.73913   0.68000   0.70833       225\n",
      "           1    0.61979   0.52889   0.57074       225\n",
      "           2    0.68246   0.64000   0.66055       225\n",
      "           3    0.57265   0.59556   0.58388       225\n",
      "           4    0.61538   0.60177   0.60850       226\n",
      "           5    0.73143   0.57143   0.64160       224\n",
      "           6    0.59827   0.92000   0.72504       225\n",
      "           7    0.71028   0.67556   0.69248       225\n",
      "\n",
      "    accuracy                        0.65167      1800\n",
      "   macro avg    0.65867   0.65165   0.64889      1800\n",
      "weighted avg    0.65861   0.65167   0.64887      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# modelo de classificador com os parâmetros padrões\n",
    "clf = SVC(gamma='scale')\n",
    "\n",
    "# criando o modelo de classificação com os dados de treino\n",
    "cross_val2(clf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
