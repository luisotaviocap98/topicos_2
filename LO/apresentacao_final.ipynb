{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 16:21:52.800926: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-16 16:21:52.804459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-16 16:21:52.804470: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import stft\n",
    "from math import prod\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from math import e\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from itertools import combinations\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(data, lowcut, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_lowpass(data, lowcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    b, a = signal.butter(order, low, btype='lowpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_highpass(data, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, high, btype='highpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_notch(data, cutoff, var=1, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = (cutoff - var) / nyq\n",
    "    high = (cutoff + var) / nyq\n",
    "    b, a = signal.iirfilter(order, [low, high], btype='bandstop', ftype=\"butter\")\n",
    "    return signal.filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtros(data):\n",
    "    data_filtered = butter_notch(data, 60)\n",
    "    data_filtered = butter_highpass(data_filtered, 5)\n",
    "    data_filtered = butter_lowpass(data_filtered, 50)\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4, 1600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'trial_2': [array([[  0.29706151,  -0.10758804,   1.23396836, ..., -38.45522264,\n",
       "          -17.73104717,   0.81996573],\n",
       "         [  0.08937505,  -7.59702407,  -5.33727604, ...,  30.65703983,\n",
       "           39.85397463,  -4.36759111],\n",
       "         [ -0.37811694,   0.44031343,   3.97210754, ...,  14.22481131,\n",
       "           26.12198471,   2.06869271],\n",
       "         [  0.08187095,   2.26459197,   3.72874838, ...,  -5.42794101,\n",
       "           -2.58438479,  -0.51082867]]),\n",
       "  array([[-1.73949608e-01, -1.42606709e+01, -1.55178994e+01, ...,\n",
       "          -5.04905317e+01, -4.19364713e+01,  9.20553298e+00],\n",
       "         [ 3.61063262e-02,  3.88964943e+00,  2.20453159e+00, ...,\n",
       "           7.98866294e+01,  7.50537834e+01, -2.10478914e-01],\n",
       "         [ 4.99892252e-02, -5.66187924e+00, -9.97914406e+00, ...,\n",
       "           2.21823731e+00,  8.47436948e-01,  3.28411724e-01],\n",
       "         [ 2.29972170e-02,  3.26872918e+00,  4.23690585e+00, ...,\n",
       "          -6.01274568e+00, -2.61444681e+00, -1.98066580e-01]]),\n",
       "  array([[  0.11907216,   3.39327291,   2.87792021, ...,   2.36730454,\n",
       "            2.83147253,   0.27363561],\n",
       "         [ -0.03321934,  -0.28832491,  -1.32475959, ..., -29.91814872,\n",
       "          -24.2894814 ,  -1.79250764],\n",
       "         [ -0.31780254,   4.7769454 ,   5.42556806, ...,  -0.76465945,\n",
       "           -1.47441007,  -1.0878036 ],\n",
       "         [ -0.17604392,   2.7049608 ,   1.27191785, ...,   0.2172488 ,\n",
       "           -0.69967462,   0.62342211]]),\n",
       "  array([[  0.13015503,  -6.07456144, -10.58212388, ...,  -3.12952408,\n",
       "            0.05870249,  -5.51005583],\n",
       "         [ -0.18673174,  -4.0766338 ,  -3.41135502, ...,  -8.64006182,\n",
       "           -5.19652824,  -0.56677434],\n",
       "         [ -0.18309174,   4.28533017,   4.71060827, ...,   7.55307413,\n",
       "           -8.37883099,   3.01461066],\n",
       "         [  0.13600279,   1.15988806,  -0.47830233, ...,  -1.02957885,\n",
       "           -0.10011682,  -0.95606915]]),\n",
       "  array([[-4.07935093e-01, -1.32583872e+01, -1.38436424e+01, ...,\n",
       "           1.48796104e+01,  2.19082822e+01,  3.91290750e+00],\n",
       "         [-4.83442261e-01, -5.65756962e+00, -7.56262291e+00, ...,\n",
       "          -5.77993941e+00, -4.80674024e+00,  1.64985959e-01],\n",
       "         [ 2.04836035e-02,  3.75828196e+00,  5.36145479e+00, ...,\n",
       "          -3.21509852e+01, -3.14892145e+01,  1.03164241e+00],\n",
       "         [-4.09539647e-01,  8.48119304e+00,  8.17636863e+00, ...,\n",
       "           8.66193277e+00,  7.83824357e+00,  3.74792827e-01]]),\n",
       "  array([[  0.526426  ,   6.73231426,  10.14742838, ...,  61.77159536,\n",
       "           50.28913114,  -2.28147377],\n",
       "         [  0.12371896,   3.1112256 ,   3.76837648, ..., -25.99265294,\n",
       "          -19.97899125,  -4.64048123],\n",
       "         [ -0.43283801,   0.9612428 ,  -0.13932282, ...,  -5.53523799,\n",
       "           -5.65779377,  -1.12088234],\n",
       "         [ -0.06383116,   3.297932  ,   0.68785391, ...,  -9.07897429,\n",
       "           -9.27164231,   1.4829658 ]]),\n",
       "  array([[-1.35929163e+00,  9.98726433e+00,  1.15559578e+01, ...,\n",
       "          -1.03807401e+01, -2.79689529e+01, -3.52171560e+00],\n",
       "         [-2.93026744e-01, -2.06543971e+01, -2.09251146e+01, ...,\n",
       "          -2.74645548e+00, -7.15913914e+00, -4.98846545e-01],\n",
       "         [ 9.26280905e-03,  1.94671472e+00,  1.63208607e+00, ...,\n",
       "           1.65778333e+01,  1.68860205e+01,  9.50493697e-01],\n",
       "         [-5.48388744e-01,  6.52132862e-01,  2.71222967e-01, ...,\n",
       "           2.33546589e+00,  1.86384677e-01, -1.20190343e+00]]),\n",
       "  array([[ 3.10680345e-01,  4.95113186e+00,  6.54289473e+00, ...,\n",
       "           3.59800909e+01,  1.57211925e-01,  2.08621851e+00],\n",
       "         [ 2.95376974e-01,  2.02508619e+00, -4.90717511e+00, ...,\n",
       "          -9.80730667e+01, -1.12237025e+02, -1.06883701e+01],\n",
       "         [ 1.09516428e-01, -5.11575359e-02,  7.10090281e-01, ...,\n",
       "           2.13750254e+01,  1.57751671e+01,  3.57118508e-01],\n",
       "         [ 3.98687972e-01,  7.96715654e+00,  8.04687506e+00, ...,\n",
       "          -1.49346990e+01,  7.06377784e+00,  1.52789836e+01]])],\n",
       " 'trial_1': [array([[ 8.86971424e-01,  2.75032326e+00,  7.30910660e-01, ...,\n",
       "           3.20848183e+01,  2.63629669e+01, -9.70162171e-01],\n",
       "         [ 1.14110323e-02, -1.25572281e+00, -7.87835958e-01, ...,\n",
       "          -4.27222536e+01, -4.59572418e+01,  1.14632761e+01],\n",
       "         [ 3.04300771e-02, -5.78062191e-01, -2.73157842e+00, ...,\n",
       "           1.45374873e+01,  5.37522607e+00,  9.25156851e-01],\n",
       "         [ 3.77486366e-01, -3.28394203e-01,  1.61014470e+00, ...,\n",
       "           6.65025614e+00,  3.81722011e+00,  7.66291046e-01]]),\n",
       "  array([[  0.87895261,  10.83082549,   7.94568282, ...,   2.22737428,\n",
       "          -16.57643156,   2.31425458],\n",
       "         [  1.61366433,   7.03969846,   5.07326019, ...,  -0.69471828,\n",
       "          -23.59994116,  -8.64044464],\n",
       "         [ -0.09501406,   3.64290801,   5.49207298, ...,  -1.50448432,\n",
       "           -1.98745328,   0.3716078 ],\n",
       "         [  1.40265117,   0.60873325,  -2.13356858, ..., -23.8279123 ,\n",
       "          -19.16239428,  -0.61128691]]),\n",
       "  array([[ 0.40246225, 11.38863356, 15.26006936, ..., 11.14502708,\n",
       "          17.69077235, -6.93840439],\n",
       "         [-0.22134116,  4.24184954,  3.71249999, ..., 22.83217741,\n",
       "          21.8168833 ,  0.10476536],\n",
       "         [ 0.28457403,  3.56112214,  1.97702901, ..., 10.17736237,\n",
       "          10.23530824, -1.2490714 ],\n",
       "         [ 0.31282916,  9.07914183, 11.20824938, ...,  2.71211683,\n",
       "           3.29515056, -0.38027456]]),\n",
       "  array([[-1.75573435e-01, -5.30930819e-01,  6.00469507e-01, ...,\n",
       "          -1.33687010e+02, -1.37540461e+02, -3.65350385e+00],\n",
       "         [ 2.48614083e-01, -1.07892624e+00, -4.57632245e-01, ...,\n",
       "          -4.87655813e-01, -4.69363106e+00,  1.07866992e+00],\n",
       "         [-9.03982308e-02,  3.58434427e+00,  4.31445337e+00, ...,\n",
       "           4.61523404e+01,  9.20408906e+00,  3.89367362e+00],\n",
       "         [-9.33887519e-02, -4.55256687e+00, -4.03753104e+00, ...,\n",
       "          -7.86498156e+00, -7.42576228e+00, -2.43435318e-02]]),\n",
       "  array([[ 2.52970060e-01,  1.01746832e+00,  1.17079798e+00, ...,\n",
       "           7.08446967e+01,  5.46007595e+01,  3.03245770e+01],\n",
       "         [ 3.55323399e-02, -3.51936271e+00, -4.24684439e+00, ...,\n",
       "          -5.38162315e+00, -4.42935613e+00, -2.89233548e-02],\n",
       "         [-2.22498326e-01, -1.93069475e+00, -1.08117600e+00, ...,\n",
       "          -1.66318629e+01, -2.06361291e+01,  1.04395773e+00],\n",
       "         [ 1.48158288e-01, -1.77809957e+00, -1.45155735e+00, ...,\n",
       "          -3.09108392e+00, -7.02002212e-01, -8.33704267e-02]]),\n",
       "  array([[  0.28067999,   5.01786947,   6.72434492, ..., -16.74981138,\n",
       "           -9.35142495,  -1.06381875],\n",
       "         [ -0.34447541,   0.81814283,   0.8705072 , ...,   1.45282936,\n",
       "            4.01492921,   0.13285181],\n",
       "         [ -0.11894031,  -0.13646147,  -0.34540942, ...,   0.24240911,\n",
       "           -0.06564157,  -0.3195351 ],\n",
       "         [ -0.2233174 ,   3.41599619,   3.46925423, ...,   8.71120473,\n",
       "            7.0501572 ,   0.4411246 ]]),\n",
       "  array([[ -0.61563631, -49.615515  , -57.18115374, ...,  -9.0286571 ,\n",
       "            1.31404222,  -0.96677615],\n",
       "         [  0.18505669, -10.34683969,  -6.34458928, ...,   7.66832065,\n",
       "            8.86587295,   0.53566298],\n",
       "         [ -0.08028494,   2.66787875,   2.86082078, ...,  12.51165678,\n",
       "            8.56733795,  -0.41834313],\n",
       "         [ -0.17062828,  -3.68746465,  -5.68357359, ...,   4.45364152,\n",
       "            4.19014975,   0.56674164]]),\n",
       "  array([[ -0.44253139,   3.68653917,   6.17622309, ...,   3.79040842,\n",
       "            3.16759689,  -2.08672603],\n",
       "         [  0.81752249,  -3.84977708,  -4.91519492, ..., -89.50343584,\n",
       "          -64.65901153,   2.02014618],\n",
       "         [  1.12642709,  -1.29999269,  -2.4090414 , ..., -43.77741798,\n",
       "          -39.31685308,   0.10901993],\n",
       "         [ -0.57794832,  -4.61998918,  -5.21331882, ...,   1.0788295 ,\n",
       "           -7.74785474,   0.1527334 ]])],\n",
       " 'trial_3': [array([[-2.81285471e-01, -2.80102954e+00, -6.49196868e+00, ...,\n",
       "          -3.53344831e+01, -2.60744936e+01, -7.95881872e-01],\n",
       "         [-3.57774137e-01,  7.97218385e-01,  2.40415204e+00, ...,\n",
       "           4.90428835e+01,  4.72429851e+01, -2.69521269e+00],\n",
       "         [-3.44359663e-01, -2.10871089e+00, -3.52739557e+00, ...,\n",
       "          -1.11159214e+01, -7.45925841e+00, -1.21033170e+00],\n",
       "         [ 1.13019602e-01,  1.82208876e+00,  1.90876018e+00, ...,\n",
       "           6.55106451e+00,  4.40053776e+00,  4.87368875e-04]]),\n",
       "  array([[  0.27114618,   5.82425996,   2.78406065, ...,  51.14446161,\n",
       "           49.79374475,   5.78595964],\n",
       "         [  0.142472  ,  -9.68238612, -10.84004053, ...,  16.83825394,\n",
       "           -6.17527531,  -1.12307888],\n",
       "         [  0.2261916 ,   0.44932622,  -0.86574375, ...,   0.33065465,\n",
       "           -0.17528108,  -0.52353601],\n",
       "         [  0.09134151,   1.85978608,   2.15428092, ...,   6.50997249,\n",
       "            5.48737038,  -0.61447138]]),\n",
       "  array([[ 0.93303868,  2.11698893,  4.20853364, ..., -4.65875738,\n",
       "          -2.27486501, -1.78074634],\n",
       "         [-0.10736557, -5.76324605, -9.47361414, ..., -3.30135595,\n",
       "          -1.31505604,  0.65242706],\n",
       "         [ 0.16579179, -4.61219775, -4.01274622, ...,  0.02995513,\n",
       "           2.79710835,  1.11363222],\n",
       "         [ 0.2057942 , -2.53408032, -4.36800921, ...,  5.24957582,\n",
       "           7.56295836,  0.46745614]]),\n",
       "  array([[ -0.13448021, -26.19338017, -30.478793  , ...,  17.39402282,\n",
       "            5.70843709,  -0.82858818],\n",
       "         [ -0.31414774,  -5.5064401 ,  -5.12140359, ...,  -2.48241901,\n",
       "           -4.27931504,   0.94906508],\n",
       "         [  0.09115839,   4.87644569,   4.60389231, ...,  19.59895051,\n",
       "           19.09918867,   1.30548091],\n",
       "         [  0.16788478,  -4.3005663 ,  -3.26677829, ...,  -2.64705358,\n",
       "           -3.97743535,   0.5454322 ]]),\n",
       "  array([[ 0.72772372, -4.97853346, -2.13093495, ...,  2.123064  ,\n",
       "           1.65300469, -0.4759337 ],\n",
       "         [-0.03141511, -2.9069953 , -2.67521211, ..., -2.97419145,\n",
       "          -6.0228361 , -0.08900635],\n",
       "         [-0.02219471, -1.63786135, -1.60784963, ...,  8.16232367,\n",
       "           9.41206011,  1.05972944],\n",
       "         [ 0.04995173, -6.00523003, -6.0966636 , ..., -3.61096062,\n",
       "          -4.05286343,  0.61560087]]),\n",
       "  array([[ -0.0283558 ,  -0.54213688,  -0.07350977, ...,   1.30614731,\n",
       "            0.66682469,   3.1492468 ],\n",
       "         [ -0.46228554,  -5.66747125,  -8.2773274 , ..., -11.28403636,\n",
       "          -13.88716382,   0.32765171],\n",
       "         [ -0.22416486,   4.76245002,   4.48343167, ...,  -2.83395614,\n",
       "           -2.28677131,   0.26572737],\n",
       "         [ -0.11451965,   3.04889513,   2.43137931, ...,  -9.6751866 ,\n",
       "           -7.83789618,  -0.1959526 ]]),\n",
       "  array([[  0.10232333,  -2.69748521,  -2.24981138, ...,  67.26247734,\n",
       "           56.49239383,   2.66563282],\n",
       "         [  0.49826994,  -5.15404643,  -5.33689818, ..., -13.29895965,\n",
       "          -16.07500034,  -0.76676463],\n",
       "         [ -0.2910385 ,  -0.39428683,   0.87667895, ...,  12.29342868,\n",
       "            8.8043443 ,   0.15507507],\n",
       "         [  0.26903536,  -2.5973059 ,  -1.43255297, ..., -11.29277312,\n",
       "          -10.29669743,  -0.163006  ]]),\n",
       "  array([[ -0.11609513,  -2.17035401,  -3.01718127, ...,  25.51561783,\n",
       "           40.94590653,  -1.13549902],\n",
       "         [ -0.11181073,   7.58206663,   7.81063794, ..., -33.87133874,\n",
       "           17.30872253,   2.13418933],\n",
       "         [  0.18292964,   2.45936322,   2.60793469, ...,  34.73312815,\n",
       "           29.76770388,  -3.92555835],\n",
       "         [ -0.38101716,   3.37221245,   2.08804709, ...,  45.39087041,\n",
       "           44.05384886,  -3.66204915]])]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = './datasets/topicos_cc'\n",
    "arquivos = os.listdir(dir)\n",
    "arq_numpy = [f for f in arquivos if f.endswith(\".npy\") and f.startswith('p2')]\n",
    "participantes = {}\n",
    "vetor = []\n",
    "for i in arq_numpy:\n",
    "    nome = i.split('_')\n",
    "    trial = np.load(dir+'/'+i)\n",
    "    for m in range(0,8):\n",
    "        if participantes.get(f'trial_{nome[1]}',0) == 0:\n",
    "            participantes[f'trial_{nome[1]}'] = []\n",
    "        dados = trial[m, :, :].swapaxes(0,1)\n",
    "        participantes[f'trial_{nome[1]}'].append(filtros(dados))\n",
    "        \n",
    "\n",
    "arr = np.vstack((np.array(participantes['trial_1']), np.array(participantes['trial_2']), np.array(participantes['trial_3'])))\n",
    "\n",
    "\n",
    "print(arr.shape)\n",
    "participantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (24, 4, 1600)\n",
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (24, 4, 125, 128) - (classes, ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (24, 4, 125, 65) - (classes, ensaios, canais, janelas, linhas)\n"
     ]
    }
   ],
   "source": [
    "step = 11.8\n",
    "segment = 128\n",
    "data = arr\n",
    "# .get_data()\n",
    "print('', data.shape)\n",
    "\n",
    "n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "ids = np.arange(n_win) * int(step)\n",
    "\n",
    "# Janelas do dado no dominio do tempo\n",
    "chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "# Janelas do dado no domínio da frequência\n",
    "_, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=115)\n",
    "chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "print(f'Dominio do tempo: {chunks_time.shape} - (classes, ensaios, canais, janelas, linhas)')\n",
    "print(f'Dominio da frequência:  {chunks_freq.shape} - (classes, ensaios, canais, janelas, linhas)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "\n",
    "# funções de extração de características\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape[:-1]) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape[:-1])))\n",
    "\n",
    "def wamp(x):\n",
    "    limiar = np.abs(np.diff(x))\n",
    "    return np.sum(limiar > 0.0001, axis=-1)\n",
    "\n",
    "def wl(x):\n",
    "    return np.sum(np.abs(np.diff(x)), axis=-1)\n",
    "\n",
    "\n",
    "def getzc(data, th):\n",
    "    t = len(data)\n",
    "    soma = 0\n",
    "    for i in range(t-1):\n",
    "        res = (data[i]*data[i+1])\n",
    "        res2 = np.abs(data[i]-data[i+1])\n",
    "        if (res<0 and res2 > th):\n",
    "            soma +=1\n",
    "    return soma\n",
    "\n",
    "def zc(data):\n",
    "    f=[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for i in range(x):\n",
    "        l = []\n",
    "        for j in range(y):\n",
    "            li = []\n",
    "            for k in range(z):\n",
    "                li.append(getzc(data[i][j][k], 0.0001))\n",
    "            l.append(li.copy())\n",
    "        f.append(l.copy())\n",
    "\n",
    "    return np.array(f)\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "\n",
    "def fmn(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*PSD(w)), axis=-1)/np.sum(PSD(w), axis=-1)\n",
    "\n",
    "def mmnf(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*np.abs(w)), axis=-1)/np.sum(np.abs(w), axis=-1)\n",
    "\n",
    "\n",
    "def logDec(data):\n",
    "    N = np.prod(data.shape)\n",
    "    return e ** (np.sum(np.log10(np.abs(data)), axis=-1))/N\n",
    "\n",
    "\n",
    "def iemg(x):\n",
    "    return np.sum(np.abs(x), axis=-1)\n",
    "\n",
    "def dasdv(x):\n",
    "    return np.sqrt(np.sum(np.diff(x)**2, axis=-1)/(np.prod(x.shape[:-1]) - 1))\n",
    "\n",
    "def tm(x,n):\n",
    "    return np.abs(np.sum(x**n , axis=-1)/np.prod(x.shape[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 24, 4, 125)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = list()\n",
    "final_data.append(var(chunks_time))\n",
    "final_data.append(rms(chunks_time))\n",
    "final_data.append(fmd(chunks_freq))\n",
    "final_data.append(mmdf(chunks_freq))\n",
    "final_data.append(logDec(chunks_time))\n",
    "final_data.append(wamp(chunks_time))\n",
    "final_data.append(wl(chunks_time))\n",
    "final_data.append(zc(chunks_time))\n",
    "final_data.append(fmn(chunks_freq))\n",
    "final_data.append(mmnf(chunks_freq))\n",
    "final_data.append(iemg(chunks_time))\n",
    "final_data.append(dasdv(chunks_time))\n",
    "\n",
    "for n in range(3,6):\n",
    "    final_data.append(tm(chunks_time, n))\n",
    "\n",
    "f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "final_data.append(Pxx_den)\n",
    "\n",
    "final = np.array(final_data)\n",
    "final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final.transpose(1,3,2,0)\n",
    "X = X.reshape(X.shape[0]*X.shape[1], X.shape[2]*X.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[i] * int(X.shape[0] / 8) for i in range(8)]\n",
    "y = np.array(y).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = []\n",
    "trial.append((X[:1000], y[:1000]))\n",
    "trial.append((X[1000:2000], y[1000:2000]))\n",
    "trial.append((X[2000:3000], y[2000:3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h):\n",
    "    loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' in s]\n",
    "    if len(loss_list) == 0:\n",
    "        print('Custo não está presente no histórico')\n",
    "        return\n",
    "    epochs = range(1, len(history.history[loss_list[0]]) + 1)\n",
    "    # Custo\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Custo [treinamento] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Custo [validação] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    plt.title('Custo')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Custo')\n",
    "    plt.legend()\n",
    "    # Acurácia\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Acurácia [treinamento] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Acurácia [validação] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    plt.title('Acurácia')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model):\n",
    "    j=0\n",
    "    scores = []\n",
    "    validations=[]\n",
    "    for i in combinations(trial, 2):\n",
    "        X_treino = np.vstack((i[0][0],i[1][0]))\n",
    "        X_teste = trial[j][0]\n",
    "\n",
    "        y_treino = np.vstack((i[0][1],i[1][1]))\n",
    "        y_treino= y_treino.reshape(y_treino.shape[0]*y_treino.shape[1])\n",
    "        y_teste = trial[j][1]\n",
    "\n",
    "\n",
    "        j+=1\n",
    "\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(\n",
    "        X_treino, y_treino, test_size=0.3, shuffle=True, stratify=y_treino)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_treino)\n",
    "\n",
    "        X_treino = scaler.transform(X_treino)\n",
    "        X_teste = scaler.transform(X_teste)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        history = model.fit(X_treino, y_treino, epochs=100, batch_size=15, validation_data=(X_val, y_val))\n",
    "        # plot_history(history)\n",
    "        predict_x=model.predict(X_val) \n",
    "        score=np.argmax(predict_x,axis=1)\n",
    "        scores.append(score)\n",
    "        validations.append(y_val)\n",
    "\n",
    "\n",
    "    # y_true =  np.vstack((trial[0][1],trial[1][1], trial[2][1]))\n",
    "    y_true =  np.vstack((validations[0],validations[1], validations[2]))\n",
    "    y_true= y_true.reshape(y_true.shape[0]*y_true.shape[1])\n",
    "    sc = np.vstack((scores[0], scores[1], scores[2]))\n",
    "    sc= sc.reshape(sc.shape[0]*sc.shape[1])\n",
    "\n",
    "    print('\\n\\nAcurácia: %0.2f%%' % (accuracy_score(y_true, sc) * 100))\n",
    "    print('Matriz de confusão:')\n",
    "    print(confusion_matrix(y_true, sc))\n",
    "    print()\n",
    "    print(classification_report(y_true, sc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 16:21:56.313335: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-16 16:21:56.313359: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-16 16:21:56.313377: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (luisotavio-Aspire5): /proc/driver/nvidia/version does not exist\n",
      "2022-06-16 16:21:56.313653: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 2ms/step - loss: 2.0064 - accuracy: 0.3150 - val_loss: 1.6263 - val_accuracy: 0.4333\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4984 - accuracy: 0.4786 - val_loss: 1.3589 - val_accuracy: 0.4933\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3173 - accuracy: 0.5329 - val_loss: 1.2479 - val_accuracy: 0.5767\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1993 - accuracy: 0.6186 - val_loss: 1.1419 - val_accuracy: 0.6533\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1518 - accuracy: 0.6500 - val_loss: 1.1396 - val_accuracy: 0.6233\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0862 - accuracy: 0.6950 - val_loss: 1.0958 - val_accuracy: 0.6250\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0668 - accuracy: 0.6986 - val_loss: 1.0199 - val_accuracy: 0.7083\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0325 - accuracy: 0.7029 - val_loss: 1.0310 - val_accuracy: 0.6967\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0006 - accuracy: 0.7357 - val_loss: 1.0132 - val_accuracy: 0.7067\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9901 - accuracy: 0.7336 - val_loss: 0.9911 - val_accuracy: 0.7367\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9325 - accuracy: 0.7664 - val_loss: 0.9492 - val_accuracy: 0.7233\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9203 - accuracy: 0.7593 - val_loss: 0.9475 - val_accuracy: 0.7300\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8901 - accuracy: 0.7821 - val_loss: 0.8955 - val_accuracy: 0.7867\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8819 - accuracy: 0.7979 - val_loss: 0.9153 - val_accuracy: 0.7433\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8571 - accuracy: 0.7957 - val_loss: 0.9592 - val_accuracy: 0.7150\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8647 - accuracy: 0.7929 - val_loss: 0.8892 - val_accuracy: 0.7900\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8537 - accuracy: 0.7929 - val_loss: 0.9019 - val_accuracy: 0.7550\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8368 - accuracy: 0.8043 - val_loss: 0.8659 - val_accuracy: 0.7617\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8068 - accuracy: 0.8186 - val_loss: 0.8809 - val_accuracy: 0.7917\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8097 - accuracy: 0.8164 - val_loss: 0.8491 - val_accuracy: 0.7867\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8208 - accuracy: 0.8143 - val_loss: 0.8010 - val_accuracy: 0.8133\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8117 - accuracy: 0.8136 - val_loss: 0.8058 - val_accuracy: 0.8083\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7643 - accuracy: 0.8421 - val_loss: 0.7921 - val_accuracy: 0.8183\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7843 - accuracy: 0.8150 - val_loss: 0.9666 - val_accuracy: 0.7817\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8171 - accuracy: 0.8243 - val_loss: 0.8889 - val_accuracy: 0.7867\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7927 - accuracy: 0.8214 - val_loss: 0.8052 - val_accuracy: 0.8067\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7569 - accuracy: 0.8507 - val_loss: 0.8112 - val_accuracy: 0.8233\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.8493 - val_loss: 0.7264 - val_accuracy: 0.8417\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7441 - accuracy: 0.8407 - val_loss: 0.7884 - val_accuracy: 0.8200\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7434 - accuracy: 0.8521 - val_loss: 0.7449 - val_accuracy: 0.8467\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7567 - accuracy: 0.8414 - val_loss: 0.8083 - val_accuracy: 0.7883\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7461 - accuracy: 0.8357 - val_loss: 0.8063 - val_accuracy: 0.8133\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7236 - accuracy: 0.8543 - val_loss: 0.7366 - val_accuracy: 0.8483\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.8593 - val_loss: 0.7382 - val_accuracy: 0.8500\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.8557 - val_loss: 0.8040 - val_accuracy: 0.8233\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7530 - accuracy: 0.8450 - val_loss: 0.7571 - val_accuracy: 0.8450\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.8636 - val_loss: 0.7794 - val_accuracy: 0.8167\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.8636 - val_loss: 0.7145 - val_accuracy: 0.8483\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.8643 - val_loss: 0.8139 - val_accuracy: 0.8283\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.8621 - val_loss: 0.7896 - val_accuracy: 0.7850\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.8650 - val_loss: 0.7256 - val_accuracy: 0.8550\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.8707 - val_loss: 0.7320 - val_accuracy: 0.8200\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.8779 - val_loss: 0.6868 - val_accuracy: 0.8650\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.8743 - val_loss: 0.6934 - val_accuracy: 0.8633\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7233 - accuracy: 0.8350 - val_loss: 0.7512 - val_accuracy: 0.8267\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.8550 - val_loss: 0.7457 - val_accuracy: 0.8367\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.8571 - val_loss: 0.6972 - val_accuracy: 0.8567\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.8843 - val_loss: 0.7516 - val_accuracy: 0.8250\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.8636 - val_loss: 0.7355 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7185 - accuracy: 0.8493 - val_loss: 0.7375 - val_accuracy: 0.8467\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7060 - accuracy: 0.8543 - val_loss: 0.7423 - val_accuracy: 0.8167\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.8621 - val_loss: 0.7157 - val_accuracy: 0.8483\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.8643 - val_loss: 0.6500 - val_accuracy: 0.8650\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.8721 - val_loss: 0.7418 - val_accuracy: 0.8200\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.8664 - val_loss: 0.7690 - val_accuracy: 0.8183\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.8614 - val_loss: 0.7028 - val_accuracy: 0.8617\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.8821 - val_loss: 0.6864 - val_accuracy: 0.8317\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.8786 - val_loss: 0.7219 - val_accuracy: 0.8067\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.8886 - val_loss: 0.6424 - val_accuracy: 0.8683\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.8650 - val_loss: 0.6502 - val_accuracy: 0.8483\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.8800 - val_loss: 0.7148 - val_accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.8457 - val_loss: 0.7744 - val_accuracy: 0.8183\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7072 - accuracy: 0.8507 - val_loss: 0.6973 - val_accuracy: 0.8433\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.8764 - val_loss: 0.6537 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.8657 - val_loss: 0.6738 - val_accuracy: 0.8533\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.8886 - val_loss: 0.6681 - val_accuracy: 0.8483\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.8807 - val_loss: 0.6433 - val_accuracy: 0.8583\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.8971 - val_loss: 0.6949 - val_accuracy: 0.8383\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.8729 - val_loss: 0.6893 - val_accuracy: 0.8217\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.8650 - val_loss: 0.6554 - val_accuracy: 0.8633\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.8786 - val_loss: 0.6351 - val_accuracy: 0.8600\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.8707 - val_loss: 0.6509 - val_accuracy: 0.8667\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.8786 - val_loss: 0.6091 - val_accuracy: 0.8733\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.8686 - val_loss: 0.5954 - val_accuracy: 0.8883\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.8729 - val_loss: 0.6661 - val_accuracy: 0.8683\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.8529 - val_loss: 0.6923 - val_accuracy: 0.8550\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.8936 - val_loss: 0.6439 - val_accuracy: 0.8350\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.8757 - val_loss: 0.6667 - val_accuracy: 0.8483\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.8693 - val_loss: 0.6422 - val_accuracy: 0.8683\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.8579 - val_loss: 0.8768 - val_accuracy: 0.7683\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.8621 - val_loss: 0.6675 - val_accuracy: 0.8467\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.8800 - val_loss: 0.6018 - val_accuracy: 0.8933\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.8800 - val_loss: 0.5989 - val_accuracy: 0.8767\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.8979 - val_loss: 0.5565 - val_accuracy: 0.9117\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.9064 - val_loss: 0.6903 - val_accuracy: 0.8133\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.8786 - val_loss: 0.6469 - val_accuracy: 0.8517\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.8736 - val_loss: 0.6348 - val_accuracy: 0.8633\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.8907 - val_loss: 0.5901 - val_accuracy: 0.8967\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5859 - accuracy: 0.8836 - val_loss: 0.6513 - val_accuracy: 0.8467\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.8793 - val_loss: 0.6675 - val_accuracy: 0.8517\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.8900 - val_loss: 0.6334 - val_accuracy: 0.8400\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.8821 - val_loss: 0.7907 - val_accuracy: 0.8450\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.8529 - val_loss: 0.6940 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.8971 - val_loss: 0.5955 - val_accuracy: 0.8783\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.8486 - val_loss: 0.6961 - val_accuracy: 0.8317\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.8729 - val_loss: 0.6042 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.8957 - val_loss: 0.5967 - val_accuracy: 0.8867\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.9050 - val_loss: 0.6280 - val_accuracy: 0.8500\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5506 - accuracy: 0.8914 - val_loss: 0.6069 - val_accuracy: 0.8733\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.8871 - val_loss: 0.5927 - val_accuracy: 0.8800\n",
      "19/19 [==============================] - 0s 643us/step\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.4089 - accuracy: 0.4121 - val_loss: 1.6304 - val_accuracy: 0.4783\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4508 - accuracy: 0.5629 - val_loss: 1.3890 - val_accuracy: 0.5967\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2573 - accuracy: 0.6271 - val_loss: 1.2180 - val_accuracy: 0.5983\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1526 - accuracy: 0.6586 - val_loss: 1.1527 - val_accuracy: 0.6500\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0383 - accuracy: 0.7086 - val_loss: 1.0267 - val_accuracy: 0.6850\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9658 - accuracy: 0.7221 - val_loss: 0.9617 - val_accuracy: 0.7033\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8868 - accuracy: 0.7600 - val_loss: 0.8825 - val_accuracy: 0.7633\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8394 - accuracy: 0.7879 - val_loss: 0.9207 - val_accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8159 - accuracy: 0.7893 - val_loss: 0.8051 - val_accuracy: 0.8200\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.8169 - accuracy: 0.8050 - val_loss: 0.8685 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7828 - accuracy: 0.8029 - val_loss: 0.7791 - val_accuracy: 0.8217\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.8214 - val_loss: 0.7909 - val_accuracy: 0.8117\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7447 - accuracy: 0.8193 - val_loss: 0.7913 - val_accuracy: 0.8100\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.8257 - val_loss: 0.7678 - val_accuracy: 0.8117\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.8393 - val_loss: 0.8438 - val_accuracy: 0.7717\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.8250 - val_loss: 0.7812 - val_accuracy: 0.8067\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7372 - accuracy: 0.8379 - val_loss: 0.8595 - val_accuracy: 0.7600\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7494 - accuracy: 0.8336 - val_loss: 0.7684 - val_accuracy: 0.8033\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.8500 - val_loss: 0.7584 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.8671 - val_loss: 0.7429 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.8536 - val_loss: 0.7415 - val_accuracy: 0.8300\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.8436 - val_loss: 0.7471 - val_accuracy: 0.8233\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.8729 - val_loss: 0.7088 - val_accuracy: 0.8183\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.8607 - val_loss: 0.7693 - val_accuracy: 0.7917\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.8529 - val_loss: 0.7779 - val_accuracy: 0.8167\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.8764 - val_loss: 0.6991 - val_accuracy: 0.8617\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.8650 - val_loss: 0.6727 - val_accuracy: 0.8550\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.8621 - val_loss: 0.6798 - val_accuracy: 0.8467\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.8793 - val_loss: 0.6705 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.8700 - val_loss: 0.6962 - val_accuracy: 0.8400\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.8679 - val_loss: 0.7378 - val_accuracy: 0.8167\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6195 - accuracy: 0.8771 - val_loss: 0.7245 - val_accuracy: 0.8167\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.8757 - val_loss: 0.7074 - val_accuracy: 0.8183\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.8571 - val_loss: 0.7175 - val_accuracy: 0.8317\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.8700 - val_loss: 0.6676 - val_accuracy: 0.8550\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.8829 - val_loss: 0.7151 - val_accuracy: 0.8250\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.8786 - val_loss: 0.5985 - val_accuracy: 0.8883\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.8764 - val_loss: 0.6841 - val_accuracy: 0.8383\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.8671 - val_loss: 0.7174 - val_accuracy: 0.8200\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.8636 - val_loss: 0.6487 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.8679 - val_loss: 0.6996 - val_accuracy: 0.8117\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6143 - accuracy: 0.8714 - val_loss: 0.6344 - val_accuracy: 0.8517\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.8679 - val_loss: 0.7623 - val_accuracy: 0.7950\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.8464 - val_loss: 0.6859 - val_accuracy: 0.8250\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.8864 - val_loss: 0.6625 - val_accuracy: 0.8350\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.8800 - val_loss: 0.8177 - val_accuracy: 0.7833\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.8800 - val_loss: 0.6753 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5544 - accuracy: 0.8986 - val_loss: 0.6556 - val_accuracy: 0.8483\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.8957 - val_loss: 0.6737 - val_accuracy: 0.8317\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.8843 - val_loss: 0.6367 - val_accuracy: 0.8633\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.8979 - val_loss: 0.6634 - val_accuracy: 0.8283\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.8564 - val_loss: 0.6096 - val_accuracy: 0.8800\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.8850 - val_loss: 0.6035 - val_accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.8793 - val_loss: 0.6542 - val_accuracy: 0.8400\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.8600 - val_loss: 0.6480 - val_accuracy: 0.8317\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.8957 - val_loss: 0.5832 - val_accuracy: 0.8817\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.8921 - val_loss: 0.6356 - val_accuracy: 0.8383\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.8736 - val_loss: 0.7069 - val_accuracy: 0.8117\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.9000 - val_loss: 0.6363 - val_accuracy: 0.8417\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.8900 - val_loss: 0.5848 - val_accuracy: 0.8750\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.9000 - val_loss: 0.5928 - val_accuracy: 0.8700\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.8993 - val_loss: 0.5897 - val_accuracy: 0.8800\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5463 - accuracy: 0.9029 - val_loss: 0.6336 - val_accuracy: 0.8417\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.8964 - val_loss: 0.6314 - val_accuracy: 0.8467\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.9007 - val_loss: 0.6178 - val_accuracy: 0.8617\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.9121 - val_loss: 0.6277 - val_accuracy: 0.8533\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.8943 - val_loss: 0.5897 - val_accuracy: 0.8700\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.8750 - val_loss: 0.6781 - val_accuracy: 0.8583\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.8886 - val_loss: 0.7062 - val_accuracy: 0.8217\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.9014 - val_loss: 0.6305 - val_accuracy: 0.8433\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.8800 - val_loss: 0.6599 - val_accuracy: 0.8367\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.8879 - val_loss: 0.5997 - val_accuracy: 0.8500\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.9029 - val_loss: 0.5984 - val_accuracy: 0.8617\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.9057 - val_loss: 0.5727 - val_accuracy: 0.8917\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.9057 - val_loss: 0.5963 - val_accuracy: 0.8600\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.9036 - val_loss: 0.6114 - val_accuracy: 0.8583\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.8721 - val_loss: 0.8480 - val_accuracy: 0.8383\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.8743 - val_loss: 0.6377 - val_accuracy: 0.8600\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.8893 - val_loss: 0.6641 - val_accuracy: 0.8417\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5388 - accuracy: 0.9064 - val_loss: 0.6287 - val_accuracy: 0.8517\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5338 - accuracy: 0.9036 - val_loss: 0.6667 - val_accuracy: 0.8467\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.8971 - val_loss: 0.6396 - val_accuracy: 0.8533\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.9029 - val_loss: 0.6508 - val_accuracy: 0.8400\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.9043 - val_loss: 0.5462 - val_accuracy: 0.9017\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.9136 - val_loss: 0.5577 - val_accuracy: 0.9017\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.9214 - val_loss: 0.5522 - val_accuracy: 0.8933\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.9243 - val_loss: 0.5906 - val_accuracy: 0.8717\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.9057 - val_loss: 0.6016 - val_accuracy: 0.8700\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.8814 - val_loss: 0.6694 - val_accuracy: 0.8317\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.8857 - val_loss: 0.5827 - val_accuracy: 0.8617\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.9007 - val_loss: 0.6094 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.8986 - val_loss: 0.5744 - val_accuracy: 0.8700\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.8979 - val_loss: 0.6374 - val_accuracy: 0.8667\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.9036 - val_loss: 0.6610 - val_accuracy: 0.8367\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.8950 - val_loss: 0.5936 - val_accuracy: 0.8617\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.9064 - val_loss: 0.6304 - val_accuracy: 0.8517\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.9229 - val_loss: 0.5571 - val_accuracy: 0.8833\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.9093 - val_loss: 0.5535 - val_accuracy: 0.8850\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.9043 - val_loss: 0.5457 - val_accuracy: 0.8967\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.9186 - val_loss: 0.6361 - val_accuracy: 0.8400\n",
      "19/19 [==============================] - 0s 696us/step\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.8615 - accuracy: 0.4164 - val_loss: 2.8863 - val_accuracy: 0.5617\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2509 - accuracy: 0.6057 - val_loss: 1.4023 - val_accuracy: 0.6483\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0533 - accuracy: 0.6857 - val_loss: 1.0025 - val_accuracy: 0.6950\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9716 - accuracy: 0.6957 - val_loss: 1.0173 - val_accuracy: 0.7067\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9187 - accuracy: 0.7193 - val_loss: 0.9543 - val_accuracy: 0.6783\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.7364 - val_loss: 0.9805 - val_accuracy: 0.7517\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7968 - accuracy: 0.7693 - val_loss: 0.9886 - val_accuracy: 0.7017\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7573 - accuracy: 0.7850 - val_loss: 1.0499 - val_accuracy: 0.7517\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.7850 - val_loss: 1.0665 - val_accuracy: 0.7700\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7565 - accuracy: 0.7786 - val_loss: 1.0742 - val_accuracy: 0.7617\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7270 - accuracy: 0.8150 - val_loss: 0.9252 - val_accuracy: 0.7767\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.8250 - val_loss: 0.9703 - val_accuracy: 0.8083\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.8157 - val_loss: 1.1536 - val_accuracy: 0.8083\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.8164 - val_loss: 0.9395 - val_accuracy: 0.8067\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.8379 - val_loss: 0.9281 - val_accuracy: 0.8083\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.8393 - val_loss: 0.8204 - val_accuracy: 0.8400\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.8343 - val_loss: 0.9820 - val_accuracy: 0.7983\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.8293 - val_loss: 0.8015 - val_accuracy: 0.8217\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.8236 - val_loss: 1.0244 - val_accuracy: 0.7917\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.8514 - val_loss: 1.0227 - val_accuracy: 0.8433\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.8686 - val_loss: 1.0207 - val_accuracy: 0.8383\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.8686 - val_loss: 0.7856 - val_accuracy: 0.8383\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.8471 - val_loss: 1.2029 - val_accuracy: 0.7983\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7567 - accuracy: 0.8214 - val_loss: 0.8172 - val_accuracy: 0.7967\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.8386 - val_loss: 0.8066 - val_accuracy: 0.8200\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.8664 - val_loss: 1.1827 - val_accuracy: 0.8383\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.8350 - val_loss: 1.1899 - val_accuracy: 0.8133\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.8607 - val_loss: 1.0713 - val_accuracy: 0.8317\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6172 - accuracy: 0.8707 - val_loss: 0.9237 - val_accuracy: 0.8050\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.8671 - val_loss: 1.2346 - val_accuracy: 0.7167\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6205 - accuracy: 0.8643 - val_loss: 0.7427 - val_accuracy: 0.8600\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.8850 - val_loss: 0.7584 - val_accuracy: 0.8483\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.8714 - val_loss: 0.8452 - val_accuracy: 0.8633\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.8693 - val_loss: 0.8758 - val_accuracy: 0.8600\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5964 - accuracy: 0.8743 - val_loss: 1.4028 - val_accuracy: 0.7833\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.8607 - val_loss: 0.8174 - val_accuracy: 0.8233\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.8600 - val_loss: 0.7491 - val_accuracy: 0.8300\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.8836 - val_loss: 0.7957 - val_accuracy: 0.8633\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.8793 - val_loss: 1.0138 - val_accuracy: 0.8083\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.8714 - val_loss: 0.7047 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6027 - accuracy: 0.8793 - val_loss: 0.8595 - val_accuracy: 0.8250\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.8664 - val_loss: 0.7042 - val_accuracy: 0.8533\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.8764 - val_loss: 0.8420 - val_accuracy: 0.8567\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.8871 - val_loss: 1.0238 - val_accuracy: 0.8717\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6192 - accuracy: 0.8600 - val_loss: 0.7522 - val_accuracy: 0.8600\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6411 - accuracy: 0.8521 - val_loss: 0.8961 - val_accuracy: 0.8417\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.8793 - val_loss: 0.9732 - val_accuracy: 0.8633\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.8907 - val_loss: 0.8670 - val_accuracy: 0.8650\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.9079 - val_loss: 0.7483 - val_accuracy: 0.8400\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5463 - accuracy: 0.8836 - val_loss: 0.7088 - val_accuracy: 0.8700\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.8814 - val_loss: 1.5800 - val_accuracy: 0.8250\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6080 - accuracy: 0.8636 - val_loss: 0.8568 - val_accuracy: 0.8333\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5850 - accuracy: 0.8779 - val_loss: 0.7649 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.8743 - val_loss: 0.8678 - val_accuracy: 0.8317\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.8779 - val_loss: 1.1715 - val_accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.8886 - val_loss: 0.8582 - val_accuracy: 0.8583\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5579 - accuracy: 0.8857 - val_loss: 1.0808 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.8964 - val_loss: 0.7106 - val_accuracy: 0.8350\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7085 - accuracy: 0.8207 - val_loss: 1.3559 - val_accuracy: 0.7833\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.8393 - val_loss: 0.7391 - val_accuracy: 0.8350\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6159 - accuracy: 0.8707 - val_loss: 1.4080 - val_accuracy: 0.8467\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.8857 - val_loss: 0.8558 - val_accuracy: 0.8650\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.8943 - val_loss: 0.7725 - val_accuracy: 0.8367\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.8836 - val_loss: 2.4018 - val_accuracy: 0.7567\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6185 - accuracy: 0.8700 - val_loss: 1.0865 - val_accuracy: 0.8567\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.8807 - val_loss: 1.7681 - val_accuracy: 0.8450\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.8814 - val_loss: 1.0651 - val_accuracy: 0.8683\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.8943 - val_loss: 1.0008 - val_accuracy: 0.8683\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.9086 - val_loss: 0.5891 - val_accuracy: 0.8733\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.8857 - val_loss: 0.6567 - val_accuracy: 0.8617\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5746 - accuracy: 0.8914 - val_loss: 0.9763 - val_accuracy: 0.8367\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5798 - accuracy: 0.8836 - val_loss: 0.5998 - val_accuracy: 0.8717\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.8900 - val_loss: 0.6350 - val_accuracy: 0.8583\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.8843 - val_loss: 0.6780 - val_accuracy: 0.8400\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.8807 - val_loss: 0.6775 - val_accuracy: 0.8400\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.8686 - val_loss: 0.6770 - val_accuracy: 0.8450\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.8914 - val_loss: 0.5922 - val_accuracy: 0.8717\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.9057 - val_loss: 0.5647 - val_accuracy: 0.8683\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.9086 - val_loss: 0.5402 - val_accuracy: 0.8900\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7318 - accuracy: 0.8457 - val_loss: 0.8290 - val_accuracy: 0.7917\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.8864 - val_loss: 0.6270 - val_accuracy: 0.8567\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.8957 - val_loss: 0.7157 - val_accuracy: 0.8033\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.9157 - val_loss: 0.5340 - val_accuracy: 0.9150\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.8886 - val_loss: 0.5591 - val_accuracy: 0.8850\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.8836 - val_loss: 0.7611 - val_accuracy: 0.8550\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.8771 - val_loss: 0.6035 - val_accuracy: 0.8650\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.9036 - val_loss: 0.6149 - val_accuracy: 0.8517\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.8986 - val_loss: 0.6166 - val_accuracy: 0.8617\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.8871 - val_loss: 0.5263 - val_accuracy: 0.9033\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.9000 - val_loss: 0.6070 - val_accuracy: 0.8717\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.9143 - val_loss: 0.6060 - val_accuracy: 0.8717\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.9093 - val_loss: 0.7047 - val_accuracy: 0.8567\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5198 - accuracy: 0.9014 - val_loss: 0.5711 - val_accuracy: 0.8833\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.9157 - val_loss: 0.8725 - val_accuracy: 0.8267\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.9029 - val_loss: 0.6180 - val_accuracy: 0.8533\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.9114 - val_loss: 0.5788 - val_accuracy: 0.8717\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5476 - accuracy: 0.8907 - val_loss: 0.6299 - val_accuracy: 0.8467\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6356 - accuracy: 0.8514 - val_loss: 0.6068 - val_accuracy: 0.8800\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.8929 - val_loss: 0.7791 - val_accuracy: 0.8617\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.8936 - val_loss: 0.7290 - val_accuracy: 0.8717\n",
      "19/19 [==============================] - 0s 587us/step\n",
      "\n",
      "\n",
      "Acurácia: 86.39%\n",
      "Matriz de confusão:\n",
      "[[178   2  15   9   1  14   1   5]\n",
      " [  0 188  10   5   3   3   6  10]\n",
      " [  8   9 201   0   3   2   0   1]\n",
      " [  4   1   0 204   2   9   3   3]\n",
      " [  3   5   1   7 184   2  11  12]\n",
      " [  0   3   1   1   2 199   6  12]\n",
      " [  0   1   0   4   3   7 207   3]\n",
      " [  3   4  12   2   0   5   6 194]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.90816   0.79111   0.84561       225\n",
      "           1    0.88263   0.83556   0.85845       225\n",
      "           2    0.83750   0.89732   0.86638       224\n",
      "           3    0.87931   0.90265   0.89083       226\n",
      "           4    0.92929   0.81778   0.86998       225\n",
      "           5    0.82573   0.88839   0.85591       224\n",
      "           6    0.86250   0.92000   0.89032       225\n",
      "           7    0.80833   0.85841   0.83262       226\n",
      "\n",
      "    accuracy                        0.86389      1800\n",
      "   macro avg    0.86668   0.86390   0.86376      1800\n",
      "weighted avg    0.86670   0.86389   0.86376      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definição de uma fração do regularizador\n",
    "l = 0.01\n",
    "\n",
    "# desenvolvimento do modelo Keras para uma MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=64,\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Aplicação de um modelo de descida de gradiente utilizando o Stocastic Gradient Descendent (SGD)\n",
    "sgd = SGD(lr=0.05, momentum=0.0)\n",
    "# Função de otimização da rede: ADAM\n",
    "adam = Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\n",
    "# Função de custo baseada em dados originalmente categóricos\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  \n",
    "cross_val(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val2(model):\n",
    "    j=0\n",
    "    scores = []\n",
    "    validations = []\n",
    "    for i in combinations(trial, 2):\n",
    "        X_treino = np.vstack((i[0][0],i[1][0]))\n",
    "        X_teste = trial[j][0]\n",
    "\n",
    "        y_treino = np.vstack((i[0][1],i[1][1]))\n",
    "        y_treino= y_treino.reshape(y_treino.shape[0]*y_treino.shape[1])\n",
    "        y_teste = trial[j][1]\n",
    "\n",
    "\n",
    "        j+=1\n",
    "\n",
    "        X_treino, X_val, y_treino, y_val = train_test_split(\n",
    "        X_treino, y_treino, test_size=0.3, shuffle=True, stratify=y_treino)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_treino)\n",
    "\n",
    "        X_treino = scaler.transform(X_treino)\n",
    "        X_teste = scaler.transform(X_teste)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        history = model.fit(X_treino, y_treino)\n",
    "        # plot_history(history)\n",
    "        predict_x=model.predict(X_val) \n",
    "        # print(predict_x)\n",
    "        # print(predict_x.shape)\n",
    "        # score=np.argmax(predict_x)\n",
    "        # score=np.argmax(predict_x,axis=1)\n",
    "        # scores.append(score)\n",
    "        scores.append(predict_x)\n",
    "        validations.append(y_val)\n",
    "\n",
    "    y_true =  np.vstack((validations[0],validations[1], validations[2]))\n",
    "    y_true= y_true.reshape(y_true.shape[0]*y_true.shape[1])\n",
    "    sc = np.vstack((scores[0], scores[1], scores[2]))\n",
    "    sc= sc.reshape(sc.shape[0]*sc.shape[1])\n",
    "\n",
    "    print('\\n\\nAcurácia: %0.2f%%' % (accuracy_score(y_true, sc) * 100))\n",
    "    print('Matriz de confusão:')\n",
    "    print(confusion_matrix(y_true, sc))\n",
    "    print()\n",
    "    print(classification_report(y_true, sc, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Acurácia: 67.33%\n",
      "Matriz de confusão:\n",
      "[[169  17  19   8   4   2   4   2]\n",
      " [  1 120  13  28  15   0  37  12]\n",
      " [  8  18 151   4  20  13   0  11]\n",
      " [  8   4   8 157   5   9  33   1]\n",
      " [  5  19   5  26 126   2  28  14]\n",
      " [ 12   3   8  12   2 138  36  13]\n",
      " [  0   1   0   4   0   2 213   5]\n",
      " [ 10  11  10  10  17  13  16 138]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.79343   0.75111   0.77169       225\n",
      "           1    0.62176   0.53097   0.57279       226\n",
      "           2    0.70561   0.67111   0.68793       225\n",
      "           3    0.63052   0.69778   0.66245       225\n",
      "           4    0.66667   0.56000   0.60870       225\n",
      "           5    0.77095   0.61607   0.68486       224\n",
      "           6    0.58038   0.94667   0.71959       225\n",
      "           7    0.70408   0.61333   0.65558       225\n",
      "\n",
      "    accuracy                        0.67333      1800\n",
      "   macro avg    0.68417   0.67338   0.67045      1800\n",
      "weighted avg    0.68409   0.67333   0.67039      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# modelo de classificador com os parâmetros padrões\n",
    "clf = SVC(gamma='scale')\n",
    "\n",
    "# criando o modelo de classificação com os dados de treino\n",
    "cross_val2(clf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
