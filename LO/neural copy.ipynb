{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 00:03:05.033451: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-09 00:03:05.037095: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-09 00:03:05.037106: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import stft\n",
    "from math import prod\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from math import e\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(data, lowcut, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_lowpass(data, lowcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    b, a = signal.butter(order, low, btype='lowpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_highpass(data, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, high, btype='highpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_notch(data, cutoff, var=1, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = (cutoff - var) / nyq\n",
    "    high = (cutoff + var) / nyq\n",
    "    b, a = signal.iirfilter(order, [low, high], btype='bandstop', ftype=\"butter\")\n",
    "    return signal.filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtros(data):\n",
    "    data_filtered = butter_notch(data, 60)\n",
    "    data_filtered = butter_highpass(data_filtered, 5)\n",
    "    data_filtered = butter_lowpass(data_filtered, 50)\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4, 1600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'trial_2': [array([[  0.29706151,  -0.10758804,   1.23396836, ..., -38.45522264,\n",
       "          -17.73104717,   0.81996573],\n",
       "         [  0.08937505,  -7.59702407,  -5.33727604, ...,  30.65703983,\n",
       "           39.85397463,  -4.36759111],\n",
       "         [ -0.37811694,   0.44031343,   3.97210754, ...,  14.22481131,\n",
       "           26.12198471,   2.06869271],\n",
       "         [  0.08187095,   2.26459197,   3.72874838, ...,  -5.42794101,\n",
       "           -2.58438479,  -0.51082867]]),\n",
       "  array([[-1.73949608e-01, -1.42606709e+01, -1.55178994e+01, ...,\n",
       "          -5.04905317e+01, -4.19364713e+01,  9.20553298e+00],\n",
       "         [ 3.61063262e-02,  3.88964943e+00,  2.20453159e+00, ...,\n",
       "           7.98866294e+01,  7.50537834e+01, -2.10478914e-01],\n",
       "         [ 4.99892252e-02, -5.66187924e+00, -9.97914406e+00, ...,\n",
       "           2.21823731e+00,  8.47436948e-01,  3.28411724e-01],\n",
       "         [ 2.29972170e-02,  3.26872918e+00,  4.23690585e+00, ...,\n",
       "          -6.01274568e+00, -2.61444681e+00, -1.98066580e-01]]),\n",
       "  array([[  0.11907216,   3.39327291,   2.87792021, ...,   2.36730454,\n",
       "            2.83147253,   0.27363561],\n",
       "         [ -0.03321934,  -0.28832491,  -1.32475959, ..., -29.91814872,\n",
       "          -24.2894814 ,  -1.79250764],\n",
       "         [ -0.31780254,   4.7769454 ,   5.42556806, ...,  -0.76465945,\n",
       "           -1.47441007,  -1.0878036 ],\n",
       "         [ -0.17604392,   2.7049608 ,   1.27191785, ...,   0.2172488 ,\n",
       "           -0.69967462,   0.62342211]]),\n",
       "  array([[  0.13015503,  -6.07456144, -10.58212388, ...,  -3.12952408,\n",
       "            0.05870249,  -5.51005583],\n",
       "         [ -0.18673174,  -4.0766338 ,  -3.41135502, ...,  -8.64006182,\n",
       "           -5.19652824,  -0.56677434],\n",
       "         [ -0.18309174,   4.28533017,   4.71060827, ...,   7.55307413,\n",
       "           -8.37883099,   3.01461066],\n",
       "         [  0.13600279,   1.15988806,  -0.47830233, ...,  -1.02957885,\n",
       "           -0.10011682,  -0.95606915]]),\n",
       "  array([[-4.07935093e-01, -1.32583872e+01, -1.38436424e+01, ...,\n",
       "           1.48796104e+01,  2.19082822e+01,  3.91290750e+00],\n",
       "         [-4.83442261e-01, -5.65756962e+00, -7.56262291e+00, ...,\n",
       "          -5.77993941e+00, -4.80674024e+00,  1.64985959e-01],\n",
       "         [ 2.04836035e-02,  3.75828196e+00,  5.36145479e+00, ...,\n",
       "          -3.21509852e+01, -3.14892145e+01,  1.03164241e+00],\n",
       "         [-4.09539647e-01,  8.48119304e+00,  8.17636863e+00, ...,\n",
       "           8.66193277e+00,  7.83824357e+00,  3.74792827e-01]]),\n",
       "  array([[  0.526426  ,   6.73231426,  10.14742838, ...,  61.77159536,\n",
       "           50.28913114,  -2.28147377],\n",
       "         [  0.12371896,   3.1112256 ,   3.76837648, ..., -25.99265294,\n",
       "          -19.97899125,  -4.64048123],\n",
       "         [ -0.43283801,   0.9612428 ,  -0.13932282, ...,  -5.53523799,\n",
       "           -5.65779377,  -1.12088234],\n",
       "         [ -0.06383116,   3.297932  ,   0.68785391, ...,  -9.07897429,\n",
       "           -9.27164231,   1.4829658 ]]),\n",
       "  array([[-1.35929163e+00,  9.98726433e+00,  1.15559578e+01, ...,\n",
       "          -1.03807401e+01, -2.79689529e+01, -3.52171560e+00],\n",
       "         [-2.93026744e-01, -2.06543971e+01, -2.09251146e+01, ...,\n",
       "          -2.74645548e+00, -7.15913914e+00, -4.98846545e-01],\n",
       "         [ 9.26280905e-03,  1.94671472e+00,  1.63208607e+00, ...,\n",
       "           1.65778333e+01,  1.68860205e+01,  9.50493697e-01],\n",
       "         [-5.48388744e-01,  6.52132862e-01,  2.71222967e-01, ...,\n",
       "           2.33546589e+00,  1.86384677e-01, -1.20190343e+00]]),\n",
       "  array([[ 3.10680345e-01,  4.95113186e+00,  6.54289473e+00, ...,\n",
       "           3.59800909e+01,  1.57211925e-01,  2.08621851e+00],\n",
       "         [ 2.95376974e-01,  2.02508619e+00, -4.90717511e+00, ...,\n",
       "          -9.80730667e+01, -1.12237025e+02, -1.06883701e+01],\n",
       "         [ 1.09516428e-01, -5.11575359e-02,  7.10090281e-01, ...,\n",
       "           2.13750254e+01,  1.57751671e+01,  3.57118508e-01],\n",
       "         [ 3.98687972e-01,  7.96715654e+00,  8.04687506e+00, ...,\n",
       "          -1.49346990e+01,  7.06377784e+00,  1.52789836e+01]])],\n",
       " 'trial_1': [array([[ 8.86971424e-01,  2.75032326e+00,  7.30910660e-01, ...,\n",
       "           3.20848183e+01,  2.63629669e+01, -9.70162171e-01],\n",
       "         [ 1.14110323e-02, -1.25572281e+00, -7.87835958e-01, ...,\n",
       "          -4.27222536e+01, -4.59572418e+01,  1.14632761e+01],\n",
       "         [ 3.04300771e-02, -5.78062191e-01, -2.73157842e+00, ...,\n",
       "           1.45374873e+01,  5.37522607e+00,  9.25156851e-01],\n",
       "         [ 3.77486366e-01, -3.28394203e-01,  1.61014470e+00, ...,\n",
       "           6.65025614e+00,  3.81722011e+00,  7.66291046e-01]]),\n",
       "  array([[  0.87895261,  10.83082549,   7.94568282, ...,   2.22737428,\n",
       "          -16.57643156,   2.31425458],\n",
       "         [  1.61366433,   7.03969846,   5.07326019, ...,  -0.69471828,\n",
       "          -23.59994116,  -8.64044464],\n",
       "         [ -0.09501406,   3.64290801,   5.49207298, ...,  -1.50448432,\n",
       "           -1.98745328,   0.3716078 ],\n",
       "         [  1.40265117,   0.60873325,  -2.13356858, ..., -23.8279123 ,\n",
       "          -19.16239428,  -0.61128691]]),\n",
       "  array([[ 0.40246225, 11.38863356, 15.26006936, ..., 11.14502708,\n",
       "          17.69077235, -6.93840439],\n",
       "         [-0.22134116,  4.24184954,  3.71249999, ..., 22.83217741,\n",
       "          21.8168833 ,  0.10476536],\n",
       "         [ 0.28457403,  3.56112214,  1.97702901, ..., 10.17736237,\n",
       "          10.23530824, -1.2490714 ],\n",
       "         [ 0.31282916,  9.07914183, 11.20824938, ...,  2.71211683,\n",
       "           3.29515056, -0.38027456]]),\n",
       "  array([[-1.75573435e-01, -5.30930819e-01,  6.00469507e-01, ...,\n",
       "          -1.33687010e+02, -1.37540461e+02, -3.65350385e+00],\n",
       "         [ 2.48614083e-01, -1.07892624e+00, -4.57632245e-01, ...,\n",
       "          -4.87655813e-01, -4.69363106e+00,  1.07866992e+00],\n",
       "         [-9.03982308e-02,  3.58434427e+00,  4.31445337e+00, ...,\n",
       "           4.61523404e+01,  9.20408906e+00,  3.89367362e+00],\n",
       "         [-9.33887519e-02, -4.55256687e+00, -4.03753104e+00, ...,\n",
       "          -7.86498156e+00, -7.42576228e+00, -2.43435318e-02]]),\n",
       "  array([[ 2.52970060e-01,  1.01746832e+00,  1.17079798e+00, ...,\n",
       "           7.08446967e+01,  5.46007595e+01,  3.03245770e+01],\n",
       "         [ 3.55323399e-02, -3.51936271e+00, -4.24684439e+00, ...,\n",
       "          -5.38162315e+00, -4.42935613e+00, -2.89233548e-02],\n",
       "         [-2.22498326e-01, -1.93069475e+00, -1.08117600e+00, ...,\n",
       "          -1.66318629e+01, -2.06361291e+01,  1.04395773e+00],\n",
       "         [ 1.48158288e-01, -1.77809957e+00, -1.45155735e+00, ...,\n",
       "          -3.09108392e+00, -7.02002212e-01, -8.33704267e-02]]),\n",
       "  array([[  0.28067999,   5.01786947,   6.72434492, ..., -16.74981138,\n",
       "           -9.35142495,  -1.06381875],\n",
       "         [ -0.34447541,   0.81814283,   0.8705072 , ...,   1.45282936,\n",
       "            4.01492921,   0.13285181],\n",
       "         [ -0.11894031,  -0.13646147,  -0.34540942, ...,   0.24240911,\n",
       "           -0.06564157,  -0.3195351 ],\n",
       "         [ -0.2233174 ,   3.41599619,   3.46925423, ...,   8.71120473,\n",
       "            7.0501572 ,   0.4411246 ]]),\n",
       "  array([[ -0.61563631, -49.615515  , -57.18115374, ...,  -9.0286571 ,\n",
       "            1.31404222,  -0.96677615],\n",
       "         [  0.18505669, -10.34683969,  -6.34458928, ...,   7.66832065,\n",
       "            8.86587295,   0.53566298],\n",
       "         [ -0.08028494,   2.66787875,   2.86082078, ...,  12.51165678,\n",
       "            8.56733795,  -0.41834313],\n",
       "         [ -0.17062828,  -3.68746465,  -5.68357359, ...,   4.45364152,\n",
       "            4.19014975,   0.56674164]]),\n",
       "  array([[ -0.44253139,   3.68653917,   6.17622309, ...,   3.79040842,\n",
       "            3.16759689,  -2.08672603],\n",
       "         [  0.81752249,  -3.84977708,  -4.91519492, ..., -89.50343584,\n",
       "          -64.65901153,   2.02014618],\n",
       "         [  1.12642709,  -1.29999269,  -2.4090414 , ..., -43.77741798,\n",
       "          -39.31685308,   0.10901993],\n",
       "         [ -0.57794832,  -4.61998918,  -5.21331882, ...,   1.0788295 ,\n",
       "           -7.74785474,   0.1527334 ]])],\n",
       " 'trial_3': [array([[-2.81285471e-01, -2.80102954e+00, -6.49196868e+00, ...,\n",
       "          -3.53344831e+01, -2.60744936e+01, -7.95881872e-01],\n",
       "         [-3.57774137e-01,  7.97218385e-01,  2.40415204e+00, ...,\n",
       "           4.90428835e+01,  4.72429851e+01, -2.69521269e+00],\n",
       "         [-3.44359663e-01, -2.10871089e+00, -3.52739557e+00, ...,\n",
       "          -1.11159214e+01, -7.45925841e+00, -1.21033170e+00],\n",
       "         [ 1.13019602e-01,  1.82208876e+00,  1.90876018e+00, ...,\n",
       "           6.55106451e+00,  4.40053776e+00,  4.87368875e-04]]),\n",
       "  array([[  0.27114618,   5.82425996,   2.78406065, ...,  51.14446161,\n",
       "           49.79374475,   5.78595964],\n",
       "         [  0.142472  ,  -9.68238612, -10.84004053, ...,  16.83825394,\n",
       "           -6.17527531,  -1.12307888],\n",
       "         [  0.2261916 ,   0.44932622,  -0.86574375, ...,   0.33065465,\n",
       "           -0.17528108,  -0.52353601],\n",
       "         [  0.09134151,   1.85978608,   2.15428092, ...,   6.50997249,\n",
       "            5.48737038,  -0.61447138]]),\n",
       "  array([[ 0.93303868,  2.11698893,  4.20853364, ..., -4.65875738,\n",
       "          -2.27486501, -1.78074634],\n",
       "         [-0.10736557, -5.76324605, -9.47361414, ..., -3.30135595,\n",
       "          -1.31505604,  0.65242706],\n",
       "         [ 0.16579179, -4.61219775, -4.01274622, ...,  0.02995513,\n",
       "           2.79710835,  1.11363222],\n",
       "         [ 0.2057942 , -2.53408032, -4.36800921, ...,  5.24957582,\n",
       "           7.56295836,  0.46745614]]),\n",
       "  array([[ -0.13448021, -26.19338017, -30.478793  , ...,  17.39402282,\n",
       "            5.70843709,  -0.82858818],\n",
       "         [ -0.31414774,  -5.5064401 ,  -5.12140359, ...,  -2.48241901,\n",
       "           -4.27931504,   0.94906508],\n",
       "         [  0.09115839,   4.87644569,   4.60389231, ...,  19.59895051,\n",
       "           19.09918867,   1.30548091],\n",
       "         [  0.16788478,  -4.3005663 ,  -3.26677829, ...,  -2.64705358,\n",
       "           -3.97743535,   0.5454322 ]]),\n",
       "  array([[ 0.72772372, -4.97853346, -2.13093495, ...,  2.123064  ,\n",
       "           1.65300469, -0.4759337 ],\n",
       "         [-0.03141511, -2.9069953 , -2.67521211, ..., -2.97419145,\n",
       "          -6.0228361 , -0.08900635],\n",
       "         [-0.02219471, -1.63786135, -1.60784963, ...,  8.16232367,\n",
       "           9.41206011,  1.05972944],\n",
       "         [ 0.04995173, -6.00523003, -6.0966636 , ..., -3.61096062,\n",
       "          -4.05286343,  0.61560087]]),\n",
       "  array([[ -0.0283558 ,  -0.54213688,  -0.07350977, ...,   1.30614731,\n",
       "            0.66682469,   3.1492468 ],\n",
       "         [ -0.46228554,  -5.66747125,  -8.2773274 , ..., -11.28403636,\n",
       "          -13.88716382,   0.32765171],\n",
       "         [ -0.22416486,   4.76245002,   4.48343167, ...,  -2.83395614,\n",
       "           -2.28677131,   0.26572737],\n",
       "         [ -0.11451965,   3.04889513,   2.43137931, ...,  -9.6751866 ,\n",
       "           -7.83789618,  -0.1959526 ]]),\n",
       "  array([[  0.10232333,  -2.69748521,  -2.24981138, ...,  67.26247734,\n",
       "           56.49239383,   2.66563282],\n",
       "         [  0.49826994,  -5.15404643,  -5.33689818, ..., -13.29895965,\n",
       "          -16.07500034,  -0.76676463],\n",
       "         [ -0.2910385 ,  -0.39428683,   0.87667895, ...,  12.29342868,\n",
       "            8.8043443 ,   0.15507507],\n",
       "         [  0.26903536,  -2.5973059 ,  -1.43255297, ..., -11.29277312,\n",
       "          -10.29669743,  -0.163006  ]]),\n",
       "  array([[ -0.11609513,  -2.17035401,  -3.01718127, ...,  25.51561783,\n",
       "           40.94590653,  -1.13549902],\n",
       "         [ -0.11181073,   7.58206663,   7.81063794, ..., -33.87133874,\n",
       "           17.30872253,   2.13418933],\n",
       "         [  0.18292964,   2.45936322,   2.60793469, ...,  34.73312815,\n",
       "           29.76770388,  -3.92555835],\n",
       "         [ -0.38101716,   3.37221245,   2.08804709, ...,  45.39087041,\n",
       "           44.05384886,  -3.66204915]])]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = './datasets/topicos_cc'\n",
    "arquivos = os.listdir(dir)\n",
    "arq_numpy = [f for f in arquivos if f.endswith(\".npy\") and f.startswith('p2')]\n",
    "participantes = {}\n",
    "vetor = []\n",
    "for i in arq_numpy:\n",
    "    nome = i.split('_')\n",
    "    trial = np.load(dir+'/'+i)\n",
    "    for m in range(0,8):\n",
    "        if participantes.get(f'trial_{nome[1]}',0) == 0:\n",
    "            participantes[f'trial_{nome[1]}'] = []\n",
    "        # if participantes[f'participante_{nome[0]}'].get(f'trial_{nome[1]}',0) == 0:\n",
    "        #     participantes[f'participante_{nome[0]}'][f'trial_{nome[1]}'] = {}\n",
    "        dados = trial[m, :, :].swapaxes(0,1)\n",
    "        participantes[f'trial_{nome[1]}'].append(filtros(dados))\n",
    "        # participantes[f'participante_{nome[0]}'][f'trial_{nome[1]}'][f'movimento_{m+1}'] = filtros(dados)\n",
    "        # vetor.append(filtros(dados))\n",
    "        # print(f'participante_{nome[0]} trial_{nome[1]} movimento_{m+1}')\n",
    "        # print(np.array(filtros(dados)).shape)\n",
    "        \n",
    "\n",
    "# participantes\n",
    "# np.array(participantes).shape\n",
    "\n",
    "arr = np.vstack((np.array(participantes['trial_1']), np.array(participantes['trial_2']), np.array(participantes['trial_3'])))\n",
    "    \n",
    "\n",
    "# v = list()\n",
    "# for i in arq_numpy:\n",
    "#     trial = np.load(dir+'/'+i)\n",
    "#     v.append(trial[:, :, :].swapaxes(1,2))    \n",
    "\n",
    "# arr = np.vstack((v[0], v[1], v[2]))\n",
    "\n",
    "print(arr.shape)\n",
    "participantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (24, 4, 1600)\n",
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (24, 4, 125, 128) - (classes, ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (24, 4, 125, 65) - (classes, ensaios, canais, janelas, linhas)\n"
     ]
    }
   ],
   "source": [
    "step = 11.8\n",
    "segment = 128\n",
    "data = arr\n",
    "# .get_data()\n",
    "print('', data.shape)\n",
    "\n",
    "n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "ids = np.arange(n_win) * int(step)\n",
    "\n",
    "# Janelas do dado no dominio do tempo\n",
    "chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "# Janelas do dado no domínio da frequência\n",
    "_, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=115)\n",
    "chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "print(f'Dominio do tempo: {chunks_time.shape} - (classes, ensaios, canais, janelas, linhas)')\n",
    "print(f'Dominio da frequência:  {chunks_freq.shape} - (classes, ensaios, canais, janelas, linhas)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "\n",
    "# funções de extração de características\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape[:-1]) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape[:-1])))\n",
    "\n",
    "def wamp(x):\n",
    "    limiar = np.abs(np.diff(x))\n",
    "    return np.sum(limiar > 0.0001, axis=-1)\n",
    "\n",
    "def wl(x):\n",
    "    return np.sum(np.abs(np.diff(x)), axis=-1)\n",
    "\n",
    "# def zc(x):\n",
    "#     trs = 0.0001\n",
    " \n",
    "#     f = [1 if i*j <= 0 else 0 for i,j in zip(x[:,:,:,:-1], x[:,:,:,1:])]\n",
    "    \n",
    "#     return np.sum(f)\n",
    "\n",
    "\n",
    "def getzc(data, th):\n",
    "    t = len(data)\n",
    "    soma = 0\n",
    "    for i in range(t-1):\n",
    "        res = (data[i]*data[i+1])\n",
    "        res2 = np.abs(data[i]-data[i+1])\n",
    "        if (res<0 and res2 > th):\n",
    "            soma +=1\n",
    "    return soma\n",
    "\n",
    "def zc(data):\n",
    "    f=[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for i in range(x):\n",
    "        l = []\n",
    "        for j in range(y):\n",
    "            li = []\n",
    "            for k in range(z):\n",
    "                li.append(getzc(data[i][j][k], 0.0001))\n",
    "            l.append(li.copy())\n",
    "        f.append(l.copy())\n",
    "\n",
    "    return np.array(f)\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "\n",
    "def fmn(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*PSD(w)), axis=-1)/np.sum(PSD(w), axis=-1)\n",
    "\n",
    "def mmnf(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*np.abs(w)), axis=-1)/np.sum(np.abs(w), axis=-1)\n",
    "\n",
    "\n",
    "def logDec(data):\n",
    "    N = np.prod(data.shape)\n",
    "    return e ** (np.sum(np.log10(np.abs(data)), axis=-1))/N\n",
    "\n",
    "\n",
    "def iemg(x):\n",
    "    return np.sum(np.abs(x), axis=-1)\n",
    "\n",
    "def dasdv(x):\n",
    "    return np.sqrt(np.sum(np.diff(x)**2, axis=-1)/(np.prod(x.shape[:-1]) - 1))\n",
    "\n",
    "def tm(x,n):\n",
    "    return np.abs(np.sum(x**n , axis=-1)/np.prod(x.shape[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4, 125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 24, 4, 125)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = list()\n",
    "final_data.append(var(chunks_time))\n",
    "final_data.append(rms(chunks_time))\n",
    "final_data.append(fmd(chunks_freq))\n",
    "final_data.append(mmdf(chunks_freq))\n",
    "final_data.append(logDec(chunks_time))\n",
    "final_data.append(wamp(chunks_time))\n",
    "final_data.append(wl(chunks_time))\n",
    "final_data.append(zc(chunks_time))\n",
    "final_data.append(fmn(chunks_freq))\n",
    "final_data.append(mmnf(chunks_freq))\n",
    "final_data.append(iemg(chunks_time))\n",
    "final_data.append(dasdv(chunks_time))\n",
    "print(iemg(chunks_time).shape)\n",
    "for n in range(3,6):\n",
    "    final_data.append(tm(chunks_time, n))\n",
    "\n",
    "\n",
    "\n",
    "f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "# print(f.shape)\n",
    "# print(Pxx_den.shape)\n",
    "final_data.append(Pxx_den)\n",
    "\n",
    "final = np.array(final_data)\n",
    "final.shape\n",
    "\n",
    "\n",
    "\n",
    "# (24,                  4,      125,    65) - \n",
    "# (classes + ensaios, canais, janelas, linhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 125, 4, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3000, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final.transpose(1,3,2,0)\n",
    "print(X.shape)\n",
    "\n",
    "X = X.reshape(X.shape[0]*X.shape[1], X.shape[2]*X.shape[3])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos rótulos: (3000,)\n"
     ]
    }
   ],
   "source": [
    "y = [[i] * int(X.shape[0] / 8) for i in range(8)]\n",
    "y = np.array(y).flatten()\n",
    "print('Shape dos rótulos:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Dividindo em conjuntos de treino (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3)\n",
    "\n",
    "# # treino: 80% dos 80% de treino. teste: 20% dos 80% de treino.\n",
    "\n",
    "# --------- split validacao\n",
    "# ---------- separar trials p treino e teste\n",
    "# --------- kfold\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# scaler.fit(X)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "# X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h):\n",
    "    loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' in s]\n",
    "    if len(loss_list) == 0:\n",
    "        print('Custo não está presente no histórico')\n",
    "        return\n",
    "    epochs = range(1, len(history.history[loss_list[0]]) + 1)\n",
    "    # Custo\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Custo [treinamento] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Custo [validação] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    plt.title('Custo')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Custo')\n",
    "    plt.legend()\n",
    "    # Acurácia\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Acurácia [treinamento] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Acurácia [validação] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    plt.title('Acurácia')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# # scaler.fit(X)\n",
    "\n",
    "# X = scaler.transform(X)\n",
    "# # X = scaler.transform(X)\n",
    "# # X_test = scaler.transform(X_test)\n",
    "\n",
    "# # X_train = np.nan_to_num(X_train)\n",
    "# X = np.nan_to_num(X)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = []\n",
    "trial.append((X[:1000], y[:1000]))\n",
    "trial.append((X[1000:2000], y[1000:2000]))\n",
    "trial.append((X[2000:3000], y[2000:3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combinations Of string \"GeEKS\" OF SIZE 3.\n",
    "  \n",
    "  \n",
    "from itertools import combinations\n",
    "\n",
    "  \n",
    "# size of combination is set to 3\n",
    "j=0\n",
    "for i in combinations(trial, 2):\n",
    "    # print(j,i) \n",
    "    print(i[j-1][1].shape)\n",
    "    # print(trial[j][0].shape)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 64)\n",
      "(2000,)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 00:03:09.560944: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-09 00:03:09.560984: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-09 00:03:09.561008: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (luisotavio-Aspire5): /proc/driver/nvidia/version does not exist\n",
      "2022-06-09 00:03:09.561328: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 1ms/step - loss: 1.7609 - accuracy: 0.3975\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.3580 - accuracy: 0.5165\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.2082 - accuracy: 0.6135\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.1445 - accuracy: 0.6510\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0788 - accuracy: 0.6825\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0540 - accuracy: 0.6975\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.0140 - accuracy: 0.7260\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.9654 - accuracy: 0.7375\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.9343 - accuracy: 0.7540\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.9305 - accuracy: 0.7540\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.9324 - accuracy: 0.7520\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8745 - accuracy: 0.7895\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8623 - accuracy: 0.7850\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8534 - accuracy: 0.7890\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8300 - accuracy: 0.8060\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8311 - accuracy: 0.8040\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8899 - accuracy: 0.7835\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7977 - accuracy: 0.8265\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7890 - accuracy: 0.8195\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7831 - accuracy: 0.8240\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7635 - accuracy: 0.8320\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7469 - accuracy: 0.8355\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7847 - accuracy: 0.8135\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7366 - accuracy: 0.8430\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7466 - accuracy: 0.8325\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7410 - accuracy: 0.8370\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7631 - accuracy: 0.8225\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7150 - accuracy: 0.8470\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.8490\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7257 - accuracy: 0.8425\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.8600\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.8595\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.8440\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.8630\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.8490\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.8720\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.8565\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.8525\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6311 - accuracy: 0.8695\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.8595\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.8660\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.8510\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7101 - accuracy: 0.8425\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.8530\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.8685\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.8780\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6359 - accuracy: 0.8680\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.8790\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.8690\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.8875\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.8675\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.8800\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.8585\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.8620\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.8680\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.8485\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6086 - accuracy: 0.8795\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.8905\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.8805\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.8725\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.8610\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.8795\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.8855\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.8860\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.8880\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.8820\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.8760\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.8545\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.8735\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.8955\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.8810\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6131 - accuracy: 0.8695\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.8755\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.8905\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.8525\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.8850\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.8895\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5769 - accuracy: 0.8895\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.9150\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.8910\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.8890\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.8635\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.8660\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6025 - accuracy: 0.8720\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.8945\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.8935\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.8775\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.8735\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.8825\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.8735\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.8800\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.8720\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.8970\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.9050\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.9030\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.8860\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.8600\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.8930\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.8975\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.8815\n",
      "32/32 [==============================] - 0s 860us/step\n",
      "(2000, 64)\n",
      "(2000,)\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 2.4374 - accuracy: 0.3755\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 1.3815 - accuracy: 0.6055\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.1973 - accuracy: 0.6610\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0499 - accuracy: 0.7155\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.9336 - accuracy: 0.7520\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8667 - accuracy: 0.7875\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8287 - accuracy: 0.7915\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8181 - accuracy: 0.7910\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7591 - accuracy: 0.8235\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7862 - accuracy: 0.8130\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7395 - accuracy: 0.8230\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7334 - accuracy: 0.8280\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6815 - accuracy: 0.8460\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7384 - accuracy: 0.8375\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.8450\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.8590\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.8760\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.8640\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7100 - accuracy: 0.8440\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.8580\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.8405\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.8755\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.8805\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.8770\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6125 - accuracy: 0.8765\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.8700\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.9005\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.8725\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.8840\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.8725\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.8720\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.8930\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.8840\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.8825\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.8995\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.9005\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.8800\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.8455\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.8920\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.8875\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5474 - accuracy: 0.8995\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.8930\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6411 - accuracy: 0.8670\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.8970\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.9030\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.8950\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.8630\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.8955\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.8900\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.8835\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.8775\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.9045\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.8960\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.9105\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.8865\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.8770\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.8905\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.9120\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.8855\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5097 - accuracy: 0.9100\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.8870\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.8930\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.9015\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5417 - accuracy: 0.8940\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5507 - accuracy: 0.8920\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 0s 921us/step - loss: 0.4852 - accuracy: 0.9225\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.9210\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.8870\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.8790\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.9125\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.8965\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.8620\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.9015\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.9135\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.9040\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.8995\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.9070\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.9085\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.8930\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.8865\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.9180\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.9045\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.8935\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.9070\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8930\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.9170\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.9105\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.9140\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.8855\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.9050\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.9110\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.9010\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.9055\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9165\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.9180\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.9040\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.9100\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5180 - accuracy: 0.9020\n",
      "32/32 [==============================] - 0s 685us/step\n",
      "(2000, 64)\n",
      "(2000,)\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.9043 - accuracy: 0.5120\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 1.0808 - accuracy: 0.6720\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.9354 - accuracy: 0.7235\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.8844 - accuracy: 0.7495\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.8141 - accuracy: 0.7715\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7880 - accuracy: 0.7855\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7516 - accuracy: 0.7955\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.8105\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.7042 - accuracy: 0.8265\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7269 - accuracy: 0.8155\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.8365\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6978 - accuracy: 0.8215\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7308 - accuracy: 0.8325\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.8285\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.8435\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.8410\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.8470\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.8480\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.8490\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.8585\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.8615\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.8530\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.8570\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.8870\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.8600\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.8515\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.8755\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6864 - accuracy: 0.8495\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.8550\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5750 - accuracy: 0.8895\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.8635\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5892 - accuracy: 0.8720\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.8925\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.8645\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7459 - accuracy: 0.8295\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.8830\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.8960\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.8815\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.8945\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.8920\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.9020\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.8870\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.8795\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.9125\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 0s 962us/step - loss: 0.5841 - accuracy: 0.8880\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.8965\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.7063 - accuracy: 0.8510\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.8810\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.8930\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.9105\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.9015\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.8955\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.8810\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8955\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.8835\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.9035\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.9060\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.8945\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5434 - accuracy: 0.8880\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.8835\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.8905\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.8900\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.8805\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.9085\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.9160\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.9005\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.8975\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6137 - accuracy: 0.8640\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.9015\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.8885\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5305 - accuracy: 0.8960\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.8995\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8965\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8990\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.8950\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.8890\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5270 - accuracy: 0.8860\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.8600\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.9175\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.9150\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.8575\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.9010\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.8875\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.9165\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.9135\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.8985\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.9190\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8945\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.8755\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.8880\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.8945\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.9225\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5466 - accuracy: 0.8900\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.9135\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.9190\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.9255\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.9060\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.9015\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.8935\n",
      "32/32 [==============================] - 0s 644us/step\n",
      "\n",
      "\n",
      "Acurácia: 61.30%\n",
      "Matriz de confusão:\n",
      "[[324   6  14  28   3   0   0   0]\n",
      " [  0 366   1   4   4   0   0   0]\n",
      " [ 65  25 220   0   1  54  10   0]\n",
      " [ 91  40   5   0   0 112 115  12]\n",
      " [ 41  35  43   0   0  62 103  91]\n",
      " [ 11   7  42  26   5 205   0  79]\n",
      " [  0   0   1   4   5   0 360   5]\n",
      " [  0   0   0   2   6   1   2 364]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.60902   0.86400   0.71444       375\n",
      "           1    0.76409   0.97600   0.85714       375\n",
      "           2    0.67485   0.58667   0.62767       375\n",
      "           3    0.00000   0.00000   0.00000       375\n",
      "           4    0.00000   0.00000   0.00000       375\n",
      "           5    0.47235   0.54667   0.50680       375\n",
      "           6    0.61017   0.96000   0.74611       375\n",
      "           7    0.66062   0.97067   0.78618       375\n",
      "\n",
      "    accuracy                        0.61300      3000\n",
      "   macro avg    0.47389   0.61300   0.52979      3000\n",
      "weighted avg    0.47389   0.61300   0.52979      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definição de uma fração do regularizador\n",
    "l = 0.01\n",
    "\n",
    "# desenvolvimento do modelo Keras para uma MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=64,\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Aplicação de um modelo de descida de gradiente utilizando o Stocastic Gradient Descendent (SGD)\n",
    "sgd = SGD(lr=0.05, momentum=0.0)\n",
    "# Função de otimização da rede: ADAM\n",
    "adam = Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\n",
    "# Função de custo baseada em dados originalmente categóricos\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "# size of combination is set to 3\n",
    "j=0\n",
    "scores = []\n",
    "for i in combinations(trial, 2):\n",
    "    X_treino = np.vstack((i[0][0],i[1][0]))\n",
    "    X_teste = trial[j][0]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_treino)\n",
    "\n",
    "    X_treino = scaler.transform(X_treino)\n",
    "    X_teste = scaler.transform(X_teste)\n",
    "\n",
    "    y_treino = np.vstack((i[0][1],i[1][1]))\n",
    "    y_treino= y_treino.reshape(y_treino.shape[0]*y_treino.shape[1])\n",
    "    y_teste = trial[j][1]\n",
    "\n",
    "    j+=1\n",
    "    print(X_treino.shape)\n",
    "    print(y_treino.shape)\n",
    "\n",
    "    history = model.fit(X_treino, y_treino, epochs=100, batch_size=15)\n",
    "    # plot_history(history)\n",
    "    # score = model.predict_classes(X_test)\n",
    "    predict_x=model.predict(X_teste) \n",
    "    score=np.argmax(predict_x,axis=1)\n",
    "    scores.append(score)\n",
    "# y_true = [np.where(x == 1)[0] for x in y_test]\n",
    "\n",
    "y_true =  np.vstack((trial[0][1],trial[1][1], trial[2][1]))\n",
    "y_true= y_true.reshape(y_true.shape[0]*y_true.shape[1])\n",
    "sc = np.vstack((scores[0], scores[1], scores[2]))\n",
    "sc= sc.reshape(sc.shape[0]*sc.shape[1])\n",
    "\n",
    "print('\\n\\nAcurácia: %0.2f%%' % (accuracy_score(y_true, sc) * 100))\n",
    "print('Matriz de confusão:')\n",
    "print(confusion_matrix(y_true, sc))\n",
    "print()\n",
    "print(classification_report(y_true, sc, digits=5))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
