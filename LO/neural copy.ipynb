{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 14:58:40.250766: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-14 14:58:40.255368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-14 14:58:40.255382: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import stft\n",
    "from math import prod\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from math import e\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(data, lowcut, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_lowpass(data, lowcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    b, a = signal.butter(order, low, btype='lowpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_highpass(data, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, high, btype='highpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_notch(data, cutoff, var=1, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = (cutoff - var) / nyq\n",
    "    high = (cutoff + var) / nyq\n",
    "    b, a = signal.iirfilter(order, [low, high], btype='bandstop', ftype=\"butter\")\n",
    "    return signal.filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtros(data):\n",
    "    data_filtered = butter_notch(data, 60)\n",
    "    data_filtered = butter_highpass(data_filtered, 5)\n",
    "    data_filtered = butter_lowpass(data_filtered, 50)\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4, 1600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'trial_2': [array([[  0.29706151,  -0.10758804,   1.23396836, ..., -38.45522264,\n",
       "          -17.73104717,   0.81996573],\n",
       "         [  0.08937505,  -7.59702407,  -5.33727604, ...,  30.65703983,\n",
       "           39.85397463,  -4.36759111],\n",
       "         [ -0.37811694,   0.44031343,   3.97210754, ...,  14.22481131,\n",
       "           26.12198471,   2.06869271],\n",
       "         [  0.08187095,   2.26459197,   3.72874838, ...,  -5.42794101,\n",
       "           -2.58438479,  -0.51082867]]),\n",
       "  array([[-1.73949608e-01, -1.42606709e+01, -1.55178994e+01, ...,\n",
       "          -5.04905317e+01, -4.19364713e+01,  9.20553298e+00],\n",
       "         [ 3.61063262e-02,  3.88964943e+00,  2.20453159e+00, ...,\n",
       "           7.98866294e+01,  7.50537834e+01, -2.10478914e-01],\n",
       "         [ 4.99892252e-02, -5.66187924e+00, -9.97914406e+00, ...,\n",
       "           2.21823731e+00,  8.47436948e-01,  3.28411724e-01],\n",
       "         [ 2.29972170e-02,  3.26872918e+00,  4.23690585e+00, ...,\n",
       "          -6.01274568e+00, -2.61444681e+00, -1.98066580e-01]]),\n",
       "  array([[  0.11907216,   3.39327291,   2.87792021, ...,   2.36730454,\n",
       "            2.83147253,   0.27363561],\n",
       "         [ -0.03321934,  -0.28832491,  -1.32475959, ..., -29.91814872,\n",
       "          -24.2894814 ,  -1.79250764],\n",
       "         [ -0.31780254,   4.7769454 ,   5.42556806, ...,  -0.76465945,\n",
       "           -1.47441007,  -1.0878036 ],\n",
       "         [ -0.17604392,   2.7049608 ,   1.27191785, ...,   0.2172488 ,\n",
       "           -0.69967462,   0.62342211]]),\n",
       "  array([[  0.13015503,  -6.07456144, -10.58212388, ...,  -3.12952408,\n",
       "            0.05870249,  -5.51005583],\n",
       "         [ -0.18673174,  -4.0766338 ,  -3.41135502, ...,  -8.64006182,\n",
       "           -5.19652824,  -0.56677434],\n",
       "         [ -0.18309174,   4.28533017,   4.71060827, ...,   7.55307413,\n",
       "           -8.37883099,   3.01461066],\n",
       "         [  0.13600279,   1.15988806,  -0.47830233, ...,  -1.02957885,\n",
       "           -0.10011682,  -0.95606915]]),\n",
       "  array([[-4.07935093e-01, -1.32583872e+01, -1.38436424e+01, ...,\n",
       "           1.48796104e+01,  2.19082822e+01,  3.91290750e+00],\n",
       "         [-4.83442261e-01, -5.65756962e+00, -7.56262291e+00, ...,\n",
       "          -5.77993941e+00, -4.80674024e+00,  1.64985959e-01],\n",
       "         [ 2.04836035e-02,  3.75828196e+00,  5.36145479e+00, ...,\n",
       "          -3.21509852e+01, -3.14892145e+01,  1.03164241e+00],\n",
       "         [-4.09539647e-01,  8.48119304e+00,  8.17636863e+00, ...,\n",
       "           8.66193277e+00,  7.83824357e+00,  3.74792827e-01]]),\n",
       "  array([[  0.526426  ,   6.73231426,  10.14742838, ...,  61.77159536,\n",
       "           50.28913114,  -2.28147377],\n",
       "         [  0.12371896,   3.1112256 ,   3.76837648, ..., -25.99265294,\n",
       "          -19.97899125,  -4.64048123],\n",
       "         [ -0.43283801,   0.9612428 ,  -0.13932282, ...,  -5.53523799,\n",
       "           -5.65779377,  -1.12088234],\n",
       "         [ -0.06383116,   3.297932  ,   0.68785391, ...,  -9.07897429,\n",
       "           -9.27164231,   1.4829658 ]]),\n",
       "  array([[-1.35929163e+00,  9.98726433e+00,  1.15559578e+01, ...,\n",
       "          -1.03807401e+01, -2.79689529e+01, -3.52171560e+00],\n",
       "         [-2.93026744e-01, -2.06543971e+01, -2.09251146e+01, ...,\n",
       "          -2.74645548e+00, -7.15913914e+00, -4.98846545e-01],\n",
       "         [ 9.26280905e-03,  1.94671472e+00,  1.63208607e+00, ...,\n",
       "           1.65778333e+01,  1.68860205e+01,  9.50493697e-01],\n",
       "         [-5.48388744e-01,  6.52132862e-01,  2.71222967e-01, ...,\n",
       "           2.33546589e+00,  1.86384677e-01, -1.20190343e+00]]),\n",
       "  array([[ 3.10680345e-01,  4.95113186e+00,  6.54289473e+00, ...,\n",
       "           3.59800909e+01,  1.57211925e-01,  2.08621851e+00],\n",
       "         [ 2.95376974e-01,  2.02508619e+00, -4.90717511e+00, ...,\n",
       "          -9.80730667e+01, -1.12237025e+02, -1.06883701e+01],\n",
       "         [ 1.09516428e-01, -5.11575359e-02,  7.10090281e-01, ...,\n",
       "           2.13750254e+01,  1.57751671e+01,  3.57118508e-01],\n",
       "         [ 3.98687972e-01,  7.96715654e+00,  8.04687506e+00, ...,\n",
       "          -1.49346990e+01,  7.06377784e+00,  1.52789836e+01]])],\n",
       " 'trial_1': [array([[ 8.86971424e-01,  2.75032326e+00,  7.30910660e-01, ...,\n",
       "           3.20848183e+01,  2.63629669e+01, -9.70162171e-01],\n",
       "         [ 1.14110323e-02, -1.25572281e+00, -7.87835958e-01, ...,\n",
       "          -4.27222536e+01, -4.59572418e+01,  1.14632761e+01],\n",
       "         [ 3.04300771e-02, -5.78062191e-01, -2.73157842e+00, ...,\n",
       "           1.45374873e+01,  5.37522607e+00,  9.25156851e-01],\n",
       "         [ 3.77486366e-01, -3.28394203e-01,  1.61014470e+00, ...,\n",
       "           6.65025614e+00,  3.81722011e+00,  7.66291046e-01]]),\n",
       "  array([[  0.87895261,  10.83082549,   7.94568282, ...,   2.22737428,\n",
       "          -16.57643156,   2.31425458],\n",
       "         [  1.61366433,   7.03969846,   5.07326019, ...,  -0.69471828,\n",
       "          -23.59994116,  -8.64044464],\n",
       "         [ -0.09501406,   3.64290801,   5.49207298, ...,  -1.50448432,\n",
       "           -1.98745328,   0.3716078 ],\n",
       "         [  1.40265117,   0.60873325,  -2.13356858, ..., -23.8279123 ,\n",
       "          -19.16239428,  -0.61128691]]),\n",
       "  array([[ 0.40246225, 11.38863356, 15.26006936, ..., 11.14502708,\n",
       "          17.69077235, -6.93840439],\n",
       "         [-0.22134116,  4.24184954,  3.71249999, ..., 22.83217741,\n",
       "          21.8168833 ,  0.10476536],\n",
       "         [ 0.28457403,  3.56112214,  1.97702901, ..., 10.17736237,\n",
       "          10.23530824, -1.2490714 ],\n",
       "         [ 0.31282916,  9.07914183, 11.20824938, ...,  2.71211683,\n",
       "           3.29515056, -0.38027456]]),\n",
       "  array([[-1.75573435e-01, -5.30930819e-01,  6.00469507e-01, ...,\n",
       "          -1.33687010e+02, -1.37540461e+02, -3.65350385e+00],\n",
       "         [ 2.48614083e-01, -1.07892624e+00, -4.57632245e-01, ...,\n",
       "          -4.87655813e-01, -4.69363106e+00,  1.07866992e+00],\n",
       "         [-9.03982308e-02,  3.58434427e+00,  4.31445337e+00, ...,\n",
       "           4.61523404e+01,  9.20408906e+00,  3.89367362e+00],\n",
       "         [-9.33887519e-02, -4.55256687e+00, -4.03753104e+00, ...,\n",
       "          -7.86498156e+00, -7.42576228e+00, -2.43435318e-02]]),\n",
       "  array([[ 2.52970060e-01,  1.01746832e+00,  1.17079798e+00, ...,\n",
       "           7.08446967e+01,  5.46007595e+01,  3.03245770e+01],\n",
       "         [ 3.55323399e-02, -3.51936271e+00, -4.24684439e+00, ...,\n",
       "          -5.38162315e+00, -4.42935613e+00, -2.89233548e-02],\n",
       "         [-2.22498326e-01, -1.93069475e+00, -1.08117600e+00, ...,\n",
       "          -1.66318629e+01, -2.06361291e+01,  1.04395773e+00],\n",
       "         [ 1.48158288e-01, -1.77809957e+00, -1.45155735e+00, ...,\n",
       "          -3.09108392e+00, -7.02002212e-01, -8.33704267e-02]]),\n",
       "  array([[  0.28067999,   5.01786947,   6.72434492, ..., -16.74981138,\n",
       "           -9.35142495,  -1.06381875],\n",
       "         [ -0.34447541,   0.81814283,   0.8705072 , ...,   1.45282936,\n",
       "            4.01492921,   0.13285181],\n",
       "         [ -0.11894031,  -0.13646147,  -0.34540942, ...,   0.24240911,\n",
       "           -0.06564157,  -0.3195351 ],\n",
       "         [ -0.2233174 ,   3.41599619,   3.46925423, ...,   8.71120473,\n",
       "            7.0501572 ,   0.4411246 ]]),\n",
       "  array([[ -0.61563631, -49.615515  , -57.18115374, ...,  -9.0286571 ,\n",
       "            1.31404222,  -0.96677615],\n",
       "         [  0.18505669, -10.34683969,  -6.34458928, ...,   7.66832065,\n",
       "            8.86587295,   0.53566298],\n",
       "         [ -0.08028494,   2.66787875,   2.86082078, ...,  12.51165678,\n",
       "            8.56733795,  -0.41834313],\n",
       "         [ -0.17062828,  -3.68746465,  -5.68357359, ...,   4.45364152,\n",
       "            4.19014975,   0.56674164]]),\n",
       "  array([[ -0.44253139,   3.68653917,   6.17622309, ...,   3.79040842,\n",
       "            3.16759689,  -2.08672603],\n",
       "         [  0.81752249,  -3.84977708,  -4.91519492, ..., -89.50343584,\n",
       "          -64.65901153,   2.02014618],\n",
       "         [  1.12642709,  -1.29999269,  -2.4090414 , ..., -43.77741798,\n",
       "          -39.31685308,   0.10901993],\n",
       "         [ -0.57794832,  -4.61998918,  -5.21331882, ...,   1.0788295 ,\n",
       "           -7.74785474,   0.1527334 ]])],\n",
       " 'trial_3': [array([[-2.81285471e-01, -2.80102954e+00, -6.49196868e+00, ...,\n",
       "          -3.53344831e+01, -2.60744936e+01, -7.95881872e-01],\n",
       "         [-3.57774137e-01,  7.97218385e-01,  2.40415204e+00, ...,\n",
       "           4.90428835e+01,  4.72429851e+01, -2.69521269e+00],\n",
       "         [-3.44359663e-01, -2.10871089e+00, -3.52739557e+00, ...,\n",
       "          -1.11159214e+01, -7.45925841e+00, -1.21033170e+00],\n",
       "         [ 1.13019602e-01,  1.82208876e+00,  1.90876018e+00, ...,\n",
       "           6.55106451e+00,  4.40053776e+00,  4.87368875e-04]]),\n",
       "  array([[  0.27114618,   5.82425996,   2.78406065, ...,  51.14446161,\n",
       "           49.79374475,   5.78595964],\n",
       "         [  0.142472  ,  -9.68238612, -10.84004053, ...,  16.83825394,\n",
       "           -6.17527531,  -1.12307888],\n",
       "         [  0.2261916 ,   0.44932622,  -0.86574375, ...,   0.33065465,\n",
       "           -0.17528108,  -0.52353601],\n",
       "         [  0.09134151,   1.85978608,   2.15428092, ...,   6.50997249,\n",
       "            5.48737038,  -0.61447138]]),\n",
       "  array([[ 0.93303868,  2.11698893,  4.20853364, ..., -4.65875738,\n",
       "          -2.27486501, -1.78074634],\n",
       "         [-0.10736557, -5.76324605, -9.47361414, ..., -3.30135595,\n",
       "          -1.31505604,  0.65242706],\n",
       "         [ 0.16579179, -4.61219775, -4.01274622, ...,  0.02995513,\n",
       "           2.79710835,  1.11363222],\n",
       "         [ 0.2057942 , -2.53408032, -4.36800921, ...,  5.24957582,\n",
       "           7.56295836,  0.46745614]]),\n",
       "  array([[ -0.13448021, -26.19338017, -30.478793  , ...,  17.39402282,\n",
       "            5.70843709,  -0.82858818],\n",
       "         [ -0.31414774,  -5.5064401 ,  -5.12140359, ...,  -2.48241901,\n",
       "           -4.27931504,   0.94906508],\n",
       "         [  0.09115839,   4.87644569,   4.60389231, ...,  19.59895051,\n",
       "           19.09918867,   1.30548091],\n",
       "         [  0.16788478,  -4.3005663 ,  -3.26677829, ...,  -2.64705358,\n",
       "           -3.97743535,   0.5454322 ]]),\n",
       "  array([[ 0.72772372, -4.97853346, -2.13093495, ...,  2.123064  ,\n",
       "           1.65300469, -0.4759337 ],\n",
       "         [-0.03141511, -2.9069953 , -2.67521211, ..., -2.97419145,\n",
       "          -6.0228361 , -0.08900635],\n",
       "         [-0.02219471, -1.63786135, -1.60784963, ...,  8.16232367,\n",
       "           9.41206011,  1.05972944],\n",
       "         [ 0.04995173, -6.00523003, -6.0966636 , ..., -3.61096062,\n",
       "          -4.05286343,  0.61560087]]),\n",
       "  array([[ -0.0283558 ,  -0.54213688,  -0.07350977, ...,   1.30614731,\n",
       "            0.66682469,   3.1492468 ],\n",
       "         [ -0.46228554,  -5.66747125,  -8.2773274 , ..., -11.28403636,\n",
       "          -13.88716382,   0.32765171],\n",
       "         [ -0.22416486,   4.76245002,   4.48343167, ...,  -2.83395614,\n",
       "           -2.28677131,   0.26572737],\n",
       "         [ -0.11451965,   3.04889513,   2.43137931, ...,  -9.6751866 ,\n",
       "           -7.83789618,  -0.1959526 ]]),\n",
       "  array([[  0.10232333,  -2.69748521,  -2.24981138, ...,  67.26247734,\n",
       "           56.49239383,   2.66563282],\n",
       "         [  0.49826994,  -5.15404643,  -5.33689818, ..., -13.29895965,\n",
       "          -16.07500034,  -0.76676463],\n",
       "         [ -0.2910385 ,  -0.39428683,   0.87667895, ...,  12.29342868,\n",
       "            8.8043443 ,   0.15507507],\n",
       "         [  0.26903536,  -2.5973059 ,  -1.43255297, ..., -11.29277312,\n",
       "          -10.29669743,  -0.163006  ]]),\n",
       "  array([[ -0.11609513,  -2.17035401,  -3.01718127, ...,  25.51561783,\n",
       "           40.94590653,  -1.13549902],\n",
       "         [ -0.11181073,   7.58206663,   7.81063794, ..., -33.87133874,\n",
       "           17.30872253,   2.13418933],\n",
       "         [  0.18292964,   2.45936322,   2.60793469, ...,  34.73312815,\n",
       "           29.76770388,  -3.92555835],\n",
       "         [ -0.38101716,   3.37221245,   2.08804709, ...,  45.39087041,\n",
       "           44.05384886,  -3.66204915]])]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = './datasets/topicos_cc'\n",
    "arquivos = os.listdir(dir)\n",
    "arq_numpy = [f for f in arquivos if f.endswith(\".npy\") and f.startswith('p2')]\n",
    "participantes = {}\n",
    "vetor = []\n",
    "for i in arq_numpy:\n",
    "    nome = i.split('_')\n",
    "    trial = np.load(dir+'/'+i)\n",
    "    for m in range(0,8):\n",
    "        if participantes.get(f'trial_{nome[1]}',0) == 0:\n",
    "            participantes[f'trial_{nome[1]}'] = []\n",
    "        # if participantes[f'participante_{nome[0]}'].get(f'trial_{nome[1]}',0) == 0:\n",
    "        #     participantes[f'participante_{nome[0]}'][f'trial_{nome[1]}'] = {}\n",
    "        dados = trial[m, :, :].swapaxes(0,1)\n",
    "        participantes[f'trial_{nome[1]}'].append(filtros(dados))\n",
    "        # participantes[f'participante_{nome[0]}'][f'trial_{nome[1]}'][f'movimento_{m+1}'] = filtros(dados)\n",
    "        # vetor.append(filtros(dados))\n",
    "        # print(f'participante_{nome[0]} trial_{nome[1]} movimento_{m+1}')\n",
    "        # print(np.array(filtros(dados)).shape)\n",
    "        \n",
    "\n",
    "# participantes\n",
    "# np.array(participantes).shape\n",
    "\n",
    "arr = np.vstack((np.array(participantes['trial_1']), np.array(participantes['trial_2']), np.array(participantes['trial_3'])))\n",
    "    \n",
    "\n",
    "# v = list()\n",
    "# for i in arq_numpy:\n",
    "#     trial = np.load(dir+'/'+i)\n",
    "#     v.append(trial[:, :, :].swapaxes(1,2))    \n",
    "\n",
    "# arr = np.vstack((v[0], v[1], v[2]))\n",
    "\n",
    "print(arr.shape)\n",
    "participantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (24, 4, 1600)\n",
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (24, 4, 125, 128) - (classes, ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (24, 4, 125, 65) - (classes, ensaios, canais, janelas, linhas)\n"
     ]
    }
   ],
   "source": [
    "step = 11.8\n",
    "segment = 128\n",
    "data = arr\n",
    "# .get_data()\n",
    "print('', data.shape)\n",
    "\n",
    "n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "ids = np.arange(n_win) * int(step)\n",
    "\n",
    "# Janelas do dado no dominio do tempo\n",
    "chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "# Janelas do dado no domínio da frequência\n",
    "_, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=115)\n",
    "chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "print(f'Dominio do tempo: {chunks_time.shape} - (classes, ensaios, canais, janelas, linhas)')\n",
    "print(f'Dominio da frequência:  {chunks_freq.shape} - (classes, ensaios, canais, janelas, linhas)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "\n",
    "# funções de extração de características\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape[:-1]) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape[:-1])))\n",
    "\n",
    "def wamp(x):\n",
    "    limiar = np.abs(np.diff(x))\n",
    "    return np.sum(limiar > 0.0001, axis=-1)\n",
    "\n",
    "def wl(x):\n",
    "    return np.sum(np.abs(np.diff(x)), axis=-1)\n",
    "\n",
    "# def zc(x):\n",
    "#     trs = 0.0001\n",
    " \n",
    "#     f = [1 if i*j <= 0 else 0 for i,j in zip(x[:,:,:,:-1], x[:,:,:,1:])]\n",
    "    \n",
    "#     return np.sum(f)\n",
    "\n",
    "\n",
    "def getzc(data, th):\n",
    "    t = len(data)\n",
    "    soma = 0\n",
    "    for i in range(t-1):\n",
    "        res = (data[i]*data[i+1])\n",
    "        res2 = np.abs(data[i]-data[i+1])\n",
    "        if (res<0 and res2 > th):\n",
    "            soma +=1\n",
    "    return soma\n",
    "\n",
    "def zc(data):\n",
    "    f=[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for i in range(x):\n",
    "        l = []\n",
    "        for j in range(y):\n",
    "            li = []\n",
    "            for k in range(z):\n",
    "                li.append(getzc(data[i][j][k], 0.0001))\n",
    "            l.append(li.copy())\n",
    "        f.append(l.copy())\n",
    "\n",
    "    return np.array(f)\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "\n",
    "def fmn(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*PSD(w)), axis=-1)/np.sum(PSD(w), axis=-1)\n",
    "\n",
    "def mmnf(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*np.abs(w)), axis=-1)/np.sum(np.abs(w), axis=-1)\n",
    "\n",
    "\n",
    "def logDec(data):\n",
    "    N = np.prod(data.shape)\n",
    "    return e ** (np.sum(np.log10(np.abs(data)), axis=-1))/N\n",
    "\n",
    "\n",
    "def iemg(x):\n",
    "    return np.sum(np.abs(x), axis=-1)\n",
    "\n",
    "def dasdv(x):\n",
    "    return np.sqrt(np.sum(np.diff(x)**2, axis=-1)/(np.prod(x.shape[:-1]) - 1))\n",
    "\n",
    "def tm(x,n):\n",
    "    return np.abs(np.sum(x**n , axis=-1)/np.prod(x.shape[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4, 125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 24, 4, 125)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = list()\n",
    "final_data.append(var(chunks_time))\n",
    "final_data.append(rms(chunks_time))\n",
    "final_data.append(fmd(chunks_freq))\n",
    "final_data.append(mmdf(chunks_freq))\n",
    "final_data.append(logDec(chunks_time))\n",
    "final_data.append(wamp(chunks_time))\n",
    "final_data.append(wl(chunks_time))\n",
    "final_data.append(zc(chunks_time))\n",
    "final_data.append(fmn(chunks_freq))\n",
    "final_data.append(mmnf(chunks_freq))\n",
    "final_data.append(iemg(chunks_time))\n",
    "final_data.append(dasdv(chunks_time))\n",
    "print(iemg(chunks_time).shape)\n",
    "for n in range(3,6):\n",
    "    final_data.append(tm(chunks_time, n))\n",
    "\n",
    "\n",
    "\n",
    "f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "# print(f.shape)\n",
    "# print(Pxx_den.shape)\n",
    "final_data.append(Pxx_den)\n",
    "\n",
    "final = np.array(final_data)\n",
    "final.shape\n",
    "\n",
    "\n",
    "\n",
    "# (24,                  4,      125,    65) - \n",
    "# (classes + ensaios, canais, janelas, linhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 125, 4, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3000, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final.transpose(1,3,2,0)\n",
    "print(X.shape)\n",
    "\n",
    "X = X.reshape(X.shape[0]*X.shape[1], X.shape[2]*X.shape[3])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos rótulos: (3000,)\n"
     ]
    }
   ],
   "source": [
    "y = [[i] * int(X.shape[0] / 8) for i in range(8)]\n",
    "y = np.array(y).flatten()\n",
    "print('Shape dos rótulos:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Dividindo em conjuntos de treino (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3)\n",
    "\n",
    "# # treino: 80% dos 80% de treino. teste: 20% dos 80% de treino.\n",
    "\n",
    "# --------- split validacao\n",
    "# ---------- separar trials p treino e teste\n",
    "# --------- kfold\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# scaler.fit(X)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "# X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(h):\n",
    "    loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in h.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in h.history.keys() if 'acc' in s and 'val' in s]\n",
    "    if len(loss_list) == 0:\n",
    "        print('Custo não está presente no histórico')\n",
    "        return\n",
    "    epochs = range(1, len(history.history[loss_list[0]]) + 1)\n",
    "    # Custo\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Custo [treinamento] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Custo [validação] (' + str(str(format(\n",
    "                    h.history[l][-1],'.5f'))+')'))\n",
    "    plt.title('Custo')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Custo')\n",
    "    plt.legend()\n",
    "    # Acurácia\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'b',\n",
    "                 label='Acurácia [treinamento] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:\n",
    "        plt.plot(epochs, h.history[l], 'g',\n",
    "                 label='Acurácia [validação] (' + str(format(\n",
    "                    h.history[l][-1],'.5f'))+')')\n",
    "    plt.title('Acurácia')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Acurácia')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# # scaler.fit(X)\n",
    "\n",
    "# X = scaler.transform(X)\n",
    "# # X = scaler.transform(X)\n",
    "# # X_test = scaler.transform(X_test)\n",
    "\n",
    "# # X_train = np.nan_to_num(X_train)\n",
    "# X = np.nan_to_num(X)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = []\n",
    "trial.append((X[:1000], y[:1000]))\n",
    "trial.append((X[1000:2000], y[1000:2000]))\n",
    "trial.append((X[2000:3000], y[2000:3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000,)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combinations Of string \"GeEKS\" OF SIZE 3.\n",
    "  \n",
    "  \n",
    "from itertools import combinations\n",
    "\n",
    "  \n",
    "# size of combination is set to 3\n",
    "j=0\n",
    "for i in combinations(trial, 2):\n",
    "    # print(j,i) \n",
    "    print(i[j-1][1].shape)\n",
    "    # print(trial[j][0].shape)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 64)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisotavio/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 3ms/step - loss: 1.9517 - accuracy: 0.3200 - val_loss: 1.6475 - val_accuracy: 0.3750\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.4761 - accuracy: 0.4686 - val_loss: 1.4276 - val_accuracy: 0.5350\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3017 - accuracy: 0.5400 - val_loss: 1.3329 - val_accuracy: 0.5583\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 1.1996 - accuracy: 0.6021 - val_loss: 1.2737 - val_accuracy: 0.5500\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1255 - accuracy: 0.6443 - val_loss: 1.1910 - val_accuracy: 0.6350\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0871 - accuracy: 0.6650 - val_loss: 1.2259 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0695 - accuracy: 0.6779 - val_loss: 1.1677 - val_accuracy: 0.6617\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0131 - accuracy: 0.7264 - val_loss: 1.0937 - val_accuracy: 0.7117\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9889 - accuracy: 0.7314 - val_loss: 1.1570 - val_accuracy: 0.6633\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9819 - accuracy: 0.7343 - val_loss: 1.1062 - val_accuracy: 0.6883\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9519 - accuracy: 0.7529 - val_loss: 1.0568 - val_accuracy: 0.6983\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.9373 - accuracy: 0.7629 - val_loss: 1.0817 - val_accuracy: 0.6883\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8991 - accuracy: 0.7800 - val_loss: 1.0343 - val_accuracy: 0.7167\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.8760 - accuracy: 0.7779 - val_loss: 0.9947 - val_accuracy: 0.7417\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.7921 - val_loss: 0.9740 - val_accuracy: 0.7550\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8658 - accuracy: 0.7914 - val_loss: 1.0303 - val_accuracy: 0.7233\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8891 - accuracy: 0.7714 - val_loss: 1.0021 - val_accuracy: 0.7150\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8528 - accuracy: 0.7950 - val_loss: 0.9631 - val_accuracy: 0.7750\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8211 - accuracy: 0.8164 - val_loss: 0.9637 - val_accuracy: 0.7733\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8117 - accuracy: 0.8157 - val_loss: 0.9278 - val_accuracy: 0.7967\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8150 - accuracy: 0.8100 - val_loss: 1.0730 - val_accuracy: 0.7533\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8182 - accuracy: 0.8021 - val_loss: 0.9805 - val_accuracy: 0.7533\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7876 - accuracy: 0.8236 - val_loss: 0.9051 - val_accuracy: 0.7883\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7810 - accuracy: 0.8321 - val_loss: 0.8650 - val_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7648 - accuracy: 0.8221 - val_loss: 0.9300 - val_accuracy: 0.7833\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7794 - accuracy: 0.8114 - val_loss: 0.9115 - val_accuracy: 0.7750\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8264 - accuracy: 0.8136 - val_loss: 0.9997 - val_accuracy: 0.7467\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7912 - accuracy: 0.8186 - val_loss: 0.8899 - val_accuracy: 0.8100\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.8343 - val_loss: 0.9308 - val_accuracy: 0.7667\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7342 - accuracy: 0.8450 - val_loss: 0.8529 - val_accuracy: 0.8017\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.8329 - val_loss: 0.9082 - val_accuracy: 0.7667\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7163 - accuracy: 0.8457 - val_loss: 0.8428 - val_accuracy: 0.8083\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.8571 - val_loss: 0.8378 - val_accuracy: 0.8183\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7575 - accuracy: 0.8336 - val_loss: 0.9411 - val_accuracy: 0.7483\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7232 - accuracy: 0.8450 - val_loss: 0.8195 - val_accuracy: 0.8150\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.8721 - val_loss: 0.8405 - val_accuracy: 0.7933\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7727 - accuracy: 0.8314 - val_loss: 0.8266 - val_accuracy: 0.8200\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.8586 - val_loss: 0.8079 - val_accuracy: 0.8233\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.8536 - val_loss: 0.8905 - val_accuracy: 0.7850\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.8271 - val_loss: 0.8587 - val_accuracy: 0.7850\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.8536 - val_loss: 0.8003 - val_accuracy: 0.8417\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.8679 - val_loss: 0.7855 - val_accuracy: 0.8183\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.8600 - val_loss: 0.7629 - val_accuracy: 0.8467\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.8464 - val_loss: 0.8072 - val_accuracy: 0.7983\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.8629 - val_loss: 0.7442 - val_accuracy: 0.8467\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.8371 - val_loss: 0.8244 - val_accuracy: 0.8117\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.8571 - val_loss: 0.7717 - val_accuracy: 0.8217\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.8429 - val_loss: 0.8535 - val_accuracy: 0.8017\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.8536 - val_loss: 0.8093 - val_accuracy: 0.8183\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.8686 - val_loss: 0.7488 - val_accuracy: 0.8300\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.8821 - val_loss: 0.7568 - val_accuracy: 0.8250\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.8779 - val_loss: 0.7771 - val_accuracy: 0.8033\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.8543 - val_loss: 0.9115 - val_accuracy: 0.7683\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7654 - accuracy: 0.8171 - val_loss: 0.8209 - val_accuracy: 0.8133\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.8707 - val_loss: 0.7576 - val_accuracy: 0.8433\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.8850 - val_loss: 0.7808 - val_accuracy: 0.8267\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.8714 - val_loss: 0.7589 - val_accuracy: 0.8217\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.8736 - val_loss: 0.7546 - val_accuracy: 0.8200\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.8764 - val_loss: 0.7318 - val_accuracy: 0.8467\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.8814 - val_loss: 0.6827 - val_accuracy: 0.8483\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.8664 - val_loss: 0.6964 - val_accuracy: 0.8683\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.8621 - val_loss: 0.7735 - val_accuracy: 0.8033\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.8664 - val_loss: 0.7704 - val_accuracy: 0.8167\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.8507 - val_loss: 0.7683 - val_accuracy: 0.8300\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.8600 - val_loss: 0.7562 - val_accuracy: 0.8283\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.8971 - val_loss: 0.7167 - val_accuracy: 0.8483\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.8857 - val_loss: 0.7541 - val_accuracy: 0.8150\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.8764 - val_loss: 0.7209 - val_accuracy: 0.8483\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.8679 - val_loss: 0.8574 - val_accuracy: 0.8017\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.8664 - val_loss: 0.7656 - val_accuracy: 0.8183\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.8657 - val_loss: 0.7199 - val_accuracy: 0.8400\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.8664 - val_loss: 0.8105 - val_accuracy: 0.8067\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.8314 - val_loss: 0.8299 - val_accuracy: 0.7933\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.8529 - val_loss: 0.7617 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.8921 - val_loss: 0.7043 - val_accuracy: 0.8433\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.8771 - val_loss: 0.6692 - val_accuracy: 0.8567\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.8571 - val_loss: 0.8082 - val_accuracy: 0.8300\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.8743 - val_loss: 0.7093 - val_accuracy: 0.8500\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.8971 - val_loss: 0.6958 - val_accuracy: 0.8450\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.8893 - val_loss: 0.7427 - val_accuracy: 0.8433\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.8729 - val_loss: 0.7906 - val_accuracy: 0.8250\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.8736 - val_loss: 0.7358 - val_accuracy: 0.8367\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.8671 - val_loss: 0.7237 - val_accuracy: 0.8467\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.8800 - val_loss: 0.7263 - val_accuracy: 0.8317\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.8836 - val_loss: 0.6872 - val_accuracy: 0.8617\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7373 - accuracy: 0.8314 - val_loss: 0.8298 - val_accuracy: 0.7850\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.8736 - val_loss: 0.6634 - val_accuracy: 0.8417\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.8979 - val_loss: 0.6541 - val_accuracy: 0.8550\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.8964 - val_loss: 0.6791 - val_accuracy: 0.8467\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5964 - accuracy: 0.8650 - val_loss: 0.7090 - val_accuracy: 0.8450\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.8893 - val_loss: 0.6809 - val_accuracy: 0.8483\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.8936 - val_loss: 0.6309 - val_accuracy: 0.8733\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.8843 - val_loss: 0.6732 - val_accuracy: 0.8517\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.8964 - val_loss: 0.6693 - val_accuracy: 0.8583\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.8907 - val_loss: 0.6940 - val_accuracy: 0.8350\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.8729 - val_loss: 0.7445 - val_accuracy: 0.8250\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.9011 - accuracy: 0.7950 - val_loss: 0.8862 - val_accuracy: 0.7933\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.8493 - val_loss: 0.7794 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.8750 - val_loss: 0.7239 - val_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.8829 - val_loss: 0.8123 - val_accuracy: 0.7950\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "(2000, 64)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.4819 - accuracy: 0.3836 - val_loss: 1.6519 - val_accuracy: 0.5517\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.4651 - accuracy: 0.5914 - val_loss: 1.4119 - val_accuracy: 0.5833\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2911 - accuracy: 0.6393 - val_loss: 1.3074 - val_accuracy: 0.6183\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1939 - accuracy: 0.6664 - val_loss: 1.2110 - val_accuracy: 0.6383\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1122 - accuracy: 0.6993 - val_loss: 1.1025 - val_accuracy: 0.6850\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0373 - accuracy: 0.7150 - val_loss: 1.0843 - val_accuracy: 0.6833\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9637 - accuracy: 0.7457 - val_loss: 1.0428 - val_accuracy: 0.6833\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.7536 - val_loss: 0.9623 - val_accuracy: 0.6967\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8749 - accuracy: 0.7779 - val_loss: 0.9274 - val_accuracy: 0.7750\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7935 - accuracy: 0.8079 - val_loss: 0.8725 - val_accuracy: 0.7600\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7788 - accuracy: 0.8143 - val_loss: 0.8292 - val_accuracy: 0.7750\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7950 - accuracy: 0.8064 - val_loss: 0.8314 - val_accuracy: 0.7683\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7295 - accuracy: 0.8371 - val_loss: 0.7807 - val_accuracy: 0.8133\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.8393 - val_loss: 0.7707 - val_accuracy: 0.7967\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.8414 - val_loss: 0.8305 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.8364 - val_loss: 0.7788 - val_accuracy: 0.8150\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.8536 - val_loss: 0.7428 - val_accuracy: 0.8183\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.8600 - val_loss: 0.7150 - val_accuracy: 0.8517\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.8693 - val_loss: 0.8054 - val_accuracy: 0.7783\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.8321 - val_loss: 0.7582 - val_accuracy: 0.8217\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.8450 - val_loss: 0.8123 - val_accuracy: 0.7983\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.8493 - val_loss: 0.7289 - val_accuracy: 0.8583\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.8743 - val_loss: 0.7669 - val_accuracy: 0.8133\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.8664 - val_loss: 0.7209 - val_accuracy: 0.8267\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.8843 - val_loss: 0.7609 - val_accuracy: 0.8350\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.8714 - val_loss: 0.6890 - val_accuracy: 0.8583\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.8843 - val_loss: 0.7110 - val_accuracy: 0.8317\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.8800 - val_loss: 0.6559 - val_accuracy: 0.8617\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.8893 - val_loss: 0.7119 - val_accuracy: 0.8383\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6143 - accuracy: 0.8836 - val_loss: 0.6341 - val_accuracy: 0.8683\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.8821 - val_loss: 0.6466 - val_accuracy: 0.8617\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.8921 - val_loss: 0.6670 - val_accuracy: 0.8533\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.8986 - val_loss: 0.6608 - val_accuracy: 0.8583\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6068 - accuracy: 0.8736 - val_loss: 0.6669 - val_accuracy: 0.8450\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.8836 - val_loss: 0.7557 - val_accuracy: 0.8317\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.8786 - val_loss: 0.6608 - val_accuracy: 0.8800\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.8943 - val_loss: 0.6451 - val_accuracy: 0.8683\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.9100 - val_loss: 0.6464 - val_accuracy: 0.8717\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.8893 - val_loss: 0.6348 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.8929 - val_loss: 0.6415 - val_accuracy: 0.8717\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.8850 - val_loss: 0.6707 - val_accuracy: 0.8733\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.8829 - val_loss: 0.7284 - val_accuracy: 0.8433\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.8743 - val_loss: 0.7308 - val_accuracy: 0.8150\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.9079 - val_loss: 0.6803 - val_accuracy: 0.8683\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.8857 - val_loss: 0.6440 - val_accuracy: 0.8617\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.9114 - val_loss: 0.6465 - val_accuracy: 0.8767\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.8957 - val_loss: 0.7141 - val_accuracy: 0.8500\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.8886 - val_loss: 0.6285 - val_accuracy: 0.8717\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.9021 - val_loss: 0.6045 - val_accuracy: 0.9017\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.9136 - val_loss: 0.6444 - val_accuracy: 0.8733\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.9000 - val_loss: 0.6488 - val_accuracy: 0.8600\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.9129 - val_loss: 0.6327 - val_accuracy: 0.8833\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.9093 - val_loss: 0.6433 - val_accuracy: 0.8717\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.9057 - val_loss: 0.6172 - val_accuracy: 0.8800\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.8979 - val_loss: 0.6325 - val_accuracy: 0.8650\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.9136 - val_loss: 0.6131 - val_accuracy: 0.8800\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.9050 - val_loss: 0.7105 - val_accuracy: 0.8467\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.9050 - val_loss: 0.6171 - val_accuracy: 0.8733\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.8936 - val_loss: 0.7851 - val_accuracy: 0.8133\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.8800 - val_loss: 0.5902 - val_accuracy: 0.8933\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.9036 - val_loss: 0.6093 - val_accuracy: 0.8733\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.9064 - val_loss: 0.5467 - val_accuracy: 0.9083\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.9050 - val_loss: 0.6342 - val_accuracy: 0.8600\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.8900 - val_loss: 0.6777 - val_accuracy: 0.8533\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.9107 - val_loss: 0.5805 - val_accuracy: 0.8900\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.9157 - val_loss: 0.5567 - val_accuracy: 0.9033\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.9107 - val_loss: 0.6368 - val_accuracy: 0.8600\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.8964 - val_loss: 0.6189 - val_accuracy: 0.8617\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.8800 - val_loss: 0.7494 - val_accuracy: 0.8300\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.8729 - val_loss: 0.6774 - val_accuracy: 0.8533\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.9079 - val_loss: 0.5913 - val_accuracy: 0.8733\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.9236 - val_loss: 0.5943 - val_accuracy: 0.8817\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.9121 - val_loss: 0.6092 - val_accuracy: 0.8783\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.9050 - val_loss: 0.6312 - val_accuracy: 0.8733\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.9079 - val_loss: 0.6433 - val_accuracy: 0.8467\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.8943 - val_loss: 0.6799 - val_accuracy: 0.8300\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.8779 - val_loss: 0.6557 - val_accuracy: 0.8617\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.8986 - val_loss: 0.5761 - val_accuracy: 0.8817\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.9100 - val_loss: 0.6292 - val_accuracy: 0.8633\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.9150 - val_loss: 0.6732 - val_accuracy: 0.8367\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.9143 - val_loss: 0.5864 - val_accuracy: 0.8850\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.9093 - val_loss: 0.6030 - val_accuracy: 0.8800\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.9086 - val_loss: 0.6835 - val_accuracy: 0.8467\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.9021 - val_loss: 0.6350 - val_accuracy: 0.8633\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.8943 - val_loss: 0.6552 - val_accuracy: 0.8500\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.8850 - val_loss: 0.5666 - val_accuracy: 0.9033\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.9264 - val_loss: 0.5816 - val_accuracy: 0.8817\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.9236 - val_loss: 0.6409 - val_accuracy: 0.8700\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.9114 - val_loss: 0.6200 - val_accuracy: 0.8417\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.9050 - val_loss: 0.5997 - val_accuracy: 0.8750\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.8907 - val_loss: 0.5842 - val_accuracy: 0.8850\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.9064 - val_loss: 0.5916 - val_accuracy: 0.8650\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.9050 - val_loss: 0.6427 - val_accuracy: 0.8733\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.8964 - val_loss: 0.6062 - val_accuracy: 0.8633\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.8993 - val_loss: 0.6267 - val_accuracy: 0.8667\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.8971 - val_loss: 0.5930 - val_accuracy: 0.8667\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.9114 - val_loss: 0.6051 - val_accuracy: 0.8683\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.9057 - val_loss: 0.6119 - val_accuracy: 0.8667\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.9207 - val_loss: 0.6093 - val_accuracy: 0.8617\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9314 - val_loss: 0.5359 - val_accuracy: 0.9083\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "(2000, 64)\n",
      "(2000,)\n",
      "(3000,)\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.6822 - accuracy: 0.4900 - val_loss: 1.5729 - val_accuracy: 0.5433\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3404 - accuracy: 0.6050 - val_loss: 1.1483 - val_accuracy: 0.6383\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1355 - accuracy: 0.6500 - val_loss: 1.0565 - val_accuracy: 0.6517\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0034 - accuracy: 0.6871 - val_loss: 0.9783 - val_accuracy: 0.6850\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9815 - accuracy: 0.6986 - val_loss: 0.9880 - val_accuracy: 0.6650\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9040 - accuracy: 0.7429 - val_loss: 0.9480 - val_accuracy: 0.7033\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8767 - accuracy: 0.7379 - val_loss: 0.8616 - val_accuracy: 0.7233\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8392 - accuracy: 0.7521 - val_loss: 0.8404 - val_accuracy: 0.7350\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8222 - accuracy: 0.7643 - val_loss: 0.8678 - val_accuracy: 0.7450\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8442 - accuracy: 0.7514 - val_loss: 0.7962 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7710 - accuracy: 0.7929 - val_loss: 0.7558 - val_accuracy: 0.7733\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7367 - accuracy: 0.7936 - val_loss: 0.7680 - val_accuracy: 0.7917\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7607 - accuracy: 0.7993 - val_loss: 0.8241 - val_accuracy: 0.7517\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7315 - accuracy: 0.8100 - val_loss: 0.7273 - val_accuracy: 0.7967\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7147 - accuracy: 0.8093 - val_loss: 0.6815 - val_accuracy: 0.8067\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7300 - accuracy: 0.7993 - val_loss: 0.7615 - val_accuracy: 0.7767\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.8336 - val_loss: 0.6891 - val_accuracy: 0.8067\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.8507 - val_loss: 0.6968 - val_accuracy: 0.8167\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8275 - accuracy: 0.8007 - val_loss: 0.7791 - val_accuracy: 0.7917\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7719 - accuracy: 0.8021 - val_loss: 0.7642 - val_accuracy: 0.7833\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.8493 - val_loss: 0.6779 - val_accuracy: 0.8317\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.8493 - val_loss: 0.7083 - val_accuracy: 0.8117\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.8600 - val_loss: 0.6457 - val_accuracy: 0.8433\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.8593 - val_loss: 0.6263 - val_accuracy: 0.8467\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.8764 - val_loss: 0.6133 - val_accuracy: 0.8533\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.8657 - val_loss: 0.6484 - val_accuracy: 0.8350\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.8707 - val_loss: 0.5920 - val_accuracy: 0.8767\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.8457 - val_loss: 0.6710 - val_accuracy: 0.8483\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.8679 - val_loss: 0.6845 - val_accuracy: 0.8117\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.8779 - val_loss: 0.6276 - val_accuracy: 0.8433\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.8643 - val_loss: 0.6578 - val_accuracy: 0.8083\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.8686 - val_loss: 0.6259 - val_accuracy: 0.8450\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.8757 - val_loss: 0.6831 - val_accuracy: 0.8300\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.8721 - val_loss: 0.6068 - val_accuracy: 0.8717\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.8871 - val_loss: 0.6168 - val_accuracy: 0.8400\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.8571 - val_loss: 0.6202 - val_accuracy: 0.8450\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.8900 - val_loss: 0.6573 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.8479 - val_loss: 0.6175 - val_accuracy: 0.8650\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.8600 - val_loss: 0.6227 - val_accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.8829 - val_loss: 0.6294 - val_accuracy: 0.8533\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.8900 - val_loss: 0.5746 - val_accuracy: 0.8767\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.8864 - val_loss: 0.5870 - val_accuracy: 0.8867\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.8643 - val_loss: 0.8524 - val_accuracy: 0.7850\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.8493 - val_loss: 0.6451 - val_accuracy: 0.8467\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.8707 - val_loss: 0.6203 - val_accuracy: 0.8550\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.8907 - val_loss: 0.5907 - val_accuracy: 0.8617\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.8886 - val_loss: 0.5739 - val_accuracy: 0.8783\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.9100 - val_loss: 0.5265 - val_accuracy: 0.9117\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.8507 - val_loss: 0.7264 - val_accuracy: 0.8367\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.8786 - val_loss: 0.5970 - val_accuracy: 0.8567\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.8943 - val_loss: 0.6159 - val_accuracy: 0.8650\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.8757 - val_loss: 0.7103 - val_accuracy: 0.8283\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.8886 - val_loss: 0.6637 - val_accuracy: 0.8433\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.8879 - val_loss: 0.6300 - val_accuracy: 0.8567\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.8986 - val_loss: 0.5780 - val_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.8957 - val_loss: 0.5894 - val_accuracy: 0.8600\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.8900 - val_loss: 0.5603 - val_accuracy: 0.8800\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.9021 - val_loss: 0.5457 - val_accuracy: 0.8850\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.9136 - val_loss: 0.5536 - val_accuracy: 0.8733\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.9014 - val_loss: 0.5891 - val_accuracy: 0.8700\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.8800 - val_loss: 0.5874 - val_accuracy: 0.8583\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.9036 - val_loss: 0.6190 - val_accuracy: 0.8550\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.8950 - val_loss: 0.5657 - val_accuracy: 0.8950\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.9129 - val_loss: 0.5515 - val_accuracy: 0.8900\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.8950 - val_loss: 0.5885 - val_accuracy: 0.8617\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.8929 - val_loss: 0.5437 - val_accuracy: 0.8850\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.9057 - val_loss: 0.6853 - val_accuracy: 0.8200\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.8886 - val_loss: 0.7169 - val_accuracy: 0.8217\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.8900 - val_loss: 0.7211 - val_accuracy: 0.8417\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.8843 - val_loss: 0.6610 - val_accuracy: 0.8433\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.8814 - val_loss: 0.5408 - val_accuracy: 0.8983\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.9150 - val_loss: 0.5089 - val_accuracy: 0.9133\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.9071 - val_loss: 0.6217 - val_accuracy: 0.8567\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5808 - accuracy: 0.8821 - val_loss: 0.6480 - val_accuracy: 0.8433\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.8979 - val_loss: 0.5404 - val_accuracy: 0.8933\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.9007 - val_loss: 0.5103 - val_accuracy: 0.9133\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.9314 - val_loss: 0.5199 - val_accuracy: 0.9067\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.9057 - val_loss: 0.6389 - val_accuracy: 0.8467\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.8907 - val_loss: 0.6282 - val_accuracy: 0.8517\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.9071 - val_loss: 0.5248 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.9214 - val_loss: 0.5462 - val_accuracy: 0.8867\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.8914 - val_loss: 0.5778 - val_accuracy: 0.8633\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.9107 - val_loss: 0.5713 - val_accuracy: 0.8850\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.9071 - val_loss: 0.5394 - val_accuracy: 0.8883\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.9236 - val_loss: 0.5665 - val_accuracy: 0.8950\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.8964 - val_loss: 0.5525 - val_accuracy: 0.8817\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.8707 - val_loss: 0.5552 - val_accuracy: 0.8850\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.9136 - val_loss: 0.4741 - val_accuracy: 0.9183\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8993 - val_loss: 0.5803 - val_accuracy: 0.8800\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.9179 - val_loss: 0.6229 - val_accuracy: 0.8600\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.9150 - val_loss: 0.5789 - val_accuracy: 0.8850\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.9136 - val_loss: 0.4989 - val_accuracy: 0.9133\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.9000 - val_loss: 0.4962 - val_accuracy: 0.9167\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.9350 - val_loss: 0.4725 - val_accuracy: 0.9200\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.9286 - val_loss: 0.4706 - val_accuracy: 0.9233\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.9043 - val_loss: 0.5556 - val_accuracy: 0.8783\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.9050 - val_loss: 0.5163 - val_accuracy: 0.9000\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.8850 - val_loss: 0.6046 - val_accuracy: 0.8517\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.8736 - val_loss: 0.5118 - val_accuracy: 0.9167\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.9136 - val_loss: 0.5890 - val_accuracy: 0.8767\n",
      "32/32 [==============================] - 0s 834us/step\n",
      "\n",
      "\n",
      "Acurácia: 59.57%\n",
      "Matriz de confusão:\n",
      "[[340   0  16  14   5   0   0   0]\n",
      " [ 75 234  25  10  29   2   0   0]\n",
      " [ 54  22 243   0   8  48   0   0]\n",
      " [ 91  22   6   0   0 106 134  16]\n",
      " [ 51  56  67   0   0  48 103  50]\n",
      " [  3   0  29   0   1 241  24  77]\n",
      " [  0   0   0   0   0   0 375   0]\n",
      " [  0   0   0   1  12   2   6 354]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.55375   0.90667   0.68756       375\n",
      "           1    0.70060   0.62400   0.66008       375\n",
      "           2    0.62953   0.64800   0.63863       375\n",
      "           3    0.00000   0.00000   0.00000       375\n",
      "           4    0.00000   0.00000   0.00000       375\n",
      "           5    0.53915   0.64267   0.58637       375\n",
      "           6    0.58411   1.00000   0.73746       375\n",
      "           7    0.71227   0.94400   0.81193       375\n",
      "\n",
      "    accuracy                        0.59567      3000\n",
      "   macro avg    0.46493   0.59567   0.51526      3000\n",
      "weighted avg    0.46493   0.59567   0.51526      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# definição de uma fração do regularizador\n",
    "l = 0.01\n",
    "\n",
    "# desenvolvimento do modelo Keras para uma MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=64,\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(l)))\n",
    "# Aplicação de um dropout (caso necessário)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Aplicação de um modelo de descida de gradiente utilizando o Stocastic Gradient Descendent (SGD)\n",
    "sgd = SGD(lr=0.05, momentum=0.0)\n",
    "# Função de otimização da rede: ADAM\n",
    "adam = Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\n",
    "# Função de custo baseada em dados originalmente categóricos\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "# size of combination is set to 3\n",
    "j=0\n",
    "scores = []\n",
    "for i in combinations(trial, 2):\n",
    "    X_treino = np.vstack((i[0][0],i[1][0]))\n",
    "    X_teste = trial[j][0]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_treino)\n",
    "\n",
    "    X_treino = scaler.transform(X_treino)\n",
    "    X_teste = scaler.transform(X_teste)\n",
    "\n",
    "    y_treino = np.vstack((i[0][1],i[1][1]))\n",
    "    y_treino= y_treino.reshape(y_treino.shape[0]*y_treino.shape[1])\n",
    "    y_teste = trial[j][1]\n",
    "\n",
    "\n",
    "    j+=1\n",
    "    # print(X_treino.shape)\n",
    "    # print(y_treino.shape)\n",
    "    # print(y.shape)\n",
    "\n",
    "    X_treino, X_val, y_treino, y_val = train_test_split(\n",
    "    X_treino, y_treino, test_size=0.3, shuffle=True, stratify=y_treino)\n",
    "\n",
    "    history = model.fit(X_treino, y_treino, epochs=100, batch_size=15, validation_data=(X_val, y_val))\n",
    "    # plot_history(history)\n",
    "    # score = model.predict_classes(X_test)\n",
    "    predict_x=model.predict(X_teste) \n",
    "    score=np.argmax(predict_x,axis=1)\n",
    "    scores.append(score)\n",
    "# y_true = [np.where(x == 1)[0] for x in y_test]\n",
    "\n",
    "y_true =  np.vstack((trial[0][1],trial[1][1], trial[2][1]))\n",
    "y_true= y_true.reshape(y_true.shape[0]*y_true.shape[1])\n",
    "sc = np.vstack((scores[0], scores[1], scores[2]))\n",
    "sc= sc.reshape(sc.shape[0]*sc.shape[1])\n",
    "\n",
    "print('\\n\\nAcurácia: %0.2f%%' % (accuracy_score(y_true, sc) * 100))\n",
    "print('Matriz de confusão:')\n",
    "print(confusion_matrix(y_true, sc))\n",
    "print()\n",
    "print(classification_report(y_true, sc, digits=5))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
