{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import stft\n",
    "from math import prod\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from math import e\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(data, lowcut, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_lowpass(data, lowcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    b, a = signal.butter(order, low, btype='lowpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_highpass(data, highcut, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, high, btype='highpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_notch(data, cutoff, var=1, fs=200, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = (cutoff - var) / nyq\n",
    "    high = (cutoff + var) / nyq\n",
    "    b, a = signal.iirfilter(order, [low, high], btype='bandstop', ftype=\"butter\")\n",
    "    return signal.filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtros(data):\n",
    "    data_filtered = butter_notch(data, 60)\n",
    "    data_filtered = butter_highpass(data_filtered, 5)\n",
    "    data_filtered = butter_lowpass(data_filtered, 50)\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4, 1600)\n"
     ]
    }
   ],
   "source": [
    "dir = './datasets/topicos_cc'\n",
    "arquivos = os.listdir(dir)\n",
    "arq_numpy = [f for f in arquivos if f.endswith(\".npy\") and f.startswith('p2')]\n",
    "participantes = {}\n",
    "for i in arq_numpy:\n",
    "    nome = i.split('_')\n",
    "    trial = np.load(dir+'/'+i)\n",
    "    for m in range(0,8):\n",
    "        if participantes.get(f'participante_{nome[0]}',0) == 0:\n",
    "            participantes[f'participante_{nome[0]}'] = {}\n",
    "        if participantes[f'participante_{nome[0]}'].get(f'trial_{nome[1]}',0) == 0:\n",
    "            participantes[f'participante_{nome[0]}'][f'trial_{nome[1]}'] = {}\n",
    "        dados = trial[m, :, :].swapaxes(0,1)\n",
    "        participantes[f'participante_{nome[0]}'][f'trial_{nome[1]}'][f'movimento_{m+1}'] = filtros(dados)\n",
    "\n",
    "v = list()\n",
    "for i in arq_numpy:\n",
    "    trial = np.load(dir+'/'+i)\n",
    "    v.append(trial[:, :, :].swapaxes(1,2))    \n",
    "\n",
    "arr = np.vstack((v[0], v[1], v[2]))\n",
    "\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação de dominios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def janela(overl=64):\n",
    "\n",
    "\n",
    "    melhores_step = []\n",
    "    melhor_win = []\n",
    "    for i in range(1, 128):\n",
    "        step = i\n",
    "        segment = 128\n",
    "        data = arr\n",
    "        \n",
    "        _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=overl)\n",
    "        chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "        window = chunks_freq.shape[2] \n",
    "\n",
    "        n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "        ids = np.arange(n_win) * int(step)\n",
    "\n",
    "        # Janelas do dado no dominio do tempo\n",
    "        chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "        time_window = chunks_time.shape[2]\n",
    "            \n",
    "        if( time_window >= window -3 and time_window <= window +3):\n",
    "            melhores_step.append(step)\n",
    "            melhor_win.append(time_window)\n",
    "        \n",
    "    return melhores_step, melhor_win, window\n",
    "# step = janela(overl=64)\n",
    "# print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "89\n",
      "102\n",
      "115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[57, 35, 24, 12]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_steps = []\n",
    "for i in [0.5, 0.7, 0.8, 0.9 ]:\n",
    "    n_step = int(128*i)\n",
    "    print(n_step)\n",
    "    step, win, orig = janela(overl=n_step)\n",
    "    step = np.array(step)\n",
    "    # print(step)\n",
    "    # print(win)\n",
    "    # print(orig)\n",
    "    # print(np.abs(orig-np.array(win)))\n",
    "    # print(step[np.abs(orig-np.array(win)).argmin()])\n",
    "    all_steps.append(step[np.abs(orig-np.array(win)).argmin()])\n",
    "    # print()\n",
    "    \n",
    "    \n",
    "all_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def janela(overl=64):\n",
    "\n",
    "\n",
    "    \n",
    "    for i in np.arange(1, 128, 0.1):\n",
    "        step = i\n",
    "        segment = 128\n",
    "        data = arr\n",
    "        \n",
    "        _, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=overl)\n",
    "        chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "        window = chunks_freq.shape[2] \n",
    "\n",
    "        n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "        ids = np.arange(n_win) * int(step)\n",
    "\n",
    "        # Janelas do dado no dominio do tempo\n",
    "        chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "        time_window = chunks_time.shape[2]\n",
    "            \n",
    "        if( time_window == window ):\n",
    "            return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "89\n",
      "102\n",
      "115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[56.7, 34.3, 23.4, 11.8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_steps = []\n",
    "for i in [0.5, 0.7, 0.8, 0.9 ]:\n",
    "    n_step = int(128*i)\n",
    "    print(n_step)\n",
    "    step = janela(overl=n_step)\n",
    "    all_steps.append(step.round(2))\n",
    "    \n",
    "all_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [57, 35, 24, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (24, 4, 1600)\n",
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (24, 4, 125, 128) - (classes, ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (24, 4, 125, 65) - (classes, ensaios, canais, janelas, linhas)\n"
     ]
    }
   ],
   "source": [
    "step = 11.8\n",
    "segment = 128\n",
    "data = arr\n",
    "# .get_data()\n",
    "print('', data.shape)\n",
    "\n",
    "n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "ids = np.arange(n_win) * int(step)\n",
    "\n",
    "# Janelas do dado no dominio do tempo\n",
    "chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "# Janelas do dado no domínio da frequência\n",
    "_, _, chunks_freq = stft(data, fs=200, nperseg=128, noverlap=115)\n",
    "chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "print(f'Dominio do tempo: {chunks_time.shape} - (classes, ensaios, canais, janelas, linhas)')\n",
    "print(f'Dominio da frequência:  {chunks_freq.shape} - (classes, ensaios, canais, janelas, linhas)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "\n",
    "# funções de extração de características\n",
    "\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape[:-1]) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape[:-1])))\n",
    "\n",
    "def wamp(x):\n",
    "    limiar = np.abs(np.diff(x))\n",
    "    return np.sum(limiar > 0.0001, axis=-1)\n",
    "\n",
    "def wl(x):\n",
    "    return np.sum(np.abs(np.diff(x)), axis=-1)\n",
    "\n",
    "# def zc(x):\n",
    "#     trs = 0.0001\n",
    " \n",
    "#     f = [1 if i*j <= 0 else 0 for i,j in zip(x[:,:,:,:-1], x[:,:,:,1:])]\n",
    "    \n",
    "#     return np.sum(f)\n",
    "\n",
    "\n",
    "def getzc(data, th):\n",
    "    t = len(data)\n",
    "    soma = 0\n",
    "    for i in range(t-1):\n",
    "        res = (data[i]*data[i+1])\n",
    "        res2 = np.abs(data[i]-data[i+1])\n",
    "        if (res<0 and res2 > th):\n",
    "            soma +=1\n",
    "    return soma\n",
    "\n",
    "def zc(data):\n",
    "    f=[]\n",
    "    x,y,z = data.shape[:3]\n",
    "    for i in range(x):\n",
    "        l = []\n",
    "        for j in range(y):\n",
    "            li = []\n",
    "            for k in range(z):\n",
    "                li.append(getzc(data[i][j][k], 0.0001))\n",
    "            l.append(li.copy())\n",
    "        f.append(l.copy())\n",
    "\n",
    "    return np.array(f)\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "\n",
    "def fmn(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*PSD(w)), axis=-1)/np.sum(PSD(w), axis=-1)\n",
    "\n",
    "def mmnf(w):\n",
    "    sample_rate = 200\n",
    "    f = (w * sample_rate)/(2*len(w))\n",
    "    return np.sum(np.abs(f*np.abs(w)), axis=-1)/np.sum(np.abs(w), axis=-1)\n",
    "\n",
    "\n",
    "def logDec(data):\n",
    "    N = np.prod(data.shape)\n",
    "    return e ** (np.sum(np.log10(np.abs(data)), axis=-1))/N\n",
    "\n",
    "\n",
    "def iemg(x):\n",
    "    return np.sum(np.abs(x), axis=-1)\n",
    "\n",
    "def dasdv(x):\n",
    "    return np.sqrt(np.sum(np.diff(x)**2, axis=-1)/(np.prod(x.shape[:-1]) - 1))\n",
    "\n",
    "def tm(x,n):\n",
    "    return np.abs(np.sum(x**n , axis=-1)/np.prod(x.shape[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4, 125)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 24, 4, 125)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = list()\n",
    "final_data.append(var(chunks_time))\n",
    "final_data.append(rms(chunks_time))\n",
    "final_data.append(fmd(chunks_freq))\n",
    "final_data.append(mmdf(chunks_freq))\n",
    "final_data.append(logDec(chunks_time))\n",
    "final_data.append(wamp(chunks_time))\n",
    "final_data.append(wl(chunks_time))\n",
    "final_data.append(zc(chunks_time))\n",
    "final_data.append(fmn(chunks_freq))\n",
    "final_data.append(mmnf(chunks_freq))\n",
    "final_data.append(iemg(chunks_time))\n",
    "final_data.append(dasdv(chunks_time))\n",
    "print(iemg(chunks_time).shape)\n",
    "for n in range(3,6):\n",
    "    final_data.append(tm(chunks_time, n))\n",
    "\n",
    "\n",
    "\n",
    "f, Pxx_den = signal.welch(data, fs=200, nperseg=248, noverlap=223)\n",
    "# print(f.shape)\n",
    "# print(Pxx_den.shape)\n",
    "final_data.append(Pxx_den)\n",
    "\n",
    "final = np.array(final_data)\n",
    "final.shape\n",
    "\n",
    "\n",
    "\n",
    "# (24,                  4,      125,    65) - \n",
    "# (classes + ensaios, canais, janelas, linhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223.20000000000002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "248*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final.transpose(1,3,2,0)\n",
    "X = X.reshape(X.shape[0]*X.shape[1], X.shape[2]*X.shape[3])\n",
    "# X = X.reshape(s[0] * s[1], s[2] * s[3])\n",
    "# sh = data.shape\n",
    "# \n",
    "# X = data.reshape(sh[0], int(sh[1]/3), 3 * sh[2], sh[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.transpose(1, 2, 3, 0)\n",
    "# print('classes', 'amostras', 'canais', 'características')\n",
    "# print(X.shape)\n",
    "# X = X.reshape(X.shape[0]*X.shape[1], X.shape[2]*X.shape[3])\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos rótulos: (3000,)\n"
     ]
    }
   ],
   "source": [
    "# criação dos rótulos\n",
    "\n",
    "# 1,1,1,1,1,1,1,1,1,1,...,2,2,2,2,2,2,2,2,2,2,...,3,...\n",
    "y = [[str(i)] * int(X.shape[0] / 8) for i in range(8)]\n",
    "y = np.array(y).flatten()\n",
    "print('Shape dos rótulos:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler = MaxAbsScaler()\n",
    "# scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisotavio/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py:1014: RuntimeWarning: overflow encountered in square\n",
      "  temp **= 2\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py:1020: RuntimeWarning: overflow encountered in square\n",
      "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py:1020: RuntimeWarning: invalid value encountered in subtract\n",
      "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
      "/home/luisotavio/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:80: RuntimeWarning: overflow encountered in square\n",
      "  upper_bound = n_samples * eps * var + (n_samples * mean * eps) ** 2\n"
     ]
    }
   ],
   "source": [
    "scaler.fit(X_train)\n",
    "# scaler.fit(X)\n",
    "\n",
    "\n",
    "# print(type(X_train))\n",
    "# print(type(scaler.transform(X_train)))\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "# X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executar_svm(X_train, X_test, y_train, y_test):\n",
    "    # modelo de classificador com os parâmetros padrões\n",
    "    clf = SVC(gamma='scale')\n",
    "\n",
    "    # criando o modelo de classificação com os dados de treino\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # aplicando o classificador nos dados de teste\n",
    "    res = clf.predict(X_test)\n",
    "\n",
    "    # obtendo e ajustando os resultados \n",
    "    tot_hit = sum([1 for i in range(len(res)) if res[i] == y_test[i]])\n",
    "    print('Acurácia: {:.2f}%'.format(tot_hit / X_test.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 72.22%\n"
     ]
    }
   ],
   "source": [
    "executar_svm(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acuracias - standardscaler\n",
    "# step\n",
    "# 57: 48.40\n",
    "# 35: 57.42\n",
    "# 24: 60.40\n",
    "# 12: 67.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acuracias - MinMaxScaler\n",
    "# 57 43.09\n",
    "# 35 47.10\n",
    "# 24 59.96\n",
    "# 12 66.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acuracias - MaxAbsScaler\n",
    "# 57 47.34\n",
    "# 35 57.10\n",
    "# 24 59.73\n",
    "# 12 64.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acuracias - RobustScaler\n",
    "# 57 9.57\n",
    "# 35 10.32\n",
    "# 24 10.07\n",
    "# 12 11.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdetector, wl, iemg\n",
    "# https://biomedical-engineering-online.biomedcentral.com/track/pdf/10.1186/1475-925X-11-55.pdf\n",
    "# https://www.biopac.com/application/emg-electromyography/advanced-feature/automated-emg-analysis/#tabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_svm(X,y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    \n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "best_acc = 0\n",
    "best_comb = 0\n",
    "best_k = 0\n",
    "# for comb in range(1,12):\n",
    "#     for res in combinations(range(9),comb):\n",
    "#         for ks in range(1,41):\n",
    "#             X_new = SelectKBest(k=ks).fit_transform(X, y)\n",
    "#             acc = do_svm(X_new.take(res, axis=1), y)\n",
    "\n",
    "#             if acc > best_acc:\n",
    "#                 best_acc = acc\n",
    "#                 best_comb = res\n",
    "#                 best_k = ks\n",
    "\n",
    "# print(f\"Melhor Acurácia: {best_acc}, Melhor Combinação: {best_comb}, Melhor K: {best_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modificar janelamento, para ver qual janelamento eh melhor (50%, 70%, 80%, 90%)\n",
    "# welch scipy\n",
    "# minmax, maxabs, robust  -- scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, Pxx_den = signal.welch(x, fs, nperseg=1024)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
